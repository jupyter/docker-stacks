# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018- Project Jupyter
# This file is distributed under the same license as the docker-stacks
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: docker-stacks latest\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-08-25 10:59+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../using/common.md:1 0bee2bb3f5674032b335ca573e9053be
msgid "Common Features"
msgstr ""

#: ../../using/common.md:3 c576a39e7839453ab2fa440007e08c9d
msgid ""
"A container launched from any Jupyter Docker Stacks image runs a Jupyter "
"Notebook server by default. The container does so by executing a `start-"
"notebook.sh` script. This script configures the internal container "
"environment and then runs `jupyter notebook`, passing it any command line"
" arguments received."
msgstr ""

# 298bc09d3aab4abcb413ad481d6242ff
#: ../../using/common.md:7 88853b17e41e4bacad5a89d048b5adc2
msgid ""
"This page describes the options supported by the startup script as well "
"as how to bypass it to run alternative commands."
msgstr ""

#: ../../using/common.md:9 40a55b55c6da48bd949991f54da9b525
msgid "Notebook Options"
msgstr ""

#: ../../using/common.md:11 f2baa70accdd4764b1129f79fec5b46c
msgid ""
"You can pass [Jupyter command line options](https://jupyter-"
"notebook.readthedocs.io/en/stable/config.html#options) to the `start-"
"notebook.sh` script when launching the container. For example, to secure "
"the Notebook server with a custom password hashed using "
"`IPython.lib.passwd()` instead of the default token, you can run the "
"following:"
msgstr ""

# 4c08f057def247cbbfc8231e628cb792
#: ../../using/common.md:18 a9851f0742ed4a40afd3f2d969c7cbf5
msgid ""
"For example, to set the base URL of the notebook server, you can run the "
"following:"
msgstr ""

#: ../../using/common.md:24 cbb99692e8ad431aad7b0919626da7ad
msgid "Docker Options"
msgstr ""

#: ../../using/common.md:26 ad75e18d30b4402690ffef7983427c00
msgid ""
"You may instruct the `start-notebook.sh` script to customize the "
"container environment before launching the notebook server. You do so by "
"passing arguments to the `docker run` command."
msgstr ""

#: ../../using/common.md:30 66af6186b9e84ab69aebdb8fe5f80e84
msgid ""
"`-e NB_USER=jovyan` - Instructs the startup script to change the default "
"container username from `jovyan` to the provided value. Causes the script"
" to rename the `jovyan` user home folder. For this option to take effect,"
" you must run the container with `--user root`, set the working directory"
" `-w /home/${NB_USER}` and set the environment variable `-e "
"CHOWN_HOME=yes` (see below for detail). This feature is useful when "
"mounting host volumes with specific home folder."
msgstr ""

#: ../../using/common.md:34 41bc9017903442b6a24f654ec0d9b16e
msgid ""
"`-e NB_UID=1000` - Instructs the startup script to switch the numeric "
"user ID of `${NB_USER}` to the given value. This feature is useful when "
"mounting host volumes with specific owner permissions. For this option to"
" take effect, you must run the container with `--user root`. (The startup"
" script will `su ${NB_USER}` after adjusting the user ID.) You might "
"consider using modern Docker options `--user` and `--group-add` instead. "
"See the last bullet below for details."
msgstr ""

#: ../../using/common.md:40 490af8006bed4b9e8333df7336977ab2
msgid ""
"`-e NB_GID=100` - Instructs the startup script to change the primary "
"group of`${NB_USER}` to `${NB_GID}` (the new group is added with a name "
"of `${NB_GROUP}` if it is defined, otherwise the group is named "
"`${NB_USER}`). This feature is useful when mounting host volumes with "
"specific group permissions. For this option to take effect, you must run "
"the container with `--user root`. (The startup script will `su "
"${NB_USER}` after adjusting the group ID.) You might consider using "
"modern Docker options `--user` and `--group-add` instead. See the last "
"bullet below for details. The user is added to supplemental group `users`"
" (gid 100) in order to allow write access to the home directory and "
"`/opt/conda`. If you override the user/group logic, ensure the user stays"
" in group `users` if you want them to be able to modify files in the "
"image."
msgstr ""

#: ../../using/common.md:49 656f75f220174870af74f349b745738f
msgid ""
"`-e NB_GROUP=<name>` - The name used for `${NB_GID}`, which defaults to "
"`${NB_USER}`. This is only used if `${NB_GID}` is specified and "
"completely optional: there is only cosmetic effect."
msgstr ""

#: ../../using/common.md:51 adda534a99be4292ab5fed56958be404
msgid ""
"`-e NB_UMASK=<umask>` - Configures Jupyter to use a different umask value"
" from default, i.e. `022`. For example, if setting umask to `002`, new "
"files will be readable and writable by group members instead of just "
"writable by the owner. Wikipedia has a good article about "
"[umask](https://en.wikipedia.org/wiki/Umask). Feel free to read it in "
"order to choose the value that better fits your needs. Default value "
"should fit most situations. Note that `NB_UMASK` when set only applies to"
" the Jupyter process itself - you cannot use it to set a umask for "
"additional files created during run-hooks e.g. via `pip` or `conda` - if "
"you need to set a umask for these you must set `umask` for each command."
msgstr ""

#: ../../using/common.md:58 18c7b62083d3410dac9329827e6095c7
msgid ""
"`-e CHOWN_HOME=yes` - Instructs the startup script to change the "
"`${NB_USER}` home directory owner and group to the current value of "
"`${NB_UID}` and `${NB_GID}`. This change will take effect even if the "
"user home directory is mounted from the host using `-v` as described "
"below. The change is **not** applied recursively by default. You can "
"change modify the `chown` behavior by setting `CHOWN_HOME_OPTS` (e.g., "
"`-e CHOWN_HOME_OPTS='-R'`)."
msgstr ""

#: ../../using/common.md:62 b40544f1ae864d9fab63536cd79e9f7b
msgid ""
"`-e CHOWN_EXTRA=\"<some dir>,<some other dir>\"` - Instructs the startup "
"script to change the owner and group of each comma-separated container "
"directory to the current value of `${NB_UID}` and `${NB_GID}`. The change"
" is **not** applied recursively by default. You can change modify the "
"`chown` behavior by setting `CHOWN_EXTRA_OPTS` (e.g., `-e "
"CHOWN_EXTRA_OPTS='-R'`)."
msgstr ""

#: ../../using/common.md:65 efdbd62f74154bfbbfac134f1087e587
msgid ""
"`-e GRANT_SUDO=yes` - Instructs the startup script to grant the `NB_USER`"
" user passwordless `sudo` capability. You do **not** need this option to "
"allow the user to `conda` or `pip` install additional packages. This "
"option is useful, however, when you wish to give `${NB_USER}` the ability"
" to install OS packages with `apt` or modify other root-owned files in "
"the container. For this option to take effect, you must run the container"
" with `--user root`. (The `start-notebook.sh` script will `su ${NB_USER}`"
" after adding `${NB_USER}` to sudoers.) **You should only enable `sudo` "
"if you trust the user or if the container is running on an isolated "
"host.**"
msgstr ""

#: ../../using/common.md:71 de7169a56ad440ddac6b675b01f60d38
msgid ""
"`-e GEN_CERT=yes` - Instructs the startup script to generates a self-"
"signed SSL certificate and configure Jupyter Notebook to use it to accept"
" encrypted HTTPS connections."
msgstr ""

#: ../../using/common.md:72 edd0c05e8ed0486daeea926b030947e1
msgid ""
"`-e JUPYTER_ENABLE_LAB=yes` - Instructs the startup script to run "
"`jupyter lab` instead of the default `jupyter notebook` command. Useful "
"in container orchestration environments where setting environment "
"variables is easier than change command line parameters."
msgstr ""

#: ../../using/common.md:74 d0b24a8822e44704961e0620489e2b76
msgid ""
"`-e RESTARTABLE=yes` - Runs Jupyter in a loop so that quitting Jupyter "
"does not cause the container to exit. This may be useful when you need to"
" install extensions that require restarting Jupyter."
msgstr ""

#: ../../using/common.md:76 074ed506b6dc4e07821f5f4d4ed10ac4
msgid ""
"`-v /some/host/folder/for/work:/home/jovyan/work` - Mounts a host machine"
" directory as folder in the container. Useful when you want to preserve "
"notebooks and other work even after the container is destroyed. **You "
"must grant the within-container notebook user or group (`NB_UID` or "
"`NB_GID`) write access to the host directory (e.g., `sudo chown 1000 "
"/some/host/folder/for/work`).**"
msgstr ""

#: ../../using/common.md:79 0b2c34ca6fde4287978aee17736c5823
msgid ""
"`--user 5000 --group-add users` - Launches the container with a specific "
"user ID and adds that user to the `users` group so that it can modify "
"files in the default home directory and `/opt/conda`. You can use these "
"arguments as alternatives to setting `${NB_UID}` and `${NB_GID}`."
msgstr ""

#: ../../using/common.md:82 7e141c2f0a9c4dea8ae388d00a1d8b90
msgid "Startup Hooks"
msgstr ""

#: ../../using/common.md:84 2e7e2fc251e54a72a1704ce9a1afd3df
msgid ""
"You can further customize the container environment by adding shell "
"scripts (`*.sh`) to be sourced or executables (`chmod +x`) to be run to "
"the paths below:"
msgstr ""

#: ../../using/common.md:87 f7f87d3866324469ac3f0fece5733288
msgid ""
"`/usr/local/bin/start-notebook.d/` - handled before any of the standard "
"options noted above are applied"
msgstr ""

#: ../../using/common.md:89 44dc9da36e084b6da9669fcc87bd67bd
msgid ""
"`/usr/local/bin/before-notebook.d/` - handled after all of the standard "
"options noted above are applied and just before the notebook server "
"launches"
msgstr ""

#: ../../using/common.md:92 52afdf2d5fee40589952131832a2bbdd
msgid ""
"See the `run-hooks` function in the [`jupyter/base-notebook "
"start.sh`](https://github.com/jupyter/docker-stacks/blob/master/base-"
"notebook/start.sh) script for execution details."
msgstr ""

#: ../../using/common.md:95 eba79b9bc1834bee9d97ee58d690f85a
msgid "SSL Certificates"
msgstr ""

#: ../../using/common.md:97 d10aaa0c9af0443984beb97aee627307
msgid ""
"You may mount SSL key and certificate files into a container and "
"configure Jupyter Notebook to use them to accept HTTPS connections. For "
"example, to mount a host folder containing a `notebook.key` and "
"`notebook.crt` and use them, you might run the following:"
msgstr ""

# e496d62ce1b7489eabf40a55471247b4
#: ../../using/common.md:108 065443fb01754e598fe1ed6ece724648
msgid ""
"Alternatively, you may mount a single PEM file containing both the key "
"and certificate. For example:"
msgstr ""

# 6ada67b7d1a34f59ad235d7e49e6a298
#: ../../using/common.md:118 2daa613d9bbf417680c639644adcc1b9
msgid ""
"In either case, Jupyter Notebook expects the key and certificate to be a "
"base64 encoded text file. The certificate file or PEM may contain one or "
"more certificates (e.g., server, intermediate, and root)."
msgstr ""

# c908965cf0084fc2b276b50b47b87d18
#: ../../using/common.md:121 b7085ce643b44ecf8c031ade353ffa4a
msgid "For additional information about using SSL, see the following:"
msgstr ""

#: ../../using/common.md:123 b7be22871e7f4c89aaeca8c0b8541d77
msgid ""
"The [docker-stacks/examples](https://github.com/jupyter/docker-"
"stacks/tree/master/examples) for information about how to use [Let's "
"Encrypt](https://letsencrypt.org/) certificates when you run these stacks"
" on a publicly visible domain."
msgstr ""

#: ../../using/common.md:125 5651a116dde749e2aaa7eae7994fb9d2
msgid ""
"The [jupyter_notebook_config.py](https://github.com/jupyter/docker-"
"stacks/blob/master/base-notebook/jupyter_notebook_config.py) file for how"
" this Docker image generates a self-signed certificate."
msgstr ""

#: ../../using/common.md:126 b67e045471d041ff84ed7ed5f5b479fe
msgid ""
"The [Jupyter Notebook documentation](https://jupyter-"
"notebook.readthedocs.io/en/latest/public_server.html#securing-a-notebook-"
"server) for best practices about securing a public notebook server in "
"general."
msgstr ""

#: ../../using/common.md:128 57777d037f6f44189d2331774ce31027
msgid "Alternative Commands"
msgstr ""

#: ../../using/common.md:130 52d00abc9c5b44fe889697ffc7de107b
msgid "start.sh"
msgstr ""

#: ../../using/common.md:132 9f6c71fa484c45a0b0ad72d1eb945ef0
msgid ""
"The `start-notebook.sh` script actually inherits most of its option "
"handling capability from a more generic `start.sh` script. The `start.sh`"
" script supports all of the features described above, but allows you to "
"specify an arbitrary command to execute. For example, to run the text-"
"based `ipython` console in a container, do the following:"
msgstr ""

# ad0be3e8095e4394afb367e9e56e1ca5
#: ../../using/common.md:140 ef07dd97841f4b2a910e4aff89da8ccf
msgid "Or, to run JupyterLab instead of the classic notebook, run the following:"
msgstr ""

#: ../../using/common.md:146 0b637d5f86fe41e995aefdabb81726c4
msgid ""
"This script is particularly useful when you derive a new Dockerfile from "
"this image and install additional Jupyter applications with subcommands "
"like `jupyter console`, `jupyter kernelgateway`, etc."
msgstr ""

#: ../../using/common.md:148 7327b2a4146f4c1fa0e0c33ca29120af
msgid "Others"
msgstr ""

#: ../../using/common.md:150 4d282fceaffc449f98248817b3ca6316
msgid ""
"You can bypass the provided scripts and specify an arbitrary start "
"command. If you do, keep in mind that features supported by the "
"`start.sh` script and its kin will not function (e.g., `GRANT_SUDO`)."
msgstr ""

#: ../../using/common.md:153 109ca39640284c6ab48898dc237d2ae1
msgid "Conda Environments"
msgstr ""

#: ../../using/common.md:155 1112833a1eb24c8fbd49546b8c51adb6
msgid ""
"The default Python 3.x [Conda "
"environment](https://conda.io/projects/conda/en/latest/user-"
"guide/concepts/environments.html) resides in `/opt/conda`. The "
"`/opt/conda/bin` directory is part of the default `jovyan` user's "
"`${PATH}`. That directory is also whitelisted for use in `sudo` commands "
"by the `start.sh` script."
msgstr ""

#: ../../using/common.md:159 a32c8990831d4082a071dafd8db50e94
msgid ""
"The `jovyan` user has full read/write access to the `/opt/conda` "
"directory. You can use either `pip`, `conda` or `mamba` to install new "
"packages without any additional permissions."
msgstr ""

#: ../../using/common.md:179 4e2e6857ce044c73b22b227f705666c4
msgid "Using alternative channels"
msgstr ""

#: ../../using/common.md:181 75af6443e1854c82a2f649e469c5b331
msgid ""
"Conda is configured by default to use only the [`conda-"
"forge`](https://anaconda.org/conda-forge) channel. However, alternative "
"channels can be used either one shot by overwriting the default channel "
"in the installation command or by configuring `mamba` to use different "
"channels. The examples below show how to use the [anaconda default "
"channels](https://repo.anaconda.com/pkgs/main) instead of `conda-forge` "
"to install packages."
msgstr ""

#: ../../using/recipes.md:1 591794e18394401e88fd44c31a800843
msgid "Contributed Recipes"
msgstr ""

#: ../../using/recipes.md:3 bb7326483ba64e2988acb62780c54d96
msgid ""
"Users sometimes share interesting ways of using the Jupyter Docker "
"Stacks. We encourage users to [contribute these "
"recipes](../contributing/recipes.md) to the documentation in case they "
"prove useful to other members of the community by submitting a pull "
"request to `docs/using/recipes.md`. The sections below capture this "
"knowledge."
msgstr ""

#: ../../using/recipes.md:8 f7bea3cf24cc4f3c87a77a14d53d8dc6
msgid "Using `sudo` within a container"
msgstr ""

#: ../../using/recipes.md:10 6c4d8fe062c0498892cf501c69a49f05
msgid ""
"Password authentication is disabled for the `NB_USER` (e.g., `jovyan`). "
"This choice was made to avoid distributing images with a weak default "
"password that users ~might~ will forget to change before running a "
"container on a publicly accessible host."
msgstr ""

#: ../../using/recipes.md:13 7c261282ec994c78868647c9d5e39e17
msgid ""
"You can grant the within-container `NB_USER` passwordless `sudo` access "
"by adding `-e GRANT_SUDO=yes` and `--user root` to your Docker command "
"line or appropriate container orchestrator config."
msgstr ""

# f75300183d66418d958651b713e3c81e
#: ../../using/recipes.md:15 5b843dd536ab4e45a345e57ebc8d01d2
msgid "For example:"
msgstr ""

#: ../../using/recipes.md:21 8dfe526ab51e4ba4a70f4e60e4541b93
msgid ""
"**You should only enable `sudo` if you trust the user and/or if the "
"container is running on an isolated host.** See [Docker security "
"documentation](https://docs.docker.com/engine/security/userns-remap/) for"
" more information about running containers as `root`."
msgstr ""

#: ../../using/recipes.md:24 1c31234d077d42f8a33443fa4e2228b4
msgid "Using `mamba install` or `pip install` in a Child Docker image"
msgstr ""

# cfb1a65ed1a4453e8b3355f1c0c23b1c
#: ../../using/recipes.md:26 f03959c6a4ec4cd4a01f39e9b76a9c8b
msgid "Create a new Dockerfile like the one shown below."
msgstr ""

# 3ab615dc6fb6425d954cae4ce14f08b9
#: ../../using/recipes.md:37 92dee9de8e4e444c9ff4882253ef4a2e
msgid "Then build a new image."
msgstr ""

#: ../../using/recipes.md:43 34de1cba87bd427d969078437f018dd7
msgid ""
"To use a requirements.txt file, first create your `requirements.txt` file"
" with the listing of packages desired. Next, create a new Dockerfile like"
" the one shown below."
msgstr ""

# f2f035925d764425b9999b19d36c1d30
#: ../../using/recipes.md:57 a2db29fdc056486eba88997677aa1cf3
msgid "For conda, the Dockerfile is similar:"
msgstr ""

#: ../../using/recipes.md:70 bc249b804d3f4874b7c0ed0277a8e8f4
msgid ""
"Ref: [docker-"
"stacks/commit/79169618d571506304934a7b29039085e77db78c](https://github.com/jupyter"
"/docker-"
"stacks/commit/79169618d571506304934a7b29039085e77db78c#commitcomment-15960081)"
msgstr ""

#: ../../using/recipes.md:72 fefe9cf7ea8f48309d6e1c3e5d83089f
msgid "Add a Python 2.x environment"
msgstr ""

#: ../../using/recipes.md:74 b641249cdf5541c29fd82aed1b10d483
msgid ""
"Python 2.x was removed from all images on August 10th, 2017, starting in "
"tag `cc9feab481f7`. You can add a Python 2.x environment by defining your"
" own Dockerfile inheriting from one of the images like so:"
msgstr ""

#: ../../using/recipes.md:97 e42da836900246fdb54ec8d75da16c75
msgid "Ref: <https://github.com/jupyter/docker-stacks/issues/440>"
msgstr ""

#: ../../using/recipes.md:99 33929d7d88754ae397530bb36f7e8b41
msgid "Add a Python 3.x environment"
msgstr ""

#: ../../using/recipes.md:101 13da3d20a0df46af97d954a57bd5798c
msgid ""
"The default version of Python that ships with conda/ubuntu may not be the"
" version you want. To add a conda environment with a different version "
"and make it accessible to Jupyter, the instructions are very similar to "
"Python 2.x but are slightly simpler (no need to switch to `root`):"
msgstr ""

#: ../../using/recipes.md:140 55a582e890584c1daf322399004a54bd
msgid "Run JupyterLab"
msgstr ""

#: ../../using/recipes.md:142 82c2f7a8d17a481b9c346eb053fd0d08
msgid ""
"JupyterLab is preinstalled as a notebook extension starting in tag "
"[c33a7dc0eece](https://github.com/jupyter/docker-stacks/pull/355)."
msgstr ""

#: ../../using/recipes.md:145 cb0e96fe242b466ea9a127c855df97d1
msgid ""
"Run jupyterlab using a command such as `docker run -it --rm -p 8888:8888 "
"-e JUPYTER_ENABLE_LAB=yes jupyter/datascience-notebook`"
msgstr ""

#: ../../using/recipes.md:148 38e0366f66034ca9874406ceccaa69e2
msgid "Dask JupyterLab Extension"
msgstr ""

#: ../../using/recipes.md:150 355159ca49994ebbaf096e5509150cfd
msgid ""
"[Dask JupyterLab Extension](https://github.com/dask/dask-labextension) "
"provides a JupyterLab extension to manage Dask clusters, as well as embed"
" Dask's dashboard plots directly into JupyterLab panes. Create the "
"Dockerfile as:"
msgstr ""

#: ../../using/recipes.md:169 c789f7e4e64441958f1fe765417e3c47
msgid "And build the image as:"
msgstr ""

#: ../../using/recipes.md:175 cd718815a8494a3b949f4ad13810804c
msgid "Once built, run using the command:"
msgstr ""

#: ../../using/recipes.md:181 b68d8f2e233e49a1aa262461be607958
msgid "Ref: <https://github.com/jupyter/docker-stacks/issues/999>"
msgstr ""

#: ../../using/recipes.md:183 245827855c5f436081478a354609a0cc
msgid "Let's Encrypt a Notebook server"
msgstr ""

#: ../../using/recipes.md:185 e54e3ad20eaf41029f73d54fd3d396c9
msgid ""
"See the README for the simple automation here <https://github.com/jupyter"
"/docker-stacks/tree/master/examples/make-deploy> which includes steps for"
" requesting and renewing a Let's Encrypt certificate."
msgstr ""

#: ../../using/recipes.md:189 dabfbf076efa46ddb3611608bdbbc9d4
msgid "Ref: <https://github.com/jupyter/docker-stacks/issues/78>"
msgstr ""

#: ../../using/recipes.md:191 a53f75a1a06744f0a39265b2abee9294
msgid "Slideshows with Jupyter and RISE"
msgstr ""

#: ../../using/recipes.md:193 bab15af1ab1048669537461400ea8de1
msgid ""
"[RISE](https://github.com/damianavila/RISE) allows via extension to "
"create live slideshows of your notebooks, with no conversion, adding "
"javascript Reveal.js:"
msgstr ""

#: ../../using/recipes.md:204 ccc65dceae4840c381d0951100f1843f
msgid ""
"Credit: [Paolo D.](https://github.com/pdonorio) based on [docker-"
"stacks/issues/43](https://github.com/jupyter/docker-stacks/issues/43)"
msgstr ""

#: ../../using/recipes.md:207 5d3858cf88ed42788f82d12ff21b3175
msgid "xgboost"
msgstr ""

#: ../../using/recipes.md:209 f034cf4477634ef7adafd7ca41ed8488
msgid ""
"You need to install conda-forge's gcc for Python xgboost to work "
"properly. Otherwise, you'll get an exception about libgomp.so.1 missing "
"GOMP_4.0."
msgstr ""

#: ../../using/recipes.md:225 de460f729cf54f7c9c1507922aadc5af
msgid "Running behind a nginx proxy"
msgstr ""

# ca7763a5a35a47bd9fb29ae9d00feab3
#: ../../using/recipes.md:227 3999eaf4f42348fdbc5f0e3611d681dd
msgid ""
"Sometimes it is useful to run the Jupyter instance behind a nginx proxy, "
"for instance:"
msgstr ""

#: ../../using/recipes.md:229 c8a8c01b791240db937babca18ba4b5d
msgid ""
"you would prefer to access the notebook at a server URL with a path "
"(`https://example.com/jupyter`) rather than a port "
"(`https://example.com:8888`)"
msgstr ""

# a5129fb6e2b042f5b8161ed5318123f9
#: ../../using/recipes.md:231 70026dcc1ef646efa59cb7145a8c11d7
msgid ""
"you may have many different services in addition to Jupyter running on "
"the same server, and want to nginx to help improve server performance in "
"manage the connections"
msgstr ""

#: ../../using/recipes.md:234 367ded79fd854d6cab7960e6df505da6
msgid ""
"Here is a [quick example NGINX "
"configuration](https://gist.github.com/cboettig/8643341bd3c93b62b5c2) to "
"get started. You'll need a server, a `.crt` and `.key` file for your "
"server, and `docker` & `docker-compose` installed. Then just download the"
" files at that gist and run `docker-compose up -d` to test it out. "
"Customize the `nginx.conf` file to set the desired paths and add other "
"services."
msgstr ""

#: ../../using/recipes.md:239 faf2747bdc7049f6b196fc202c389fa1
msgid "Host volume mounts and notebook errors"
msgstr ""

#: ../../using/recipes.md:241 ad2e4ac82be242038b4ef2f4ef50270b
msgid ""
"If you are mounting a host directory as `/home/jovyan/work` in your "
"container and you receive permission errors or connection errors when you"
" create a notebook, be sure that the `jovyan` user (UID=1000 by default) "
"has read/write access to the directory on the host. Alternatively, "
"specify the UID of the `jovyan` user on container startup using the `-e "
"NB_UID` option described in the [Common Features, Docker Options "
"section](../using/common.html#Docker-Options)"
msgstr ""

#: ../../using/recipes.md:247 3121010541634ecdaf6c16bce4ae2cfd
msgid "Ref: <https://github.com/jupyter/docker-stacks/issues/199>"
msgstr ""

#: ../../using/recipes.md:249 e3859d3802cd42a29ed2df5372a3bc51
msgid "Manpage installation"
msgstr ""

# 7fc6566074ee4ba3a4e579437d7f151d
#: ../../using/recipes.md:251 7353293612644ea4bf8cd424355de990
msgid ""
"Most containers, including our Ubuntu base image, ship without manpages "
"installed to save space. You can use the following dockerfile to inherit "
"from one of our images to enable manpages:"
msgstr ""

#: ../../using/recipes.md:270 ad7e22b8905547f99a394f8560e935ff
msgid ""
"Adding the documentation on top of an existing singleuser image wastes a "
"lot of space and requires reinstalling every system package, which can "
"take additional time and bandwidth; the `datascience-notebook` image has "
"been shown to grow by almost 3GB when adding manapages in this way. "
"Enabling manpages in the base Ubuntu layer prevents this container bloat."
" Just use previous `Dockerfile` with original ubuntu image as your base "
"container:"
msgstr ""

#: ../../using/recipes.md:282 ae880e3f01264510b8b56984a430f19a
msgid ""
"For Ubuntu 18.04 (bionic) and earlier, you may also require to workaround"
" for a mandb bug, which was fixed in mandb >= 2.8.6.1:"
msgstr ""

#: ../../using/recipes.md:293 702c46fcb8de4305918f4b87e25fbf9e
msgid ""
"Be sure to check the current base image in `base-notebook` before "
"building."
msgstr ""

#: ../../using/recipes.md:295 b581363ffbe447c5973c17c27dbf11fa
msgid "JupyterHub"
msgstr ""

# af0ca920391b419b805ae3809388fcf2
#: ../../using/recipes.md:297 7b3591ba9c6d40d8a1f899000fbdc085
msgid "We also have contributed recipes for using JupyterHub."
msgstr ""

#: ../../using/recipes.md:299 8f8ac32506304ea9998935fb8b107830
msgid "Use JupyterHub's dockerspawner"
msgstr ""

# 81e1dbb4c1c34f4c9e88630adff3d1e9
#: ../../using/recipes.md:301 abc7660c70784f7e8cd2e0152ffd510e
msgid ""
"In most cases for use with DockerSpawner, given any image that already "
"has a notebook stack set up, you would only need to add:"
msgstr ""

# 837b7a2dac01402e8cd2cc398bd5d785
#: ../../using/recipes.md:304 9fafd90f7ae64468990cfd1dbcf668e2
msgid "install the jupyterhub-singleuser script (for the right Python)"
msgstr ""

# d9816cb5ae2041e2a5fde9cdfb91262f
#: ../../using/recipes.md:305 53789533c2394af5a5ed02d2d8e09aa7
msgid "change the command to launch the single-user server"
msgstr ""

#: ../../using/recipes.md:307 93fe115707314dd0807bdf635b383fe8
msgid ""
"Swapping out the `FROM` line in the `jupyterhub/singleuser` Dockerfile "
"should be enough for most cases."
msgstr ""

#: ../../using/recipes.md:310 ba0ed9625f004be8bdfceb67e7a0a658
msgid ""
"Credit: [Justin Tyberg](https://github.com/jtyberg), "
"[quanghoc](https://github.com/quanghoc), and [Min "
"RK](https://github.com/minrk) based on [docker-"
"stacks/issues/124](https://github.com/jupyter/docker-stacks/issues/124) "
"and [docker-stacks/pull/185](https://github.com/jupyter/docker-"
"stacks/pull/185)"
msgstr ""

#: ../../using/recipes.md:315 a3c55f1ab70c43faab5837cdab549187
msgid "Containers with a specific version of JupyterHub"
msgstr ""

#: ../../using/recipes.md:317 88a2ba1e3f614e359db8725800fc0c98
msgid ""
"To use a specific version of JupyterHub, the version of `jupyterhub` in "
"your image should match the version in the Hub itself."
msgstr ""

#: ../../using/recipes.md:327 736b311f27654fe49fbb92528018e56d
msgid ""
"Credit: [MinRK](https://github.com/jupyter/docker-"
"stacks/issues/423#issuecomment-322767742)"
msgstr ""

#: ../../using/recipes.md:329 78fdf5f068484cbbbdd201dcc7c317e8
msgid "Ref: <https://github.com/jupyter/docker-stacks/issues/177>"
msgstr ""

#: ../../using/recipes.md:331 88b6e000c15f492b99399a150a6ce25a
msgid "Spark"
msgstr ""

# 975c96d6a0b843dfabd889c753671c93
#: ../../using/recipes.md:333 465045e44624434e8ed8bec8bd86be9c
msgid "A few suggestions have been made regarding using Docker Stacks with spark."
msgstr ""

#: ../../using/recipes.md:335 f75a3315584547cbaf8de11b28c34211
msgid "Using PySpark with AWS S3"
msgstr ""

# dc4059d42eaa495f8ebca84ebc91ac09
#: ../../using/recipes.md:337 6422ff6b0ef44bb59def28c2dcca2f0c
msgid "Using Spark session for hadoop 2.7.3"
msgstr ""

# d2c12e3525bf4d9ca518fef02c4a79d3
#: ../../using/recipes.md:357 535563d9c7574f01bada9ab1379aa91e
msgid "Using Spark context for hadoop 2.6.0"
msgstr ""

#: ../../using/recipes.md:379 1b4e794c65d6473cbd378bd196a4add7
msgid "Ref: <https://github.com/jupyter/docker-stacks/issues/127>"
msgstr ""

#: ../../using/recipes.md:381 c4cb0e6d86f44dbfbc5f7d1c7b5fa29b
msgid "Using Local Spark JARs"
msgstr ""

#: ../../using/recipes.md:397 640395ee5fd047f99d92c70fed7fa85b
msgid "Ref: <https://github.com/jupyter/docker-stacks/issues/154>"
msgstr ""

#: ../../using/recipes.md:399 57aa8858520f4dd8816c42f113889138
msgid "Using spark-packages.org"
msgstr ""

#: ../../using/recipes.md:401 e05db5b18945478180b91b018190473a
msgid ""
"If you'd like to use packages from [spark-packages.org](https://spark-"
"packages.org/), see "
"[https://gist.github.com/parente/c95fdaba5a9a066efaab](https://gist.github.com/parente/c95fdaba5a9a066efaab)"
" for an example of how to specify the package identifier in the "
"environment before creating a SparkContext."
msgstr ""

#: ../../using/recipes.md:406 e6db15c9f8a9486598740258939e456f
msgid "Ref: <https://github.com/jupyter/docker-stacks/issues/43>"
msgstr ""

#: ../../using/recipes.md:408 e59d9eb405894c3c967a93e5ac71b5db
msgid "Use jupyter/all-spark-notebooks with an existing Spark/YARN cluster"
msgstr ""

#: ../../using/recipes.md:481 3d1107ab81ea421c95a25027fe3bb048
msgid ""
"Credit: [britishbadger](https://github.com/britishbadger) from [docker-"
"stacks/issues/369](https://github.com/jupyter/docker-stacks/issues/369)"
msgstr ""

#: ../../using/recipes.md:483 d0a14eeb611b48048ebc1d392c858606
msgid ""
"Run Jupyter Notebook/Lab inside an already secured environment (i.e., "
"with no token)"
msgstr ""

#: ../../using/recipes.md:485 4275fc835c1d40279712b17196041c68
msgid ""
"(Adapted from [issue 728](https://github.com/jupyter/docker-"
"stacks/issues/728))"
msgstr ""

#: ../../using/recipes.md:487 286b852b01a84bee8e94e68342752bbb
msgid ""
"The default security is very good. There are use cases, encouraged by "
"containers, where the jupyter container and the system it runs within, "
"lie inside the security boundary. In these use cases it is convenient to "
"launch the server without a password or token. In this case, you should "
"use the `start.sh` script to launch the server with no token:"
msgstr ""

# 7476a6d5eae74ecaae966e56390c096e
#: ../../using/recipes.md:492 61980c5a3d32416ea5ad2b8fa49b1e6e
msgid "For jupyterlab:"
msgstr ""

# f2efc5a0ba6b4c53b2047cc5f22bdbaa
#: ../../using/recipes.md:498 78f150417a844d5199061e78ba98f3e8
msgid "For jupyter classic:"
msgstr ""

#: ../../using/recipes.md:504 f4499bf53aee45adb2edc01b2b93aefb
msgid "Enable nbextension spellchecker for markdown (or any other nbextension)"
msgstr ""

# 8ccfbcb4264f48d0b6709fe81aa0a86d
#: ../../using/recipes.md:506 d9178aef0ae24f72849a1b3d5ffa6083
msgid "NB: this works for classic notebooks only"
msgstr ""

#: ../../using/recipes.md:522 ddea8086d59f43719a3ed244be94c6d3
msgid "Ref: <https://github.com/jupyter/docker-stacks/issues/675>"
msgstr ""

#: ../../using/recipes.md:524 a53a798e3afd4edfae2e5b49e7f6d4a2
msgid "Enable Delta Lake in Spark notebooks"
msgstr ""

#: ../../using/recipes.md:526 05df20ed4c8549aea3f05c9ce3317751
msgid ""
"Please note that the [Delta Lake](https://delta.io/) packages are only "
"available for Spark version > `3.0`. By adding the properties to `spark-"
"defaults.conf`, the user no longer needs to enable Delta support in each "
"notebook."
msgstr ""

#: ../../using/running.md:1 2ebf4f431e7a425d8ce8b27b051710e1
msgid "Running a Container"
msgstr ""

# 1f345e7a53e94439b936b3f4bbc877da
# 324906e630c646b0ae10bbff6ed587fa
#: ../../using/running.md:3 ../../using/selecting.md:7
#: 61529d189d6e40e2b92aced8db8a3ca7 ffe706983755485c9c186f5081650e16
msgid "Using one of the Jupyter Docker Stacks requires two choices:"
msgstr ""

# 781cbaffaea24fb08451cc83327cfa9b
# 1c6c83776a3b4a27a8ed4128a0dceeb7
#: ../../using/running.md:5 ../../using/selecting.md:9
#: 08c7047155284e85a441df7d9befbddf fdbf77baeb9a4f75ad9a14704fb6df72
msgid "Which Docker image you wish to use"
msgstr ""

# 632f67c9207e4ed9ba01bf59c4d942f7
# ab191cfc95204429b7c0271ecdf69d33
#: ../../using/running.md:6 ../../using/selecting.md:10
#: 5377205dc4ac4129898b6ee418d357e5 d53b50fab6974a95bce539598e1dac90
msgid "How you wish to start Docker containers from that image"
msgstr ""

# ebf870aa1ede4e2ab8fdcb2cef0fd610
#: ../../using/running.md:8 c323a7f67c1a458383d227e0e169479e
msgid "This section provides details about the second."
msgstr ""

#: ../../using/running.md:10 e742841172624f368e7a3dfeb621aec4
msgid "Using the Docker CLI"
msgstr ""

#: ../../using/running.md:12 3f1b090a72d940f7854900cea09783ad
msgid ""
"You can launch a local Docker container from the Jupyter Docker Stacks "
"using the [Docker command line "
"interface](https://docs.docker.com/engine/reference/commandline/cli/). "
"There are numerous ways to configure containers using the CLI. The "
"following are some common patterns."
msgstr ""

#: ../../using/running.md:16 e2899d8cc1164f4996b117916a653a6a
msgid ""
"**Example 1** This command pulls the `jupyter/scipy-notebook` image "
"tagged `33add21fab64` from Docker Hub if it is not already present on the"
" local host. It then starts a container running a Jupyter Notebook server"
" and exposes the server on host port 8888. The server logs appear in the "
"terminal and include a URL to the notebook server."
msgstr ""

#: ../../using/running.md:40 f253066e9e9941b5b85e5f8e5059ac1c
msgid ""
"Pressing `Ctrl-C` shuts down the notebook server but leaves the container"
" intact on disk for later restart or permanent deletion using commands "
"like the following:"
msgstr ""

#: ../../using/running.md:59 9ce2fb2b1d3a40c7a59d8f8d52e0113b
msgid ""
"**Example 2** This command pulls the `jupyter/r-notebook` image tagged "
"`33add21fab64` from Docker Hub if it is not already present on the local "
"host. It then starts a container running a Jupyter Notebook server and "
"exposes the server on host port 10000. The server logs appear in the "
"terminal and include a URL to the notebook server, but with the internal "
"container port (8888) instead of the the correct host port (10000)."
msgstr ""

#: ../../using/running.md:83 2765d5f8a39a437fb3b319d348899420
msgid ""
"Pressing `Ctrl-C` shuts down the notebook server and immediately destroys"
" the Docker container. Files written to `~/work` in the container remain "
"touched. Any other changes made in the container are lost."
msgstr ""

#: ../../using/running.md:87 e51025362cdf47d6ac5c0cb2b8ef6d44
msgid ""
"**Example 3** This command pulls the `jupyter/all-spark-notebook` image "
"currently tagged `latest` from Docker Hub if an image tagged `latest` is "
"not already present on the local host. It then starts a container named "
"`notebook` running a JupyterLab server and exposes the server on a "
"randomly selected port."
msgstr ""

# 9a561b9bb5944059801c71862521d66a
#: ../../using/running.md:94 90bb804bf969470e89a41d568817535f
msgid ""
"The assigned port and notebook server token are visible using other "
"Docker commands."
msgstr ""

#: ../../using/running.md:108 42fb32fe11ca4928af5832d118def281
msgid ""
"Together, the URL to visit on the host machine to access the server in "
"this case is "
"<http://localhost:32769?token=15914ca95f495075c0aa7d0e060f1a78b6d94f70ea373b00>."
msgstr ""

# bf82931e197b40ad940d9969993120a2
#: ../../using/running.md:110 509d439b82b74329a650a5c4067c459a
msgid ""
"The container runs in the background until stopped and/or removed by "
"additional Docker commands."
msgstr ""

#: ../../using/running.md:122 ec6226228132442ba5fe29a4f1cf0241
msgid "Using Binder"
msgstr ""

#: ../../using/running.md:124 6d7e1cf1dcb24a9d8a834fb4b0def066
msgid ""
"[Binder](https://mybinder.org/) is a service that allows you to create "
"and share custom computing environments for projects in version control. "
"You can use any of the Jupyter Docker Stacks images as a basis for a "
"Binder-compatible Dockerfile. See the [docker-stacks "
"example](https://mybinder.readthedocs.io/en/latest/sample_repos.html#using-a"
"-docker-image-from-the-jupyter-docker-stacks-repository) and [Using a "
"Dockerfile](https://mybinder.readthedocs.io/en/latest/tutorials/dockerfile.html)"
" sections in the [Binder "
"documentation](https://mybinder.readthedocs.io/en/latest/index.html) for "
"instructions."
msgstr ""

#: ../../using/running.md:131 b31e88b9dc7b4a46959129011e8add25
msgid "Using JupyterHub"
msgstr ""

#: ../../using/running.md:133 b8e225c7eea947a2a44d607279d49bb0
msgid ""
"You can configure JupyterHub to launcher Docker containers from the "
"Jupyter Docker Stacks images. If you've been following the [Zero to "
"JupyterHub with Kubernetes](https://zero-to-"
"jupyterhub.readthedocs.io/en/latest/) guide, see the [Use an existing "
"Docker image](https://zero-to-"
"jupyterhub.readthedocs.io/en/latest/jupyterhub/customizing/user-"
"environment.html#choose-and-use-an-existing-docker-image) section for "
"details. If you have a custom JupyterHub deployment, see the [Picking or "
"building a Docker image](https://github.com/jupyterhub/dockerspawner"
"#picking-or-building-a-docker-image) instructions for the "
"[dockerspawner](https://github.com/jupyterhub/dockerspawner) instead."
msgstr ""

#: ../../using/running.md:139 600db56ec460415f9119eb062ca939e5
msgid "Using Other Tools and Services"
msgstr ""

#: ../../using/running.md:141 7b0e05ee0dfa444fba7af91e302341a3
msgid ""
"You can use the Jupyter Docker Stacks with any Docker-compatible "
"technology (e.g., [Docker Compose](https://docs.docker.com/compose/), "
"[docker-py](https://github.com/docker/docker-py), your favorite cloud "
"container service). See the documentation of the tool, library, or "
"service for details about how to reference, configure, and launch "
"containers from these images."
msgstr ""

#: ../../using/selecting.md:1 799ad5e829fb47b0a13147d6e68b9752
msgid "Selecting an Image"
msgstr ""

#: ../../using/selecting.md:3 7d351f06b7ad4b1d98cc9d8b546927b5
msgid "[Core Stacks](#core-stacks)"
msgstr ""

#: ../../using/selecting.md:4 53e63aaf31a3411faa2221d18cf9475c
msgid "[Image Relationships](#image-relationships)"
msgstr ""

#: ../../using/selecting.md:5 517d977850014211a316a8c8d7835570
msgid "[Community Stacks](#community-stacks)"
msgstr ""

# af7e19bb10ec44348e8121be4129ce8a
#: ../../using/selecting.md:12 ab57f26fb3af4496bd72737e933fc58a
msgid "This section provides details about the first."
msgstr ""

#: ../../using/selecting.md:14 403b240fe6d14307b657aaa2b2e2461d
msgid "Core Stacks"
msgstr ""

#: ../../using/selecting.md:16 0c245bd34c7c4cd3908898a2041e97b9
msgid ""
"The Jupyter team maintains a set of Docker image definitions in the "
"<https://github.com/jupyter/docker-stacks> GitHub repository. The "
"following sections describe these images including their contents, "
"relationships, and versioning strategy."
msgstr ""

#: ../../using/selecting.md:19 fe2b246e387948d880a71a02560c2933
msgid "jupyter/base-notebook"
msgstr ""

#: ../../using/selecting.md:21 410696eeceda4e978a4b612a14161771
msgid ""
"[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/master"
"/base-notebook) | [Dockerfile commit history](https://github.com/jupyter"
"/docker-stacks/commits/master/base-notebook/Dockerfile) | [Docker Hub "
"image tags](https://hub.docker.com/r/jupyter/base-notebook/tags/)"
msgstr ""

#: ../../using/selecting.md:25 6fc98c31f6e74b1382ab12c3213b15c5
msgid ""
"`jupyter/base-notebook` is a small image supporting the [options common "
"across all core stacks](common.md). It is the basis for all other stacks."
msgstr ""

#: ../../using/selecting.md:28 5b7dccb69f2747dcb715b18fbdbf2abb
msgid ""
"Minimally-functional Jupyter Notebook server (e.g., no LaTeX support for "
"saving notebooks as PDFs)"
msgstr ""

#: ../../using/selecting.md:29 3ff05e9180e34d0ebd3146636a8a03f8
msgid ""
"[Miniforge](https://github.com/conda-forge/miniforge) Python 3.x in "
"`/opt/conda` with two package managers"
msgstr ""

#: ../../using/selecting.md:30 da73bc3de3c1416bbec5993702fe7359
msgid ""
"[conda](https://github.com/conda/conda): \"cross-platform, language-"
"agnostic binary package manager\"."
msgstr ""

#: ../../using/selecting.md:31 4387084d1f004016a7431f1204f82455
msgid ""
"[mamba](https://github.com/mamba-org/mamba): \"reimplementation of the "
"conda package manager in C++\". We use this package manager by default "
"when installing packages."
msgstr ""

#: ../../using/selecting.md:32 c8d3604bce2e48d1abd794bb7486ff6a
msgid "`notebook`, `jupyterhub` and `jupyterlab` packages"
msgstr ""

# c5732a5536554f91b8dd7e8946beaab8
#: ../../using/selecting.md:33 7fe258c7f2a54f60ac4523a9ce815019
msgid "No preinstalled scientific computing packages"
msgstr ""

#: ../../using/selecting.md:34 3883bc6e23e64301a92e688f68a865ae
msgid ""
"Unprivileged user `jovyan` (`uid=1000`, configurable, see options) in "
"group `users` (`gid=100`) with ownership over the `/home/jovyan` and "
"`/opt/conda` paths"
msgstr ""

#: ../../using/selecting.md:36 35738c5c49404265a60d7ba55325c7fe
msgid ""
"`tini` as the container entrypoint and a `start-notebook.sh` script as "
"the default command"
msgstr ""

#: ../../using/selecting.md:37 ee78904f717641f0b11de6cac644e15e
msgid ""
"A `start-singleuser.sh` script useful for launching containers in "
"JupyterHub"
msgstr ""

#: ../../using/selecting.md:38 945f17c2d25f428a934cae2d3779f301
msgid ""
"A `start.sh` script useful for running alternative commands in the "
"container (e.g. `ipython`, `jupyter kernelgateway`, `jupyter lab`)"
msgstr ""

# 075e6ffe0f5b4d508d555992f5dd6fe1
#: ../../using/selecting.md:39 83ebc11446e74d299f79db15af3d1947
msgid "Options for a self-signed HTTPS certificate and passwordless sudo"
msgstr ""

#: ../../using/selecting.md:41 8a96f87953ca42d7bdb2ddff38128ece
msgid "jupyter/minimal-notebook"
msgstr ""

#: ../../using/selecting.md:43 f4c4e28b899b4b51b14a64af105c81fb
msgid ""
"[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/master"
"/minimal-notebook) | [Dockerfile commit "
"history](https://github.com/jupyter/docker-stacks/commits/master/minimal-"
"notebook/Dockerfile) | [Docker Hub image "
"tags](https://hub.docker.com/r/jupyter/minimal-notebook/tags/)"
msgstr ""

#: ../../using/selecting.md:47 039314811c954235adaf32c418674148
msgid ""
"`jupyter/minimal-notebook` adds command line tools useful when working in"
" Jupyter applications."
msgstr ""

#: ../../using/selecting.md:49 ad198e2ad38a4b6bbd43e1a29e50392a
msgid "Everything in `jupyter/base-notebook`"
msgstr ""

#: ../../using/selecting.md:50 16dfdae3cec84c98935bb3f1630a6fce
msgid "[TeX Live](https://www.tug.org/texlive/) for notebook document conversion"
msgstr ""

#: ../../using/selecting.md:51 4ca3fe3385c94955b6f0e61477d01ee9
msgid ""
"[git](https://git-scm.com/), [vi](https://www.vim.org) (actually `vim-"
"tiny`), [nano](https://www.nano-editor.org/) (actually `nano-tiny`), "
"`tzdata`, and `unzip`"
msgstr ""

#: ../../using/selecting.md:55 9e319d18593d4bf5b96b30459b668657
msgid "jupyter/r-notebook"
msgstr ""

#: ../../using/selecting.md:57 341d646c7c7c4544ba8ab2271f774ad3
msgid ""
"[Source on GitHub](https://github.com/jupyter/docker-"
"stacks/tree/master/r-notebook) | [Dockerfile commit "
"history](https://github.com/jupyter/docker-"
"stacks/commits/master/r-notebook/Dockerfile) | [Docker Hub image "
"tags](https://hub.docker.com/r/jupyter/r-notebook/tags/)"
msgstr ""

#: ../../using/selecting.md:61 9943292e58fb4fac8117f258a3f62a04
msgid "`jupyter/r-notebook` includes popular packages from the R ecosystem."
msgstr ""

#: ../../using/selecting.md:63 ../../using/selecting.md:94
#: 0888bd44c17b4e4a9f4b53d8530bc1fe d4d2e78accaa4a36acf5f79e1304e250
msgid "Everything in `jupyter/minimal-notebook` and its ancestor images"
msgstr ""

#: ../../using/selecting.md:64 3872adbcd8524d5cb2497d00217525f4
msgid "The [R](https://www.r-project.org/) interpreter and base environment"
msgstr ""

#: ../../using/selecting.md:65 ../../using/selecting.md:179
#: 557fef4776f34276a2c9e810effdad38 f27888a4244e498eade55fa83b28b891
msgid ""
"[IRKernel](https://irkernel.github.io/) to support R code in Jupyter "
"notebooks"
msgstr ""

#: ../../using/selecting.md:66 0e527e721629475381322c2ab4df880f
msgid ""
"[tidyverse](https://www.tidyverse.org/) packages from [conda-forge](https"
"://conda-forge.org/feedstock-outputs/index.html)"
msgstr ""

#: ../../using/selecting.md:68 fbb85d6a4ea2472e960df8dece9a527d
msgid ""
"[caret](https://topepo.github.io/caret/index.html), "
"[crayon](https://cran.r-project.org/web/packages/crayon/index.html), "
"[devtools](https://cran.r-project.org/web/packages/devtools/index.html), "
"[forecast](https://cran.r-project.org/web/packages/forecast/index.html), "
"[hexbin](https://cran.r-project.org/web/packages/hexbin/index.html), "
"[htmltools](https://cran.r-project.org/web/packages/htmltools/index.html),"
" [htmlwidgets](https://www.htmlwidgets.org), "
"[nycflights13](https://cran.r-project.org/web/packages/nycflights13/index.html),"
" "
"[randomforest](https://cran.r-project.org/web/packages/randomForest/index.html),"
" [rcurl](https://cran.r-project.org/web/packages/RCurl/index.html), "
"[rmarkdown](https://rmarkdown.rstudio.com), "
"[rodbc](https://cran.r-project.org/web/packages/RODBC/index.html), "
"[rsqlite](https://cran.r-project.org/web/packages/RSQLite/index.html), "
"[shiny](https://shiny.rstudio.com/), "
"[tidymodels](https://www.tidymodels.org/), "
"[unixodbc](http://www.unixodbc.org) packages from [conda-forge](https"
"://conda-forge.org/feedstock-outputs/index.html)"
msgstr ""

#: ../../using/selecting.md:86 54ac4429c09c479dbf31b0c6448a31b9
msgid "jupyter/scipy-notebook"
msgstr ""

#: ../../using/selecting.md:88 eb9aac83127041a88b3a997fad834c2c
msgid ""
"[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/master"
"/scipy-notebook) | [Dockerfile commit history](https://github.com/jupyter"
"/docker-stacks/commits/master/scipy-notebook/Dockerfile) | [Docker Hub "
"image tags](https://hub.docker.com/r/jupyter/scipy-notebook/tags/)"
msgstr ""

#: ../../using/selecting.md:92 6b4eb0fead8b48888830420e2ca1863f
msgid ""
"`jupyter/scipy-notebook` includes popular packages from the scientific "
"Python ecosystem."
msgstr ""

#: ../../using/selecting.md:95 8180f8d50026430aa7816f13c1217462
msgid ""
"[altair](https://altair-viz.github.io), "
"[beautifulsoup4](https://www.crummy.com/software/BeautifulSoup/), "
"[bokeh](https://docs.bokeh.org/en/latest/), "
"[bottleneck](https://bottleneck.readthedocs.io/en/latest/), "
"[cloudpickle](https://github.com/cloudpipe/cloudpickle), [conda-"
"forge::blas=\\*=openblas](https://www.openblas.net), "
"[cython](https://cython.org), [dask](https://dask.org/), "
"[dill](https://pypi.org/project/dill/), [h5py](https://www.h5py.org), "
"[matplotlib-base](https://matplotlib.org/), "
"[numba](https://numba.pydata.org/), "
"[numexpr](https://github.com/pydata/numexpr), "
"[pandas](https://pandas.pydata.org/), "
"[patsy](https://patsy.readthedocs.io/en/latest/), "
"[protobuf](https://developers.google.com/protocol-"
"buffers/docs/pythontutorial), [pytables](https://www.pytables.org/), "
"[scikit-image](https://scikit-image.org), [scikit-learn](https://scikit-"
"learn.org/stable/), [scipy](https://www.scipy.org/), "
"[seaborn](https://seaborn.pydata.org/), "
"[sqlalchemy](https://www.sqlalchemy.org/), "
"[statsmodel](https://www.statsmodels.org/stable/index.html), "
"[sympy](https://www.sympy.org/en/index.html), "
"[widgetsnbextension](https://ipywidgets.readthedocs.io/en/latest/user_install.html"
"#installing-in-classic-jupyter-notebook), [xlrd](https://www.python-"
"excel.org) packages"
msgstr ""

#: ../../using/selecting.md:122 b35d6348286d45339f7636151933f609
msgid ""
"[ipympl](https://github.com/matplotlib/ipympl) and "
"[ipywidgets](https://ipywidgets.readthedocs.io/en/stable/) for "
"interactive visualizations and plots in Python notebooks"
msgstr ""

#: ../../using/selecting.md:125 9dcb935461ef48708ad90cd204e410dd
msgid ""
"[Facets](https://github.com/PAIR-code/facets) for visualizing machine "
"learning datasets"
msgstr ""

#: ../../using/selecting.md:128 68115c6817c9426ca7fbbe68b81ef870
msgid "jupyter/tensorflow-notebook"
msgstr ""

#: ../../using/selecting.md:130 2c616917367849f3983f64ce41be490f
msgid ""
"[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/master"
"/tensorflow-notebook) | [Dockerfile commit "
"history](https://github.com/jupyter/docker-stacks/commits/master"
"/tensorflow-notebook/Dockerfile) | [Docker Hub image "
"tags](https://hub.docker.com/r/jupyter/tensorflow-notebook/tags/)"
msgstr ""

#: ../../using/selecting.md:134 c4d8a1a0b77e4fd9adee99e6e10c277d
msgid ""
"`jupyter/tensorflow-notebook` includes popular Python deep learning "
"libraries."
msgstr ""

#: ../../using/selecting.md:136 ../../using/selecting.md:166
#: 1f3867dac61c4037b04c33d29db705cc 7671efe0be5c4832b9abada1ef00b319
msgid "Everything in `jupyter/scipy-notebook` and its ancestor images"
msgstr ""

#: ../../using/selecting.md:137 e0d49825b2184a5eb922787744040376
msgid "[tensorflow](https://www.tensorflow.org/) machine learning library"
msgstr ""

#: ../../using/selecting.md:139 7ae1f3ff5c66428789b6e4f53f0d2b4c
msgid "jupyter/datascience-notebook"
msgstr ""

#: ../../using/selecting.md:141 e89c87f14df4451eb5791303f4a03345
msgid ""
"[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/master"
"/datascience-notebook) | [Dockerfile commit "
"history](https://github.com/jupyter/docker-stacks/commits/master"
"/datascience-notebook/Dockerfile) | [Docker Hub image "
"tags](https://hub.docker.com/r/jupyter/datascience-notebook/tags/)"
msgstr ""

#: ../../using/selecting.md:145 6d7a1c3df3f149f6bd3cab057178fc8c
msgid ""
"`jupyter/datascience-notebook` includes libraries for data analysis from "
"the Julia, Python, and R communities."
msgstr ""

#: ../../using/selecting.md:148 0303ca982acc4b76b31f56857bbf5a0d
msgid ""
"Everything in the `jupyter/scipy-notebook` and `jupyter/r-notebook` "
"images, and their ancestor images"
msgstr ""

#: ../../using/selecting.md:150 d7f16afdec744873929f24f80261cfea
msgid "[rpy2](https://rpy2.github.io/doc/latest/html/index.html) package"
msgstr ""

#: ../../using/selecting.md:151 9e49369f740a4d65b20df9364e496376
msgid "The [Julia](https://julialang.org/) compiler and base environment"
msgstr ""

#: ../../using/selecting.md:152 d338fa7b6c37426abfdc3aa65142b9d3
msgid ""
"[IJulia](https://github.com/JuliaLang/IJulia.jl) to support Julia code in"
" Jupyter notebooks"
msgstr ""

#: ../../using/selecting.md:153 660f1113a8e549d297804bdd569e1820
msgid ""
"[HDF5](https://github.com/JuliaIO/HDF5.jl), "
"[Gadfly](https://gadflyjl.org/stable/), "
"[RDatasets](https://github.com/JuliaStats/RDatasets.jl) packages"
msgstr ""

#: ../../using/selecting.md:158 c7a1eb0a32f64db2b1340d8d06b4cc8b
msgid "jupyter/pyspark-notebook"
msgstr ""

#: ../../using/selecting.md:160 e7135524f96048dabf5548f4515e2ffc
msgid ""
"[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/master"
"/pyspark-notebook) | [Dockerfile commit "
"history](https://github.com/jupyter/docker-stacks/commits/master/pyspark-"
"notebook/Dockerfile) | [Docker Hub image "
"tags](https://hub.docker.com/r/jupyter/pyspark-notebook/tags/)"
msgstr ""

#: ../../using/selecting.md:164 70d547de627c4b5093bf0adaff2d8366
msgid "`jupyter/pyspark-notebook` includes Python support for Apache Spark."
msgstr ""

#: ../../using/selecting.md:167 190ccd4cf0f44804be8f52f2a84a706e
msgid "[Apache Spark](https://spark.apache.org/) with Hadoop binaries"
msgstr ""

#: ../../using/selecting.md:168 4f5d2b81044a4e698286b051e4d20d18
msgid "[pyarrow](https://arrow.apache.org/docs/python/) library"
msgstr ""

#: ../../using/selecting.md:170 9e5c9b48d4bc4113a78a20cfd7b13834
msgid "jupyter/all-spark-notebook"
msgstr ""

#: ../../using/selecting.md:172 030bcc2fb15a485a846b19e29ab16b6d
msgid ""
"[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/master"
"/all-spark-notebook) | [Dockerfile commit "
"history](https://github.com/jupyter/docker-stacks/commits/master/all-"
"spark-notebook/Dockerfile) | [Docker Hub image "
"tags](https://hub.docker.com/r/jupyter/all-spark-notebook/tags/)"
msgstr ""

#: ../../using/selecting.md:176 24539a12b8b14d4998a1b9e3526b1949
msgid ""
"`jupyter/all-spark-notebook` includes Python, R, and Scala support for "
"Apache Spark."
msgstr ""

#: ../../using/selecting.md:178 4dc83513713c4292a0c522a7a350eca0
msgid "Everything in `jupyter/pyspark-notebook` and its ancestor images"
msgstr ""

#: ../../using/selecting.md:180 1f6a71f4a78745ea8e3e6889f5c671cb
msgid ""
"[rcurl](https://cran.r-project.org/web/packages/RCurl/index.html), "
"[sparklyr](https://spark.rstudio.com), "
"[ggplot2](https://ggplot2.tidyverse.org) packages"
msgstr ""

#: ../../using/selecting.md:184 9506628e267343278ac46ce4b23ca320
msgid ""
"[spylon-kernel](https://github.com/vericast/spylon-kernel) to support "
"Scala code in Jupyter notebooks"
msgstr ""

#: ../../using/selecting.md:186 aa79276bde9242388270e4cb217e6d9d
msgid "Image Relationships"
msgstr ""

#: ../../using/selecting.md:188 1420f16934ed47b59e99f2431c7a232d
msgid ""
"The following diagram depicts the build dependency tree of the core "
"images. (i.e., the `FROM` statements in their Dockerfiles). Any given "
"image inherits the complete content of all ancestor images pointing to "
"it."
msgstr ""

#: ../../using/selecting.md:191 9e2428b064ab40f6be5be42c3a867f46
msgid ""
"[![Image inheritance "
"diagram](../images/inherit.svg)](http://interactive.blockdiag.com/?compression=deflate&src"
"=eJyFzTEPgjAQhuHdX9Gws5sQjGzujsaYKxzmQrlr2msMGv-"
"71K0srO_3XGud9NNA8DSfgzESCFlBSdi0xkvQAKTNugw4QnL6GIU10hvX-"
"Zh7Z24OLLq2SjaxpvP10lX35vCf6pOxELFmUbQiUz4oQhYzMc3gCrRt2cWe_FKosmSjyFHC6OS1AwdQWCtyj7sfh523_BI9hKlQ25YdOFdv5fcH0kiEMA)"
msgstr ""

#: ../../using/selecting.md:191 00491a050b7440c294a6977650428b1a
msgid "Image inheritancediagram"
msgstr ""

#: ../../using/selecting.md:194 3535fc88a61446aaac52c3afe16375f0
msgid "Builds"
msgstr ""

#: ../../using/selecting.md:196 d18b5af5e6a940358641687add6b0088
msgid ""
"Every Monday and whenever a pull requests is merged, images are rebuilt "
"and pushed to the public container registry."
msgstr ""

#: ../../using/selecting.md:198 be1563729beb4f67b58c674bc9a93d03
msgid "Versioning via image tags"
msgstr ""

#: ../../using/selecting.md:200 57101158d3b74d28b60bb485c87a6597
msgid ""
"Whenever a docker image is pushed to the container registry, it is tagged"
" with:"
msgstr ""

#: ../../using/selecting.md:202 6d835c7905d346768f79da6a7b0fc48c
msgid "a `latest` tag"
msgstr ""

#: ../../using/selecting.md:203 f36ed595f8d74bbdae2db6f8e95bbff9
msgid "a 12-character git commit SHA like `b9f6ce795cfc`"
msgstr ""

#: ../../using/selecting.md:204 af58a1c653a14588b861ac830bda9693
msgid "a date formatted like `2021-08-29`"
msgstr ""

#: ../../using/selecting.md:205 60e4c58bb4084f38b22d6da7ce76d2d4
msgid "a set of software version tags like `python-3.9.6` and `lab-3.0.16`"
msgstr ""

#: ../../using/selecting.md:207 a46f361da64d42389da4a74b5b804258
msgid ""
"For stability and reproducibility, you should either reference a date "
"formatted tag from a date before the current date (in UTC time) or a git "
"commit SHA older than the latest git commit SHA in the default branch of "
"the jupyter/docker-stacks GitHub repository."
msgstr ""

#: ../../using/selecting.md:212 271b38bfd70141558ecb62c540421903
msgid "Community Stacks"
msgstr ""

# a448d28293544f72b0e5de024b0a1ef5
#: ../../using/selecting.md:214 64b93fb2c81944b4b9b14a623286592f
msgid ""
"The core stacks are just a tiny sample of what's possible when combining "
"Jupyter with other technologies. We encourage members of the Jupyter "
"community to create their own stacks based on the core images and link "
"them below."
msgstr ""

#: ../../using/selecting.md:219 3ed2d57860a64eeb83dcf172fb5441ac
msgid ""
"[csharp-notebook is a community Jupyter Docker Stack image. Try C# in "
"Jupyter Notebooks](https://github.com/tlinnet/csharp-notebook). The image"
" includes more than 200 Jupyter Notebooks with example C# code and can "
"readily be tried online via mybinder.org. Try it on "
"[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/tlinnet"
"/csharp-notebook/master)."
msgstr ""

#: ../../using/selecting.md:219 ../../using/selecting.md:223
#: ../../using/selecting.md:236 ../../using/selecting.md:238
#: ../../using/selecting.md:242 ../../using/selecting.md:256
#: ../../using/selecting.md:260 49447604013e428aa44d62e17e47502e
#: 76d4734a7a4f45c3afd7d7a2d58c3544 940bbb6b45d14deda932ba7f687b2947
#: a5d2ef60fc7d49b2b475f292bcccf8fa b150e69415314f1d96aae07d859ed423
#: c2aaad68f6844525b350b7ec00f02388 e8c95ff4b83b411c8f0530f991c615de
msgid "Binder"
msgstr ""

#: ../../using/selecting.md:223 d5e2feb6f73740939f7aa69d30739fee
msgid ""
"[education-notebook is a community Jupyter Docker Stack "
"image](https://github.com/umsi-mads/education-notebook). The image "
"includes nbgrader and RISE on top of the datascience-notebook image. Try "
"it on "
"[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh"
"/umsi-mads/education-notebook/master)."
msgstr ""

#: ../../using/selecting.md:227 107e3caa830443d19f17a828a6cd26d9
msgid "**jamesdbrock/ihaskell-notebook**"
msgstr ""

#: ../../using/selecting.md:229 03ae13c6abf84bc59661561d39089d54
msgid ""
"[Source on GitHub](https://github.com/jamesdbrock/ihaskell-notebook) | "
"[Dockerfile commit history](https://github.com/jamesdbrock/ihaskell-"
"notebook/commits/master/Dockerfile) | [Github container "
"registry](https://github.com/jamesdbrock/ihaskell-notebook/pkgs/container"
"/ihaskell-notebook)"
msgstr ""

#: ../../using/selecting.md:233 0bf619b116e84a04a4e01d3d73dea6b4
msgid ""
"`jamesdbrock/ihaskell-notebook` is based on "
"[IHaskell](https://github.com/gibiansky/IHaskell). Includes popular "
"packages and example notebooks."
msgstr ""

#: ../../using/selecting.md:236 fc99c5c844f24506806ffc6f41f29eef
msgid ""
"Try it on "
"[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jamesdbrock"
"/learn-you-a-haskell-"
"notebook/master?urlpath=lab/tree/ihaskell_examples/ihaskell/IHaskell.ipynb)"
msgstr ""

#: ../../using/selecting.md:238 53bc05955a4c469fa43d90624e2cb5a7
msgid ""
"[java-notebook is a community Jupyter Docker Stack "
"image](https://github.com/jbindinga/java-notebook). The image includes "
"[IJava](https://github.com/SpencerPark/IJava) kernel on top of the "
"minimal-notebook image. Try it on "
"[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jbindinga"
"/java-notebook/master)."
msgstr ""

#: ../../using/selecting.md:242 37c129c84d3f48a6afe9ddf424c991e0
msgid ""
"[sage-notebook](https://github.com/sharpTrick/sage-notebook) is a "
"community Jupyter Docker Stack image with the "
"[sagemath](https://www.sagemath.org) kernel on top of the minimal-"
"notebook image. Try it on "
"[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sharpTrick"
"/sage-notebook/master)."
msgstr ""

#: ../../using/selecting.md:246 ef8bb93f98364c27b02f654390df48fe
msgid ""
"[GPU-Jupyter](https://github.com/iot-salzburg/gpu-jupyter/): Leverage "
"Jupyter Notebooks with the power of your NVIDIA GPU and perform GPU "
"calculations using Tensorflow and Pytorch in collaborative notebooks. "
"This is done by generating a Dockerfile, that consists of the "
"**nvidia/cuda** base image, the well-maintained **docker-stacks** that is"
" integrated as submodule and GPU-able libraries like **Tensorflow**, "
"**Keras** and **PyTorch** on top of it."
msgstr ""

#: ../../using/selecting.md:252 3549b9891e3744f3878c593df6c94801
msgid ""
"[PRP GPU Jupyter repo](https://gitlab.nautilus.optiputer.net/prp/jupyter-"
"stack/-/tree/prp) and "
"[Registry](https://gitlab.nautilus.optiputer.net/prp/jupyter-"
"stack/container_registry) PRP (Pacific Research Platform) maintained "
"registry for jupyter stack based on NVIDIA CUDA-enabled image. Added the "
"PRP image with Pytorch and some other python packages, and GUI Desktop "
"notebook based on <https://github.com/jupyterhub/jupyter-remote-desktop-"
"proxy>."
msgstr ""

#: ../../using/selecting.md:256 3040d050350c41fc91297fccb2565dcd
msgid ""
"[cgspatial-notebook](https://github.com/SCiO-systems/cgspatial-notebook) "
"is a community Jupyter Docker Stack image. The image includes major "
"geospatial Python & R libraries on top of the datascience-notebook image."
" Try it on "
"[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh"
"/SCiO-systems/cgspatial-notebook/master)"
msgstr ""

#: ../../using/selecting.md:260 15fb2767195048d48521c40fa9a48177
msgid ""
"[kotlin-notebook](https://github.com/knonm/kotlin-notebook) is a "
"community Jupyter Docker Stack image. The image includes [Kotlin kernel "
"for Jupyter/IPython](https://github.com/Kotlin/kotlin-jupyter) on top of "
"the `base-notebook` image. Try it on "
"[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/knonm"
"/kotlin-notebook/main)"
msgstr ""

#: ../../using/selecting.md:265 a2baab7f1d564bda8d3ac2db91a870b6
msgid ""
"See the [contributing guide](../contributing/stacks.md) for information "
"about how to create your own Jupyter Docker Stack."
msgstr ""

#: ../../using/specifics.md:1 7cc3e2a521fa42c6a48d0cb9797e65fc
msgid "Image Specifics"
msgstr ""

# 06b0d21a881140a29e17e5b9fa5598ab
#: ../../using/specifics.md:3 cc2c4ea432234a73ac93ffed21d00258
msgid "This page provides details about features specific to one or more images."
msgstr ""

#: ../../using/specifics.md:5 18b8fa09256a4713bbf408c97e9abd15
msgid "Apache Spark"
msgstr ""

#: ../../using/specifics.md:7 96c0b3d05f4e4ac597a807e32ce7b0fa
msgid "Specific Docker Image Options"
msgstr ""

#: ../../using/specifics.md:9 65f5d013295947b9bda493444036c7c6
msgid ""
"`-p 4040:4040` - The `jupyter/pyspark-notebook` and `jupyter/all-spark-"
"notebook` images open [SparkUI (Spark Monitoring and Instrumentation "
"UI)](https://spark.apache.org/docs/latest/monitoring.html) at default "
"port `4040`, this option map `4040` port inside docker container to "
"`4040` port on host machine. Note every new spark context that is created"
" is put onto an incrementing port (ie. 4040, 4041, 4042, etc.), and it "
"might be necessary to open multiple ports. For example: `docker run -d -p"
" 8888:8888 -p 4040:4040 -p 4041:4041 jupyter/pyspark-notebook`."
msgstr ""

#: ../../using/specifics.md:15 bc18d493d32048d684c30ca4fcc55c30
msgid "Build an Image with a Different Version of Spark"
msgstr ""

#: ../../using/specifics.md:17 522bb5b990ff4222aa31056f9f0b4234
msgid ""
"You can build a `pyspark-notebook` image (and also the downstream `all-"
"spark-notebook` image) with a different version of Spark by overriding "
"the default value of the following arguments at build time."
msgstr ""

#: ../../using/specifics.md:19 6fe49907c8a649fb905f76513a556b8d
msgid ""
"Spark distribution is defined by the combination of the Spark and the "
"Hadoop version and verified by the package checksum, see [Download Apache"
" Spark](https://spark.apache.org/downloads.html) and the [archive "
"repo](https://archive.apache.org/dist/spark/) for more information."
msgstr ""

#: ../../using/specifics.md:21 81261cc8955b49369e3da538004f4710
msgid "`spark_version`: The Spark version to install (`3.0.0`)."
msgstr ""

#: ../../using/specifics.md:22 f797bca9e6334a0db4a687f7a0d648d0
msgid "`hadoop_version`: The Hadoop version (`3.2`)."
msgstr ""

#: ../../using/specifics.md:23 058d4fe2fd224dea8afb084c2da19f21
msgid "`spark_checksum`: The package checksum (`BFE4540...`)."
msgstr ""

#: ../../using/specifics.md:24 63af3461469b4212936037a9d4978fac
msgid "Spark can run with different OpenJDK versions."
msgstr ""

#: ../../using/specifics.md:25 a44506faa0d941dd83fe7331af167de0
msgid ""
"`openjdk_version`: The version of (JRE headless) the OpenJDK distribution"
" (`11`), see [Ubuntu "
"packages](https://packages.ubuntu.com/search?keywords=openjdk)."
msgstr ""

#: ../../using/specifics.md:27 ae3aa10a8d364e74ab4b47e213816af2
msgid ""
"For example here is how to build a `pyspark-notebook` image with Spark "
"`2.4.7`, Hadoop `2.7` and OpenJDK `8`."
msgstr ""

#: ../../using/specifics.md:52 941a2d5419ab437a97b50d65bd23c4f9
msgid "Usage Examples"
msgstr ""

#: ../../using/specifics.md:54 6ff64307d3314b72981bdc1872bdb246
msgid ""
"The `jupyter/pyspark-notebook` and `jupyter/all-spark-notebook` images "
"support the use of [Apache Spark](https://spark.apache.org/) in Python, "
"R, and Scala notebooks. The following sections provide some examples of "
"how to get started using them."
msgstr ""

#: ../../using/specifics.md:57 3e77e0639bc04bbaa1ec504f54b6f85f
msgid "Using Spark Local Mode"
msgstr ""

#: ../../using/specifics.md:59 1f20d701dd204128b111a2ce20ee0cd9
msgid ""
"Spark **local mode** is useful for experimentation on small data when you"
" do not have a Spark cluster available."
msgstr ""

#: ../../using/specifics.md:61 978611477084415ca1c1be1b27e28c40
msgid "Local Mode in Python"
msgstr ""

#: ../../using/specifics.md:63 3e22c3d1f2b243c8ad31c364c389caf9
msgid "In a Python notebook."
msgstr ""

#: ../../using/specifics.md:78 394931c59e344a26a4c403a1d12f639b
msgid "Local Mode in R"
msgstr ""

#: ../../using/specifics.md:80 ../../using/specifics.md:170
#: 39f87c3eec004244bfc276e46fbdbca3 bfdc478cae2e40dcbcf26290583b56e9
msgid "In a R notebook with [SparkR][sparkr]."
msgstr ""

#: ../../using/specifics.md:97 ../../using/specifics.md:187
#: bd050567866f4aadb323fdf5f7e72096 e5594877a0b0434c9259b94e6bb13811
msgid "In a R notebook with [sparklyr][sparklyr]."
msgstr ""

#: ../../using/specifics.md:116 5d162054c1db41439405859c6e4ea07f
msgid "Local Mode in Scala"
msgstr ""

#: ../../using/specifics.md:118 ../../using/specifics.md:207
#: 731b47f894104c54865988d7d5c71817 79738e0e60ce47269d8df9d6b0e0ecc9
#, python-format
msgid ""
"Spylon kernel instantiates a `SparkContext` for you in variable `sc` "
"after you configure Spark options in a `%%init_spark` magic cell."
msgstr ""

#: ../../using/specifics.md:134 d780b6fa835847c0a4d5ca2c9154f478
msgid "Connecting to a Spark Cluster in Standalone Mode"
msgstr ""

#: ../../using/specifics.md:136 b662c7a6fd6a43e28bac79706a0cfc3e
msgid ""
"Connection to Spark Cluster on **[Standalone "
"Mode](https://spark.apache.org/docs/latest/spark-standalone.html)** "
"requires the following set of steps:"
msgstr ""

# 2c728588b6df4753a0c08f969364a79a
#: ../../using/specifics.md:138 61b5da5d43e1466f9f60cd11ac8af939
msgid ""
"Verify that the docker image (check the Dockerfile) and the Spark Cluster"
" which is being deployed, run the same version of Spark."
msgstr ""

#: ../../using/specifics.md:140 6f5fd6bb367c4b76924b9f139b32bd45
msgid ""
"[Deploy Spark in Standalone Mode](https://spark.apache.org/docs/latest"
"/spark-standalone.html)."
msgstr ""

#: ../../using/specifics.md:141 0531fb1e205341b4a93fd93fe9126acd
msgid ""
"Run the Docker container with `--net=host` in a location that is network "
"addressable by all of your Spark workers. (This is a [Spark networking "
"requirement](https://spark.apache.org/docs/latest/cluster-"
"overview.html#components).)"
msgstr ""

#: ../../using/specifics.md:144 893e6a85085543cd92bca0968d0ddce4
msgid ""
"NOTE: When using `--net=host`, you must also use the flags `--pid=host -e"
" TINI_SUBREAPER=true`. See <https://github.com/jupyter/docker-"
"stacks/issues/64> for details."
msgstr ""

#: ../../using/specifics.md:147 29e9dd8c345c4d0d8e410f198a4a2767
msgid ""
"**Note**: In the following examples we are using the Spark master URL "
"`spark://master:7077` that shall be replaced by the URL of the Spark "
"master."
msgstr ""

#: ../../using/specifics.md:149 6aa57652080a4b8795535361aab6a68d
msgid "Standalone Mode in Python"
msgstr ""

#: ../../using/specifics.md:151 160f713b280a4efda58df4da22640398
msgid ""
"The **same Python version** needs to be used on the notebook (where the "
"driver is located) and on the Spark workers. The python version used at "
"driver and worker side can be adjusted by setting the environment "
"variables `PYSPARK_PYTHON` and / or `PYSPARK_DRIVER_PYTHON`, see [Spark "
"Configuration][spark-conf] for more information."
msgstr ""

#: ../../using/specifics.md:168 9570b4e574e94a93b99b09052f02dcef
msgid "Standalone Mode in R"
msgstr ""

#: ../../using/specifics.md:205 02f20020ed4a40308e629d1846a61e37
msgid "Standalone Mode in Scala"
msgstr ""

#: ../../using/specifics.md:223 51395f27ca544e53b0c1f2da2b893061
msgid "Define Spark Dependencies"
msgstr ""

#: ../../using/specifics.md:225 eeb8fa128111423c80b11e1ba4651863
msgid ""
"Spark dependencies can be declared thanks to the `spark.jars.packages` "
"property (see [Spark "
"Configuration](https://spark.apache.org/docs/latest/configuration.html"
"#runtime-environment) for more information)."
msgstr ""

#: ../../using/specifics.md:228 cb059983e0994bd683f6329d32793422
msgid ""
"They can be defined as a comma-separated list of Maven coordinates at the"
" creation of the Spark session."
msgstr ""

#: ../../using/specifics.md:243 6a99406efe6448c3a5cd6656f3abc9ad
msgid ""
"Dependencies can also be defined in the `spark-defaults.conf`. However, "
"it has to be done by `root` so it should only be considered to build "
"custom images."
msgstr ""

#: ../../using/specifics.md:252 b1df5b875e0746868693a3843287b7f1
msgid ""
"Jars will be downloaded dynamically at the creation of the Spark session "
"and stored by default in `${HOME}/.ivy2/jars` (can be changed by setting "
"`spark.jars.ivy`)."
msgstr ""

#: ../../using/specifics.md:254 eb58994845bb43ed8b9bbda11979303d
msgid ""
"_Note: This example is given for "
"[Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/hadoop/current/install.html)._"
msgstr ""

#: ../../using/specifics.md:256 b7e3cdee12b8428d81ffb849b024a3d9
msgid "Tensorflow"
msgstr ""

#: ../../using/specifics.md:258 178991fbe2204b3189680cf82050f6ef
msgid ""
"The `jupyter/tensorflow-notebook` image supports the use of "
"[Tensorflow](https://www.tensorflow.org/) in single machine or "
"distributed mode."
msgstr ""

#: ../../using/specifics.md:261 5cf71cd115fa4519bf93e63dff848a13
msgid "Single Machine Mode"
msgstr ""

#: ../../using/specifics.md:275 443cd41bc4b4466c8004ecd7258e9470
msgid "Distributed Mode"
msgstr ""

# 5e06096348924f51881d05f984e91381
#~ msgid "This list only has 2 examples. You can be the next!"
#~ msgstr ""

# 7ed4a7919dfd446c817c64a7e420e95e
#~ msgid ""
#~ "To use a requirements.txt file, first"
#~ " create your requirements.txt file with "
#~ "the listing of packages desired.  Next,"
#~ " create a new Dockerfile like the "
#~ "one shown below."
#~ msgstr ""

# 56f2354437c74650a70bd154647eed26
#~ msgid ""
#~ "Here is a quick example NGINX "
#~ "configuration to get started.  You'll "
#~ "need a server, a .crt and .key "
#~ "file for your server, and docker &"
#~ " docker-compose installed.  Then just "
#~ "download the files at that gist "
#~ "and run docker-compose up -d to"
#~ " test it out.  Customize the "
#~ "nginx.conf file to set the desired "
#~ "paths and add other services."
#~ msgstr ""

#~ msgid ""
#~ "You must refer to git-SHA image"
#~ " tags when stability and reproducibility"
#~ " are important in your work. (e.g."
#~ " FROM jupyter/scipy-notebook:7c45ec67c8e7, docker"
#~ " run -it --rm jupyter/scipy-"
#~ "notebook:7c45ec67c8e7). You should only use"
#~ " latest when a one-off container "
#~ "instance is acceptable (e.g., you want"
#~ " to briefly try a new library "
#~ "in a notebook)."
#~ msgstr ""

# 577f93f6511a4b17afcef782def7f802
#~ msgid "ipywidgets for interactive visualizations in Python notebooks"
#~ msgstr ""

#~ msgid ""
#~ "You must refer to git-SHA image"
#~ " tags when stability and reproducibility"
#~ " are important in your work. (e.g."
#~ " FROM jupyter/scipy-notebook:7c45ec67c8e7, docker"
#~ " run  -it --rm jupyter/scipy-"
#~ "notebook:7c45ec67c8e7). You should only use"
#~ " latest when a one-off container "
#~ "instance is acceptable (e.g., you want"
#~ " to briefly try a new library "
#~ "in a notebook)."
#~ msgstr ""

# 909f17eb57bc4e4e8df8216423d9c008
#~ msgid ""
#~ "You should only enable sudo if you"
#~ " trust the user and/or if the "
#~ "container is running on an isolated "
#~ "host."
#~ msgstr ""

# 7c56c3891bd94336b21fc82d5aeab6ae
#~ msgid "Common Features"
#~ msgstr ""

# bf4e4ace24d144538edc1d9a2605cfef
#~ msgid ""
#~ "A container launched from any Jupyter"
#~ " Docker Stacks image runs a Jupyter"
#~ " Notebook server by default. The "
#~ "container does so by executing a "
#~ "start-notebook.sh script. This script "
#~ "configures the internal container environment"
#~ " and then runs jupyter notebook, "
#~ "passing it any command line arguments"
#~ " received."
#~ msgstr ""

# 056d2f8a9a4343668131dfb9de71838a
#~ msgid "Notebook Options"
#~ msgstr ""

# d1c32336e1f545d496f7a411fb18cb4e
#~ msgid ""
#~ "You can pass Jupyter command line "
#~ "options to the start-notebook.sh script"
#~ " when launching the container. For "
#~ "example, to secure the Notebook server"
#~ " with a custom password hashed using"
#~ " IPython.lib.passwd() instead of the "
#~ "default token, you can run the "
#~ "following:"
#~ msgstr ""

# 58ad38b4300449da805bc67e73be5fd0
#~ msgid "Docker Options"
#~ msgstr ""

# 0118197966504e3ab1c03a0c49e68c97
#~ msgid ""
#~ "You may instruct the start-notebook.sh"
#~ " script to customize the container "
#~ "environment before launching the notebook "
#~ "server. You do so by passing "
#~ "arguments to the docker run command."
#~ msgstr ""

# 391efc925af248fa9bfa2220bdf0730b
#~ msgid ""
#~ "-e NB_USER=jovyan - Instructs the "
#~ "startup script to change the default "
#~ "container username from jovyan to the"
#~ " provided value. Causes the script to"
#~ " rename the jovyan user home folder."
#~ " For this option to take effect, "
#~ "you must run the container with "
#~ "--user root and set the working "
#~ "directory -w /home/$NB_USER. This feature "
#~ "is useful when mounting host volumes "
#~ "with specific home folder."
#~ msgstr ""

# 97929e34ea254dd289e235276b72068f
#~ msgid ""
#~ "-e NB_UID=1000 - Instructs the startup"
#~ " script to switch the numeric user"
#~ " ID of $NB_USER to the given "
#~ "value. This feature is useful when "
#~ "mounting host volumes with specific "
#~ "owner permissions. For this option to"
#~ " take effect, you must run the "
#~ "container with --user root. (The startup"
#~ " script will su $NB_USER after "
#~ "adjusting the user ID.) You might "
#~ "consider using modern Docker options "
#~ "--user and --group-add instead. See "
#~ "the last bullet below for details."
#~ msgstr ""

# 71cac0c045d342008ca80ce23ef32431
#~ msgid ""
#~ "-e NB_GID=100 - Instructs the startup"
#~ " script to change the primary group"
#~ " of$NB_USER to $NB_GID (the new group"
#~ " is added with a name of "
#~ "$NB_GROUP if it is defined, otherwise"
#~ " the group is named $NB_USER).  This"
#~ " feature is useful when mounting host"
#~ " volumes with specific group permissions."
#~ " For this option to take effect, "
#~ "you must run the container with "
#~ "--user root. (The startup script will"
#~ " su $NB_USER after adjusting the "
#~ "group ID.) You might consider using "
#~ "modern Docker options --user and "
#~ "--group-add instead. See the last "
#~ "bullet below for details.  The user "
#~ "is added to supplemental group users "
#~ "(gid 100) in order to allow write"
#~ " access to the home directory and "
#~ "/opt/conda.  If you override the "
#~ "user/group logic, ensure the user stays"
#~ " in group users if you want "
#~ "them to be able to modify files"
#~ " in the image."
#~ msgstr ""

# 5ca13bdafc214f8b997ca2752592f1be
#~ msgid ""
#~ "-e NB_GROUP=<name> - The name used "
#~ "for $NB_GID, which defaults to $NB_USER."
#~ "  This is only used if $NB_GID "
#~ "is specified and completely optional: "
#~ "there is only cosmetic effect."
#~ msgstr ""

# 4d57d0bd85ae417687747831670ec35f
#~ msgid ""
#~ "-e NB_UMASK=<umask> - Configures Jupyter "
#~ "to use a different umask value "
#~ "from default, i.e. 022. For example, "
#~ "if setting umask to 002, new files"
#~ " will be readable and writable by "
#~ "group members instead of just writable"
#~ " by the owner. Wikipedia has a "
#~ "good article about umask. Feel free "
#~ "to read it in order to choose "
#~ "the value that better fits your "
#~ "needs. Default value should fit most "
#~ "situations. Note that NB_UMASK when set"
#~ " only applies to the Jupyter process"
#~ " itself - you cannot use it to"
#~ " set a umask for additional files "
#~ "created during run-hooks e.g. via "
#~ "pip or conda - if you need "
#~ "to set a umask for these you "
#~ "must set umask for each command."
#~ msgstr ""

# 580637e7f00d4a36b69ce3f6ec43370e
#~ msgid ""
#~ "-e CHOWN_HOME=yes - Instructs the "
#~ "startup script to change the $NB_USER"
#~ " home directory owner and group to"
#~ " the current value of $NB_UID and "
#~ "$NB_GID. This change will take effect"
#~ " even if the user home directory "
#~ "is mounted from the host using -v"
#~ " as described below. The change is"
#~ " not applied recursively by default. "
#~ "You can change modify the chown "
#~ "behavior by setting CHOWN_HOME_OPTS (e.g., "
#~ "-e CHOWN_HOME_OPTS='-R')."
#~ msgstr ""

# 42bbfaf32b43482ba99263a74b383ac3
#~ msgid ""
#~ "-e CHOWN_EXTRA=\"<some dir>,<some other dir>\""
#~ " - Instructs the startup script to"
#~ " change the owner and group of "
#~ "each comma-separated container directory "
#~ "to the current value of $NB_UID "
#~ "and $NB_GID. The change is not "
#~ "applied recursively by default. You can"
#~ " change modify the chown behavior by"
#~ " setting CHOWN_EXTRA_OPTS (e.g., -e "
#~ "CHOWN_EXTRA_OPTS='-R')."
#~ msgstr ""

# 399a6318e3724410a4dcc93cc9d8736d
#~ msgid ""
#~ "-e GRANT_SUDO=yes - Instructs the "
#~ "startup script to grant the NB_USER "
#~ "user passwordless sudo capability. You "
#~ "do not need this option to allow"
#~ " the user to conda or pip "
#~ "install additional packages. This option "
#~ "is useful, however, when you wish "
#~ "to give $NB_USER the ability to "
#~ "install OS packages with apt or "
#~ "modify other root-owned files in "
#~ "the container. For this option to "
#~ "take effect, you must run the "
#~ "container with --user root. (The "
#~ "start-notebook.sh script will su $NB_USER"
#~ " after adding $NB_USER to sudoers.) "
#~ "You should only enable sudo if you"
#~ " trust the user or if the "
#~ "container is running on an isolated "
#~ "host."
#~ msgstr ""

# 3c6485fef5d44f72b4693c1a3d1ec35c
#~ msgid ""
#~ "-e GEN_CERT=yes - Instructs the startup"
#~ " script to generates a self-signed"
#~ " SSL certificate and configure Jupyter "
#~ "Notebook to use it to accept "
#~ "encrypted HTTPS connections."
#~ msgstr ""

# efe931ecaeac4348a6f0112a65371306
#~ msgid ""
#~ "-e JUPYTER_ENABLE_LAB=yes - Instructs the "
#~ "startup script to run jupyter lab "
#~ "instead of the default jupyter notebook"
#~ " command. Useful in container orchestration"
#~ " environments where setting environment "
#~ "variables is easier than change command"
#~ " line parameters."
#~ msgstr ""

# fe40b3a059e54a53a7a5fde86441ae72
#~ msgid ""
#~ "-e RESTARTABLE=yes - Runs Jupyter in "
#~ "a loop so that quitting Jupyter "
#~ "does not cause the container to "
#~ "exit.  This may be useful when you"
#~ " need to install extensions that "
#~ "require restarting Jupyter."
#~ msgstr ""

# bb82e70358e7452d86eb1b8e971fbf27
#~ msgid ""
#~ "-v /some/host/folder/for/work:/home/jovyan/work - "
#~ "Mounts a host machine directory as "
#~ "folder in the container. Useful when "
#~ "you want to preserve notebooks and "
#~ "other work even after the container "
#~ "is destroyed. You must grant the "
#~ "within-container notebook user or group "
#~ "(NB_UID or NB_GID) write access to "
#~ "the host directory (e.g., sudo chown "
#~ "1000 /some/host/folder/for/work)."
#~ msgstr ""

# 403f8e6101534bc0951bf5bb0b03c5a0
#~ msgid ""
#~ "--user 5000 --group-add users - "
#~ "Launches the container with a specific"
#~ " user ID and adds that user to"
#~ " the users group so that it can"
#~ " modify files in the default home "
#~ "directory and /opt/conda. You can use"
#~ " these arguments as alternatives to "
#~ "setting $NB_UID and $NB_GID."
#~ msgstr ""

# 565fbbe944ed4e68a5e202eaf07d1402
#~ msgid "Startup Hooks"
#~ msgstr ""

# 70f6f3501e1b43d3a95e200c39eef8d2
#~ msgid ""
#~ "You can further customize the container"
#~ " environment by adding shell scripts "
#~ "(*.sh) to be sourced or executables "
#~ "(chmod +x) to be run to the "
#~ "paths below:"
#~ msgstr ""

# bdc8d9262aea4329b09bac1deb92d6da
#~ msgid ""
#~ "/usr/local/bin/start-notebook.d/ - handled "
#~ "before any of the standard options "
#~ "noted above are applied"
#~ msgstr ""

# 786fba9678e24e3ba5ded6536dc0492a
#~ msgid ""
#~ "/usr/local/bin/before-notebook.d/ - handled "
#~ "after all of the standard options "
#~ "noted above are applied and just "
#~ "before the notebook server launches"
#~ msgstr ""

# 5903b6a921cb42a9a8b6db0e9592769c
#~ msgid ""
#~ "See the run-hooks function in the"
#~ " jupyter/base-notebook start.sh script for"
#~ " execution details."
#~ msgstr ""

# ffb01f3597d1453bb0299e9a4a888757
#~ msgid "SSL Certificates"
#~ msgstr ""

# 7b1a34debd094e02930aa7197377b691
#~ msgid ""
#~ "You may mount SSL key and "
#~ "certificate files into a container and"
#~ " configure Jupyter Notebook to use "
#~ "them to accept HTTPS connections. For"
#~ " example, to mount a host folder "
#~ "containing a notebook.key and notebook.crt "
#~ "and use them, you might run the"
#~ " following:"
#~ msgstr ""

# 11ef89b3d17b4bcf827e73a7ebb13756
#~ msgid ""
#~ "The docker-stacks/examples for information "
#~ "about how to use Let's Encrypt "
#~ "certificates when you run these stacks"
#~ " on a publicly visible domain."
#~ msgstr ""

# 4a42ccc5b624431bbacdc8c1d5624fb4
#~ msgid ""
#~ "The jupyter_notebook_config.py file for how"
#~ " this Docker image generates a "
#~ "self-signed certificate."
#~ msgstr ""

# 95d9c3081fa34def82e309c53ef2147b
#~ msgid ""
#~ "The Jupyter Notebook documentation for "
#~ "best practices about securing a public"
#~ " notebook server in general."
#~ msgstr ""

# 9950b2e426414111ad46c6ba1e9d29bb
#~ msgid "Alternative Commands"
#~ msgstr ""

# 2e90717352804ebd8086eef378fa411d
#~ msgid "start.sh"
#~ msgstr ""

# 11637ea03062425e94964f2c70ed8676
#~ msgid ""
#~ "The start-notebook.sh script actually "
#~ "inherits most of its option handling "
#~ "capability from a more generic start.sh"
#~ " script. The start.sh script supports "
#~ "all of the features described above, "
#~ "but allows you to specify an "
#~ "arbitrary command to execute. For "
#~ "example, to run the text-based "
#~ "ipython console in a container, do "
#~ "the following:"
#~ msgstr ""

# 3d92501fb3b940b385ee986095610391
#~ msgid ""
#~ "This script is particularly useful when"
#~ " you derive a new Dockerfile from "
#~ "this image and install additional "
#~ "Jupyter applications with subcommands like "
#~ "jupyter console, jupyter kernelgateway, etc."
#~ msgstr ""

# ff1b1af310d54eedb852dc5eff7a4f7e
#~ msgid "Others"
#~ msgstr ""

# 127ffe0a552b4dafaa77d173883350d7
#~ msgid ""
#~ "You can bypass the provided scripts "
#~ "and specify an arbitrary start command."
#~ " If you do, keep in mind that"
#~ " features supported by the start.sh "
#~ "script and its kin will not "
#~ "function (e.g., GRANT_SUDO)."
#~ msgstr ""

# 1d8bc4b15c3044b3932e0df72dd694a7
#~ msgid "Conda Environments"
#~ msgstr ""

# 97935ba423ed4a8787f9895f00015e4b
#~ msgid ""
#~ "The default Python 3.x Conda environment"
#~ " resides in /opt/conda. The /opt/conda/bin"
#~ " directory is part of the default "
#~ "jovyan user's $PATH. That directory is"
#~ " also whitelisted for use in sudo "
#~ "commands by the start.sh script."
#~ msgstr ""

# a8fe459cc9ff43b3b2f31efd4587f145
#~ msgid ""
#~ "The jovyan user has full read/write "
#~ "access to the /opt/conda directory. You"
#~ " can use either conda or pip to"
#~ " install new packages without any "
#~ "additional permissions."
#~ msgstr ""

# 36939901b3744e3fb67d2bae58ae8e25
#~ msgid "Contributed Recipes"
#~ msgstr ""

# 8bc65b7f51f4442c95ea0dec5b4b2704
#~ msgid ""
#~ "Users sometimes share interesting ways "
#~ "of using the Jupyter Docker Stacks. "
#~ "We encourage users to contribute these"
#~ " recipes to the documentation in case"
#~ " they prove useful to other members"
#~ " of the community by submitting a "
#~ "pull request to docs/using/recipes.md. The "
#~ "sections below capture this knowledge."
#~ msgstr ""

# 7447af86f4f3438ba413a7e9cc9764e5
#~ msgid "Using sudo within a container"
#~ msgstr ""

# ed8292c31667424184fe7515a30f79cd
#~ msgid ""
#~ "Password authentication is disabled for "
#~ "the NB_USER (e.g., jovyan). This choice"
#~ " was made to avoid distributing "
#~ "images with a weak default password "
#~ "that users ~might~ will forget to "
#~ "change before running a container on "
#~ "a publicly accessible host."
#~ msgstr ""

# d22ae301bebb4857b866359ddbfb7e53
#~ msgid ""
#~ "You can grant the within-container "
#~ "NB_USER passwordless sudo access by "
#~ "adding -e GRANT_SUDO=yes and --user root"
#~ " to your Docker command line or "
#~ "appropriate container orchestrator config."
#~ msgstr ""

#~ msgid ""
#~ "You should only enable sudo if you"
#~ " trust the user and/or if the "
#~ "container is running on an isolated "
#~ "host. See Docker security documentation "
#~ "for more information about running "
#~ "containers as root."
#~ msgstr ""

# 5b38bd48b58242788cc8b581b575241a
#~ msgid "Using pip install or conda install in a Child Docker image"
#~ msgstr ""

# c35347a79a2e4a7faffe139767808965
#~ msgid ""
#~ "To use a requirements.txt file, first"
#~ " create your requirements.txt file with "
#~ "the listing of packages desired. Next,"
#~ " create a new Dockerfile like the "
#~ "one shown below."
#~ msgstr ""

# fd2320ac3001480992ab2dd80285467b
#~ msgid "Ref: docker-stacks/commit/79169618d571506304934a7b29039085e77db78c"
#~ msgstr ""

# 179407610520450ea0e4b566eac8ec96
#~ msgid "Add a Python 2.x environment"
#~ msgstr ""

# 19bf98219e344b80b68fbf7f3aa68ec6
#~ msgid ""
#~ "Python 2.x was removed from all "
#~ "images on August 10th, 2017, starting"
#~ " in tag cc9feab481f7. You can add "
#~ "a Python 2.x environment by defining "
#~ "your own Dockerfile inheriting from one"
#~ " of the images like so:"
#~ msgstr ""

# be4f7d9b615d490c87cc6393ed0fabf2
#~ msgid "Ref: https://github.com/jupyter/docker-stacks/issues/440"
#~ msgstr ""

#~ msgid "Add a Python 3.x environment"
#~ msgstr ""

#~ msgid ""
#~ "The default version of Python that "
#~ "ships with conda/ubuntu may not be "
#~ "the version you want. To add a "
#~ "conda environment with a different "
#~ "version and make it accessible to "
#~ "Jupyter, the instructions are very "
#~ "similar to Python 2.x but are "
#~ "slightly simpler (no need to switch "
#~ "to root):"
#~ msgstr ""

# 747e87a9067b4870bad5aa335ab39f7d
#~ msgid "Run JupyterLab"
#~ msgstr ""

# e062399bbaee4f1eb3ab48dcc60289b8
#~ msgid ""
#~ "JupyterLab is preinstalled as a notebook"
#~ " extension starting in tag c33a7dc0eece."
#~ msgstr ""

# 7c0f192d197143698dd371fff8fa3ceb
#~ msgid ""
#~ "Run jupyterlab using a command such "
#~ "as docker run -it --rm -p "
#~ "8888:8888 jupyter/datascience-notebook start.sh "
#~ "jupyter lab"
#~ msgstr ""

#~ msgid "Dask JupyterLab Extension"
#~ msgstr ""

#~ msgid ""
#~ "Dask JupyterLab Extension provides a "
#~ "JupyterLab extension to manage Dask "
#~ "clusters, as well as embed Dask's "
#~ "dashboard plots directly into JupyterLab "
#~ "panes. Create the Dockerfile as:"
#~ msgstr ""

#~ msgid "And build the image as:"
#~ msgstr ""

#~ msgid "Once built, run using the command:"
#~ msgstr ""

#~ msgid "Ref: https://github.com/jupyter/docker-stacks/issues/999"
#~ msgstr ""

# e7842069e6ce432b9f1a12271e0ddc24
#~ msgid "Let's Encrypt a Notebook server"
#~ msgstr ""

# 4c00785b93734066b349b42b23c312af
#~ msgid ""
#~ "See the README for the simple "
#~ "automation here https://github.com/jupyter/docker-"
#~ "stacks/tree/master/examples/make-deploy which "
#~ "includes steps for requesting and "
#~ "renewing a Let's Encrypt certificate."
#~ msgstr ""

# c386f5913a78475487e9f12c76af9032
#~ msgid "Ref: https://github.com/jupyter/docker-stacks/issues/78"
#~ msgstr ""

# dd297c8f73a44707bf02064434a50a47
#~ msgid "Slideshows with Jupyter and RISE"
#~ msgstr ""

# a1834343ae3045ea962e0efc80f69443
#~ msgid ""
#~ "RISE allows via extension to create "
#~ "live slideshows of your notebooks, with"
#~ " no conversion, adding javascript "
#~ "Reveal.js:"
#~ msgstr ""

# 6e0c67b18d3546a9ab024c5663aa8f90
#~ msgid "Credit: Paolo D. based on docker-stacks/issues/43"
#~ msgstr ""

# 6bf66d68f2e5439b8403c0dd8ded40c5
#~ msgid "xgboost"
#~ msgstr ""

# a9bc4b88bd3d4bc1a7832f31677c298a
#~ msgid "Running behind a nginx proxy"
#~ msgstr ""

# dd58dbc3b08744a0b9415448d3bdbba6
#~ msgid ""
#~ "you would prefer to access the "
#~ "notebook at a server URL with a"
#~ " path (https://example.com/jupyter) rather than"
#~ " a port (https://example.com:8888)"
#~ msgstr ""

# cffd649e66ae4efb8122522e465ce3e3
#~ msgid ""
#~ "Here is a quick example NGINX "
#~ "configuration to get started. You'll "
#~ "need a server, a .crt and .key "
#~ "file for your server, and docker &"
#~ " docker-compose installed. Then just "
#~ "download the files at that gist "
#~ "and run docker-compose up -d to"
#~ " test it out. Customize the "
#~ "nginx.conf file to set the desired "
#~ "paths and add other services."
#~ msgstr ""

# 7ba37cfc11224013a862d6519168acd0
#~ msgid "Host volume mounts and notebook errors"
#~ msgstr ""

# 0fc6706374ee4a5d98517ec02ee24a03
#~ msgid ""
#~ "If you are mounting a host "
#~ "directory as /home/jovyan/work in your "
#~ "container and you receive permission "
#~ "errors or connection errors when you "
#~ "create a notebook, be sure that "
#~ "the jovyan user (UID=1000 by default)"
#~ " has read/write access to the "
#~ "directory on the host. Alternatively, "
#~ "specify the UID of the jovyan user"
#~ " on container startup using the -e"
#~ " NB_UID option described in the "
#~ "Common Features, Docker Options section"
#~ msgstr ""

# a6c910ab798b43ee91c0af160a3aadb6
#~ msgid "Ref: https://github.com/jupyter/docker-stacks/issues/199"
#~ msgstr ""

# 908924a0b4fa44d79fbca1413a0fb296
#~ msgid "Manpage installation"
#~ msgstr ""

# fb4a0f5bc3534bd9bb8909ce6512f4dd
#~ msgid ""
#~ "Adding the documentation on top of "
#~ "an existing singleuser image wastes a"
#~ " lot of space and requires "
#~ "reinstalling every system package, which "
#~ "can take additional time and bandwidth;"
#~ " the datascience-notebook image has "
#~ "been shown to grow by almost 3GB"
#~ " when adding manapages in this way."
#~ " Enabling manpages in the base Ubuntu"
#~ " layer prevents this container bloat:"
#~ msgstr ""

# 84b7fb0b5fd748ecba457f867a0e30bf
#~ msgid ""
#~ "Be sure to check the current base"
#~ " image in base-notebook before "
#~ "building."
#~ msgstr ""

# 5764b06de0d941a585e5107f313235f4
#~ msgid "JupyterHub"
#~ msgstr ""

# fbff97a16a2a4a53a69dd2d1c7dfbe91
#~ msgid "Use JupyterHub's dockerspawner"
#~ msgstr ""

# 8b1bc94531e7490fbaa012f5c4a257bd
#~ msgid ""
#~ "Swapping out the FROM line in the"
#~ " jupyterhub/singleuser Dockerfile should be "
#~ "enough for most cases."
#~ msgstr ""

# ce864521fffa4c89b7584d24296515d5
#~ msgid ""
#~ "Credit: Justin Tyberg, quanghoc, and Min"
#~ " RK based on docker-stacks/issues/124 "
#~ "and docker-stacks/pull/185"
#~ msgstr ""

# 6a5d92e7b071449686d148be90544e64
#~ msgid "Containers with a specific version of JupyterHub"
#~ msgstr ""

# 091b62f4a91c4d87b92554795a00744c
#~ msgid ""
#~ "To use a specific version of "
#~ "JupyterHub, the version of jupyterhub in"
#~ " your image should match the version"
#~ " in the Hub itself."
#~ msgstr ""

# 67db6ce9d62f499a9d9aaf675a86cddc
#~ msgid "Credit: MinRK"
#~ msgstr ""

# d4613cff20a140cbbbacc84ada8fcd87
#~ msgid "Ref: https://github.com/jupyter/docker-stacks/issues/177"
#~ msgstr ""

# 19439bd85c2946bb89f385651f8283dc
#~ msgid "Spark"
#~ msgstr ""

# 9c295c93db724e5fb11a8f870f805f41
#~ msgid "Using PySpark with AWS S3"
#~ msgstr ""

# 59f08373c7354fa4bb5b7c10441b5d69
#~ msgid "Ref: https://github.com/jupyter/docker-stacks/issues/127"
#~ msgstr ""

# c32dccc031664268983f72ed7927beff
#~ msgid "Using Local Spark JARs"
#~ msgstr ""

# 19614ffa973f49bab235cb5ac9cdf259
#~ msgid "Ref: https://github.com/jupyter/docker-stacks/issues/154"
#~ msgstr ""

# fc70801958a34e5aa578388147a8a1fb
#~ msgid "Using spark-packages.org"
#~ msgstr ""

# 031b9633ca0849e9a9035f4fa5ec2d29
#~ msgid ""
#~ "If you'd like to use packages from"
#~ " spark-packages.org, see "
#~ "https://gist.github.com/parente/c95fdaba5a9a066efaab for "
#~ "an example of how to specify the"
#~ " package identifier in the environment "
#~ "before creating a SparkContext."
#~ msgstr ""

# 08c4d39ccfa84551af78867ab37d3f18
#~ msgid "Ref: https://github.com/jupyter/docker-stacks/issues/43"
#~ msgstr ""

# 285d9bf0eefb480386dfdcd55fd76ef5
#~ msgid "Use jupyter/all-spark-notebooks with an existing Spark/YARN cluster"
#~ msgstr ""

# 1b1c743d85d542989f6a8f2c97a588d3
#~ msgid "Credit: britishbadger from docker-stacks/issues/369"
#~ msgstr ""

# 06d2e360eccb489abeeebada6c0b41eb
#~ msgid ""
#~ "Run Jupyter Notebook/Lab inside an "
#~ "already secured environment (i.e., with "
#~ "no token)"
#~ msgstr ""

# 42dd63565c4a4f67825f675972554d34
#~ msgid "(Adapted from issue 728)"
#~ msgstr ""

# 8af2ceb1414f46e1802681695b5917f8
#~ msgid ""
#~ "The default security is very good. "
#~ "There are use cases, encouraged by "
#~ "containers, where the jupyter container "
#~ "and the system it runs within, lie"
#~ " inside the security boundary. In "
#~ "these use cases it is convenient "
#~ "to launch the server without a "
#~ "password or token. In this case, "
#~ "you should use the start.sh script "
#~ "to launch the server with no "
#~ "token:"
#~ msgstr ""

# 158396013982441e9e62402c499dfb11
#~ msgid "Enable nbextension spellchecker for markdown (or any other nbextension)"
#~ msgstr ""

# 78ba1c20de2445fb9b76ec6202e4d794
#~ msgid "Ref: https://github.com/jupyter/docker-stacks/issues/675"
#~ msgstr ""

# f66d723263124285a641f0dee8a41565
#~ msgid "Running a Container"
#~ msgstr ""

# 3a614d7e864741199c1223a26fc37c03
#~ msgid "Using the Docker CLI"
#~ msgstr ""

# 3039d667df25426b84be7ab9d920cfee
#~ msgid ""
#~ "You can launch a local Docker "
#~ "container from the Jupyter Docker Stacks"
#~ " using the Docker command line "
#~ "interface. There are numerous ways to"
#~ " configure containers using the CLI. "
#~ "The following are some common patterns."
#~ msgstr ""

# 0ea4263c502142b2b3fa7f55a917af19
#~ msgid ""
#~ "Example 1 This command pulls the "
#~ "jupyter/scipy-notebook image tagged "
#~ "2c80cf3537ca from Docker Hub if it "
#~ "is not already present on the "
#~ "local host. It then starts a "
#~ "container running a Jupyter Notebook "
#~ "server and exposes the server on "
#~ "host port 8888. The server logs "
#~ "appear in the terminal and include "
#~ "a URL to the notebook server."
#~ msgstr ""

# 402a9d9ecccb479994d2903710aabaa6
#~ msgid ""
#~ "Pressing Ctrl-C shuts down the notebook"
#~ " server but leaves the container "
#~ "intact on disk for later restart "
#~ "or permanent deletion using commands "
#~ "like the following:"
#~ msgstr ""

# fe38eef5fbe24b90ab070cefeef42230
#~ msgid ""
#~ "Example 2 This command pulls the "
#~ "jupyter/r-notebook image tagged e5c5a7d3e52d "
#~ "from Docker Hub if it is not "
#~ "already present on the local host. "
#~ "It then starts a container running "
#~ "a Jupyter Notebook server and exposes"
#~ " the server on host port 10000. "
#~ "The server logs appear in the "
#~ "terminal and include a URL to the"
#~ " notebook server, but with the "
#~ "internal container port (8888) instead "
#~ "of the the correct host port "
#~ "(10000)."
#~ msgstr ""

# d911c29555904311b29d8eb79fcb9843
#~ msgid ""
#~ "Pressing Ctrl-C shuts down the notebook"
#~ " server and immediately destroys the "
#~ "Docker container. Files written to "
#~ "~/work in the container remain touched."
#~ " Any other changes made in the "
#~ "container are lost."
#~ msgstr ""

# 718d037e82a64d69aea592f76b3f047b
#~ msgid ""
#~ "Example 3 This command pulls the "
#~ "jupyter/all-spark-notebook image currently "
#~ "tagged latest from Docker Hub if "
#~ "an image tagged latest is not "
#~ "already present on the local host. "
#~ "It then starts a container named "
#~ "notebook running a JupyterLab server and"
#~ " exposes the server on a randomly "
#~ "selected port."
#~ msgstr ""

# f9627b2638ec498ebfd06d0475e1dc4c
#~ msgid "Using Binder"
#~ msgstr ""

# 6e355acc72ca41a2aca2972df65259c7
#~ msgid ""
#~ "Binder is a service that allows "
#~ "you to create and share custom "
#~ "computing environments for projects in "
#~ "version control. You can use any "
#~ "of the Jupyter Docker Stacks images "
#~ "as a basis for a Binder-compatible"
#~ " Dockerfile. See the docker-stacks "
#~ "example and Using a Dockerfile sections"
#~ " in the Binder documentation for "
#~ "instructions."
#~ msgstr ""

# d6f8d0ee10b542488dce87b84eb48036
#~ msgid "Using JupyterHub"
#~ msgstr ""

# ef9a37b25db542dea89c9c1fb31c18cd
#~ msgid ""
#~ "You can configure JupyterHub to launcher"
#~ " Docker containers from the Jupyter "
#~ "Docker Stacks images. If you've been "
#~ "following the Zero to JupyterHub with"
#~ " Kubernetes guide, see the Use an "
#~ "existing Docker image section for "
#~ "details. If you have a custom "
#~ "JupyterHub deployment, see the Picking "
#~ "or building a Docker image instructions"
#~ " for the dockerspawner instead."
#~ msgstr ""

# bf63b713aece4a7eacc2ad77f6f47c2c
#~ msgid "Using Other Tools and Services"
#~ msgstr ""

# fcce8862fc7a41a394c1e19d35363653
#~ msgid ""
#~ "You can use the Jupyter Docker "
#~ "Stacks with any Docker-compatible "
#~ "technology (e.g., Docker Compose, docker-"
#~ "py, your favorite cloud container "
#~ "service). See the documentation of the"
#~ " tool, library, or service for "
#~ "details about how to reference, "
#~ "configure, and launch containers from "
#~ "these images."
#~ msgstr ""

# 75674f1f85cb43bcbc020de3b84f18f7
#~ msgid "Selecting an Image"
#~ msgstr ""

# 686b01e6feaf4363930c16cecff5f462
# cdbd4076608348a182dc09701223093a
#~ msgid "Core Stacks"
#~ msgstr ""

# daaad3b4f13e4c6395b0e9186c73030d
# d0275f3e7b07428a85c62db44d774d71
#~ msgid "Image Relationships"
#~ msgstr ""

# 892152661ffc4ea096ba152334ff086f
# a6f02cacf6334057bdb5eb1339411a32
#~ msgid "Community Stacks"
#~ msgstr ""

# fc2fca9d04f442e9a313123cec1174ff
#~ msgid ""
#~ "The Jupyter team maintains a set "
#~ "of Docker image definitions in the "
#~ "https://github.com/jupyter/docker-stacks GitHub "
#~ "repository. The following sections describe"
#~ " these images including their contents, "
#~ "relationships, and versioning strategy."
#~ msgstr ""

# 4e9d03b93e964d16b23b30610d17b3e2
#~ msgid "jupyter/base-notebook"
#~ msgstr ""

# f43dd3334aac4971a67e5bb833dafcb8
# 93db5d969cea480a827c0d6d028fc717
# 4ff6dbde14924b73b3a54bdb94096ba2
# da116e35b2494285abe8447ab372324b
# 6fb499ae6636492b979bad5a17733c4b
# c10b1e6040c84241a77edb90ea3306a4
# 227408f175a24d1cb70e69ca32f11434
# b8ff65660ef14b0692edbe3a2fdff42b
# b50d8b1a5d3849279bcbda725f9f8e62
#~ msgid "Source on GitHub | Dockerfile commit history | Docker Hub image tags"
#~ msgstr ""

# eea41b7365bd4751ae599beb4edfa168
#~ msgid ""
#~ "jupyter/base-notebook is a small image"
#~ " supporting the options common across "
#~ "all core stacks. It is the basis"
#~ " for all other stacks."
#~ msgstr ""

# facfb37f7fa64b85930d8f12fdeef2dd
#~ msgid ""
#~ "Minimally-functional Jupyter Notebook server"
#~ " (e.g., no pandoc for saving "
#~ "notebooks as PDFs)"
#~ msgstr ""

# e90347274dd1459383e31a40bc6685f2
#~ msgid "Miniconda Python 3.x in /opt/conda"
#~ msgstr ""

# 0396d289dcdd49788f06c18efeca5013
#~ msgid ""
#~ "Unprivileged user jovyan (uid=1000, "
#~ "configurable, see options) in group "
#~ "users (gid=100) with ownership over the"
#~ " /home/jovyan and /opt/conda paths"
#~ msgstr ""

# 0e9211b01ef94b66bad9288682e1a833
#~ msgid ""
#~ "tini as the container entrypoint and "
#~ "a start-notebook.sh script as the "
#~ "default command"
#~ msgstr ""

# e38b63a14dae4b718a94c6e0523daf1e
#~ msgid ""
#~ "A start-singleuser.sh script useful for"
#~ " launching containers in JupyterHub"
#~ msgstr ""

# 0a603f43d1b34be28d2c1002f6686fda
#~ msgid ""
#~ "A start.sh script useful for running "
#~ "alternative commands in the container "
#~ "(e.g. ipython, jupyter kernelgateway, jupyter"
#~ " lab)"
#~ msgstr ""

# 9cff5da6908e42d5a7da093ba0bfcfe7
#~ msgid "jupyter/minimal-notebook"
#~ msgstr ""

# 8596676795f142d2912833d1320aa6a0
#~ msgid ""
#~ "jupyter/minimal-notebook adds command line "
#~ "tools useful when working in Jupyter "
#~ "applications."
#~ msgstr ""

# b1167e8a2430451fbb41ea876714d541
#~ msgid "Everything in jupyter/base-notebook"
#~ msgstr ""

# c46294c22bd44a86ac08b977f060a21d
#~ msgid "Pandoc and TeX Live for notebook document conversion"
#~ msgstr ""

# ad6fec23e1bf4a42b0cafd2f15e74574
#~ msgid "git, emacs, jed, nano, tzdata, and unzip"
#~ msgstr ""

# 1c7363e9e14148f7a302b0075598590a
#~ msgid "jupyter/r-notebook"
#~ msgstr ""

# a6bc72d21b0c4102b16a38df077a48dd
#~ msgid "jupyter/r-notebook includes popular packages from the R ecosystem."
#~ msgstr ""

# bfe937844bef465081bdd0cc74064b77
# eb5808624ae249d5aa6b1b06350035dc
#~ msgid "Everything in jupyter/minimal-notebook and its ancestor images"
#~ msgstr ""

# db6a08c9a21f4e1eae1f4a7c7656a60d
#~ msgid "The R interpreter and base environment"
#~ msgstr ""

# c1cf2ef729d04aacbbf220cbe78edb07
# 486896c4482443dcb0f7408c888f29e9
#~ msgid "IRKernel to support R code in Jupyter notebooks"
#~ msgstr ""

# ce8993612e2e44aea34dedc24740025d
#~ msgid ""
#~ "tidyverse packages, including ggplot2, dplyr,"
#~ " tidyr, readr, purrr, tibble, stringr, "
#~ "lubridate, and broom from conda-forge"
#~ msgstr ""

# dcf536112dad48369dbd06c240f5b337
#~ msgid ""
#~ "plyr, devtools, shiny, rmarkdown, forecast,"
#~ " rsqlite, reshape2, nycflights13, caret, "
#~ "rcurl, and randomforest packages from "
#~ "conda-forge"
#~ msgstr ""

# 3e8e6435e2b64a9fb9be8fe252ed2f3a
#~ msgid "jupyter/scipy-notebook"
#~ msgstr ""

# 7d06f0f385c844389eabb820a73b9cf1
#~ msgid ""
#~ "jupyter/scipy-notebook includes popular "
#~ "packages from the scientific Python "
#~ "ecosystem."
#~ msgstr ""

# 9b123df88f864a9f8bd0472877a47a23
#~ msgid ""
#~ "pandas, numexpr, matplotlib, scipy, seaborn,"
#~ " scikit-learn, scikit-image, sympy, "
#~ "cython, patsy, statsmodel, cloudpickle, dill,"
#~ " numba, bokeh, sqlalchemy, hdf5, vincent,"
#~ " beautifulsoup, protobuf, and xlrd packages"
#~ msgstr ""

#~ msgid ""
#~ "ipywidgets and ipympl for interactive "
#~ "visualizations and plots in Python "
#~ "notebooks"
#~ msgstr ""

# 538f0c0d60e84ac7b96c747c780dfd9e
#~ msgid "Facets for visualizing machine learning datasets"
#~ msgstr ""

# 91f89dafe55d46219648e753b94f3054
#~ msgid "jupyter/tensorflow-notebook"
#~ msgstr ""

# 183ce48c172144bc91143bc63797512d
#~ msgid ""
#~ "jupyter/tensorflow-notebook includes popular "
#~ "Python deep learning libraries."
#~ msgstr ""

# 5406ba3cf8a644a79a678c7968ef36cc
# 7dad34e3954840d69b1c418bfdc475c5
#~ msgid "Everything in jupyter/scipy-notebook and its ancestor images"
#~ msgstr ""

# 7698f92c854b4324a3371453e3ee1878
#~ msgid "tensorflow and keras machine learning libraries"
#~ msgstr ""

# e1403de76d344f4d93bd47a91dd00428
#~ msgid "jupyter/datascience-notebook"
#~ msgstr ""

# 2bd4e59533d04b86846cea01ccf36ed4
#~ msgid ""
#~ "jupyter/datascience-notebook includes libraries "
#~ "for data analysis from the Julia, "
#~ "Python, and R communities."
#~ msgstr ""

# ba7ecdc5c2444acd86073ac84157e7cf
#~ msgid ""
#~ "Everything in the jupyter/scipy-notebook "
#~ "and jupyter/r-notebook images, and their "
#~ "ancestor images"
#~ msgstr ""

# bfa2ae2246be45fdb389767d6f74baa6
#~ msgid "The Julia compiler and base environment"
#~ msgstr ""

# 31750842f94747f4a0ebd0ca4ac8f2af
#~ msgid "IJulia to support Julia code in Jupyter notebooks"
#~ msgstr ""

# d8985019373a4360a66ce8c6e32056fa
#~ msgid "HDF5, Gadfly, and RDatasets packages"
#~ msgstr ""

# 051a6e882e974e599bc0221add5e0c50
#~ msgid "jupyter/pyspark-notebook"
#~ msgstr ""

# a1a474f29c9047d6bb99e9a41e789351
#~ msgid ""
#~ "jupyter/pyspark-notebook includes Python "
#~ "support for Apache Spark, optionally on"
#~ " Mesos."
#~ msgstr ""

# 6d585f39fb334a5c95c7f9864baea8a9
#~ msgid "Apache Spark with Hadoop binaries"
#~ msgstr ""

# 33bbd9311c5640008e775210d3f75097
#~ msgid "Mesos client libraries"
#~ msgstr ""

#~ msgid "jupyter/all-spark-notebook"
#~ msgstr ""

# 954fbce53b9d4e3c90c88a65e7d138bd
#~ msgid ""
#~ "jupyter/all-spark-notebook includes Python,"
#~ " R, and Scala support for Apache "
#~ "Spark, optionally on Mesos."
#~ msgstr ""

# 671183aa9bcb4f4ba34933a4cc0e28c0
#~ msgid "Everything in jupyter/pyspark-notebook and its ancestor images"
#~ msgstr ""

# 0114a45f63054b1e9a56aff6c04bd670
#~ msgid ""
#~ "Apache Toree and spylon-kernel to "
#~ "support Scala code in Jupyter notebooks"
#~ msgstr ""

# aa21cb83205c4045960bcfd3f3fc1542
#~ msgid "ggplot2, sparklyr, and rcurl packages"
#~ msgstr ""

# 07d86ef0562f455abb691bffeaca467f
#~ msgid ""
#~ "The following diagram depicts the build"
#~ " dependency tree of the core images."
#~ " (i.e., the FROM statements in their"
#~ " Dockerfiles). Any given image inherits "
#~ "the complete content of all ancestor "
#~ "images pointing to it."
#~ msgstr ""

# fbf5d0a65b8748a5ba1b29a0e43ce9f4
#~ msgid "Builds"
#~ msgstr ""

# 75fc61a8cc874e9196ee00f7af15bb0b
#~ msgid ""
#~ "Pull requests to the jupyter/docker-"
#~ "stacks repository trigger builds of all"
#~ " images on Travis CI. These images"
#~ " are for testing purposes only and"
#~ " are not saved for use. When "
#~ "pull requests merge to master, all "
#~ "images rebuild on Docker Cloud and "
#~ "become available to docker pull from "
#~ "Docker Hub."
#~ msgstr ""

#~ msgid "Versioning"
#~ msgstr ""

# 34b4f765c48944bd939679eeb9810497
#~ msgid ""
#~ "The latest tag in each Docker Hub"
#~ " repository tracks the master branch "
#~ "HEAD reference on GitHub. latest is "
#~ "a moving target, by definition, and "
#~ "will have backward-incompatible changes "
#~ "regularly."
#~ msgstr ""

# 7ea772c3bc1d4463b29db3b57e48be8d
#~ msgid ""
#~ "Every image on Docker Hub also "
#~ "receives a 12-character tag which "
#~ "corresponds with the git commit SHA "
#~ "that triggered the image build. You "
#~ "can inspect the state of the "
#~ "jupyter/docker-stacks repository for that "
#~ "commit to review the definition of "
#~ "the image (e.g., images with tag "
#~ "7c45ec67c8e7 were built from "
#~ "https://github.com/jupyter/docker-stacks/tree/7c45ec67c8e7)."
#~ msgstr ""

# cf34bef9989940dda5de9dc026732a4c
#~ msgid ""
#~ "csharp-notebook is a community Jupyter"
#~ " Docker Stack image. Try C# in "
#~ "Jupyter Notebooks. The image includes "
#~ "more than 200 Jupyter Notebooks with "
#~ "example C# code and can readily be"
#~ " tried online via mybinder.org. Click "
#~ "here to launch ."
#~ msgstr ""

# e5c4a7b08c2f4b34b361a923f9fb3dbd
#~ msgid ""
#~ "education-notebook is a community "
#~ "Jupyter Docker Stack image. The image"
#~ " includes nbgrader and RISE on top"
#~ " of the datascience-notebook image. "
#~ "Click here to launch it on ."
#~ msgstr ""

# 8a550c70c3454d72b976cabc1cbdf465
#~ msgid "crosscompass/ihaskell-notebook"
#~ msgstr ""

# 997dafa5bad846f49a7eee78001ed3fc
#~ msgid ""
#~ "crosscompass/ihaskell-notebook is based on "
#~ "IHaskell. Includes popular packages and "
#~ "example notebooks."
#~ msgstr ""

# 9af612ef9b1847e9a537228c2d3bc77d
#~ msgid "Try it on binder:"
#~ msgstr ""

# d514a88096544a2ca92ceaf14b1323eb
#~ msgid ""
#~ "java-notebook is a community Jupyter "
#~ "Docker Stack image. The image includes"
#~ " IJava kernel on top of the "
#~ "minimal-notebook image. Click here to "
#~ "launch it on ."
#~ msgstr ""

# e5b3d27fa68b47d4a2c02c7a039d7daf
#~ msgid ""
#~ "sage-notebook is a community Jupyter "
#~ "Docker Stack image with the sagemath "
#~ "kernel on top of the minimal-"
#~ "notebook image. Click here to launch "
#~ "it on ."
#~ msgstr ""

#~ msgid ""
#~ "GPU-Jupyter: Leverage Jupyter Notebooks "
#~ "with the power of your NVIDIA GPU"
#~ " and perform GPU calculations using "
#~ "Tensorflow and Pytorch in collaborative "
#~ "notebooks. This is done by generating"
#~ " a Dockerfile, that consists of the"
#~ " nvidia/cuda base image, the well-"
#~ "maintained docker-stacks that is "
#~ "integrated as submodule and GPU-able "
#~ "libraries like Tensorflow, Keras and "
#~ "PyTorch on top of it."
#~ msgstr ""

#~ msgid ""
#~ "cgspatial-notebook is a community "
#~ "Jupyter Docker Stack image. The image"
#~ " includes major geospatial Python & R"
#~ " libraries on top of the "
#~ "datascience-notebook image. Try it on "
#~ "binder:"
#~ msgstr ""

# f9f4ef31795249d9bf2a752dfbb27a8f
#~ msgid ""
#~ "See the contributing guide for "
#~ "information about how to create your "
#~ "own Jupyter Docker Stack."
#~ msgstr ""

# 7b67588ff359486cb64810359db6704c
#~ msgid "Image Specifics"
#~ msgstr ""

# 4e5d822c2e1a410099f1ab5831e29927
#~ msgid "Apache Spark"
#~ msgstr ""

# 433d8d99798649029dafd444253567b4
#~ msgid "Specific Docker Image Options"
#~ msgstr ""

# 70083fc71521409895897387117748bc
#~ msgid ""
#~ "-p 4040:4040 - The jupyter/pyspark-"
#~ "notebook and jupyter/all-spark-notebook "
#~ "images open SparkUI (Spark Monitoring "
#~ "and Instrumentation UI) at default port"
#~ " 4040, this option map 4040 port "
#~ "inside docker container to 4040 port "
#~ "on host machine . Note every new"
#~ " spark context that is created is "
#~ "put onto an incrementing port (ie. "
#~ "4040, 4041, 4042, etc.), and it "
#~ "might be necessary to open multiple "
#~ "ports. For example: docker run -d "
#~ "-p 8888:8888 -p 4040:4040 -p 4041:4041"
#~ " jupyter/pyspark-notebook"
#~ msgstr ""

# 2449b18de82e4d129cbd49e52ce9e522
#~ msgid "Usage Examples"
#~ msgstr ""

# ec077f84f7394baba4071d0d8a9c9dbf
#~ msgid ""
#~ "The jupyter/pyspark-notebook and jupyter"
#~ "/all-spark-notebook images support the "
#~ "use of Apache Spark in Python, R,"
#~ " and Scala notebooks. The following "
#~ "sections provide some examples of how"
#~ " to get started using them."
#~ msgstr ""

# ca35b3b020914e2eb2e877199a90d4a4
#~ msgid "Using Spark Local Mode"
#~ msgstr ""

# 2c5367b84e444a1aa504910b22ba1454
# 09d8b02687704d368a670cb243e299fb
#~ msgid "In a Python Notebook"
#~ msgstr ""

# 2b5c49ea60184570a8b50622140c22e1
# 192add33e94844f080ae03254899e2ee
#~ msgid "In a R Notebook"
#~ msgstr ""

# 80cedeb3b4514de792dba8e03b1c8774
# 5f3159414ddc427699709ddef740d6fd
#~ msgid "In a Spylon Kernel Scala Notebook"
#~ msgstr ""

# 07c9256c669b488aaa2df48676d5a188
#~ msgid ""
#~ "Spylon kernel instantiates a SparkContext "
#~ "for you in variable sc after you"
#~ " configure Spark options in a "
#~ "%%init_spark magic cell."
#~ msgstr ""

# aeec453983524d3ab59f7241cf8bac7b
# 472a48e72aaf46ca86a89e1598595045
#~ msgid "In an Apache Toree Scala Notebook"
#~ msgstr ""

# 762d164260cd4938b5f9556b29b0e171
#~ msgid ""
#~ "Apache Toree instantiates a local "
#~ "SparkContext for you in variable sc "
#~ "when the kernel starts."
#~ msgstr ""

# 8da1ef6876324b61885c5dec2c6a9cbf
#~ msgid "Connecting to a Spark Cluster on Mesos"
#~ msgstr ""

# e8c29961728146a28c6581966a2d2341
#~ msgid "Deploy Spark on Mesos."
#~ msgstr ""

# 1838d7f4481246538ca4ffe89e02ff4d
#~ msgid ""
#~ "Configure each slave with the --no-"
#~ "switch_user flag or create the $NB_USER"
#~ " account on every slave node."
#~ msgstr ""

# d4ee49cc6cb547389ed3228e74a4a67c
# 4b8c4c1e7ea441f1af4b4e0fbed73888
#~ msgid ""
#~ "Run the Docker container with --net=host"
#~ " in a location that is network "
#~ "addressable by all of your Spark "
#~ "workers. (This is a Spark networking "
#~ "requirement.)"
#~ msgstr ""

# 9a026387155e46fa8e4e1ea3f00d3a63
# 68e479d8f50e4685a0fb5de56a978347
#~ msgid ""
#~ "NOTE: When using --net=host, you must"
#~ " also use the flags --pid=host -e "
#~ "TINI_SUBREAPER=true. See https://github.com/jupyter"
#~ "/docker-stacks/issues/64 for details."
#~ msgstr ""

# 929575857ae647aebbcb721af39bdd7e
#~ msgid ""
#~ "The Apache Toree kernel automatically "
#~ "creates a SparkContext when it starts"
#~ " based on configuration information from"
#~ " its command line arguments and "
#~ "environment variables. You can pass "
#~ "information about your Mesos cluster via"
#~ " the SPARK_OPTS environment variable when"
#~ " you spawn a container."
#~ msgstr ""

# da5d5d861e914df98df9dba50fb3d66a
#~ msgid "Connecting to a Spark Cluster in Standalone Mode"
#~ msgstr ""

# d5a341bb44524a8cb33f086803daaf63
#~ msgid "Deploy Spark in Standalone Mode."
#~ msgstr ""

# 85baa5bd4ed5426b96dad49dacfab9cb
#~ msgid "Tensorflow"
#~ msgstr ""

# 4249b4b266fc4aeeb85dc8386ab60592
#~ msgid ""
#~ "The jupyter/tensorflow-notebook image supports"
#~ " the use of Tensorflow in single "
#~ "machine or distributed mode."
#~ msgstr ""

# 68fba23f7cd94702a9dead3c51719206
#~ msgid "Single Machine Mode"
#~ msgstr ""

# d4b74babe01d4a3a86c46844a737151b
#~ msgid "Distributed Mode"
#~ msgstr ""

#~ msgid ""
#~ "[git](https://git-scm.com/), "
#~ "[emacs](https://www.gnu.org/software/emacs/), "
#~ "[jed](https://www.jedsoft.org/jed/), [nano](https://www.nano-"
#~ "editor.org/), tzdata, and"
#~ msgstr ""

#~ msgid ""
#~ "Minimally-functional Jupyter Notebook server"
#~ " (e.g., no [pandoc](https://pandoc.org/) for "
#~ "saving notebooks as PDFs)"
#~ msgstr ""

#~ msgid ""
#~ "[Pandoc](http://pandoc.org) and [TeX "
#~ "Live](https://www.tug.org/texlive/) for notebook "
#~ "document conversion"
#~ msgstr ""

#~ msgid ""
#~ "[git](https://git-scm.com/), "
#~ "[emacs](https://www.gnu.org/software/emacs/), "
#~ "[vi](https://vim.org/) (actually `vim-tiny`), "
#~ "[jed](https://www.jedsoft.org/jed/), [nano](https://www.nano-"
#~ "editor.org/), tzdata, and"
#~ msgstr ""

#~ msgid "unzip"
#~ msgstr ""

#~ msgid ""
#~ "[pandas](https://pandas.pydata.org/), "
#~ "[numexpr](https://github.com/pydata/numexpr), "
#~ "[matplotlib](https://matplotlib.org/), "
#~ "[scipy](https://www.scipy.org/),"
#~ msgstr ""

#~ msgid ""
#~ "[seaborn](https://seaborn.pydata.org/), [scikit-"
#~ "learn](http://scikit-learn.org/stable/), [scikit-"
#~ "image](http://scikit-image.org/), "
#~ "[sympy](http://www.sympy.org/en/index.html), "
#~ "[cython](http://cython.org/), "
#~ "[patsy](https://patsy.readthedocs.io/en/latest/), "
#~ "[statsmodel](http://www.statsmodels.org/stable/index.html), "
#~ "[cloudpickle](https://github.com/cloudpipe/cloudpickle), "
#~ "[dill](https://pypi.python.org/pypi/dill), "
#~ "[numba](https://numba.pydata.org/), "
#~ "[bokeh](https://bokeh.pydata.org/en/latest/), "
#~ "[sqlalchemy](https://www.sqlalchemy.org/), "
#~ "[hdf5](http://www.h5py.org/), "
#~ "[vincent](http://vincent.readthedocs.io/en/latest/), "
#~ "[beautifulsoup](https://www.crummy.com/software/BeautifulSoup/), "
#~ "[protobuf](https://developers.google.com/protocol-"
#~ "buffers/docs/pythontutorial), and [xlrd](http://www"
#~ ".python-excel.org/) packages * "
#~ "[ipywidgets](https://ipywidgets.readthedocs.io/en/stable/) and"
#~ " [ipympl](https://github.com/matplotlib/jupyter-matplotlib)"
#~ " for interactive visualizations and plots"
#~ " in Python notebooks * "
#~ "[Facets](https://github.com/PAIR-code/facets) for "
#~ "visualizing machine learning datasets"
#~ msgstr ""

#~ msgid "Try it on binder: [![launch Learn You a Haskell for Great"
#~ msgstr ""

#~ msgid ""
#~ "Good!](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jamesdbrock"
#~ "/learn-you-a-haskell-"
#~ "notebook/master?urlpath=lab/tree/learn_you_a_haskell/00-preface.ipynb)"
#~ msgstr ""

#~ msgid ""
#~ "`-e NB_USER=jovyan` - Instructs the "
#~ "startup script to change the default "
#~ "container username from `jovyan` to the"
#~ " provided value. Causes the script to"
#~ " rename the `jovyan` user home "
#~ "folder. For this option to take "
#~ "effect, you must run the container "
#~ "with `--user root` and set the "
#~ "working directory `-w /home/$NB_USER`. This"
#~ " feature is useful when mounting host"
#~ " volumes with specific home folder."
#~ msgstr ""

#~ msgid ""
#~ "`jupyter/pyspark-notebook` includes Python "
#~ "support for Apache Spark, optionally on"
#~ " Mesos."
#~ msgstr ""

#~ msgid "[Mesos](http://mesos.apache.org/) client libraries"
#~ msgstr ""

#~ msgid ""
#~ "`jupyter/all-spark-notebook` includes Python,"
#~ " R, and Scala support for Apache "
#~ "Spark, optionally on Mesos."
#~ msgstr ""

#~ msgid "### Connecting to a Spark Cluster on Mesos"
#~ msgstr ""

# 4926e921fbd24baba9888b3f08cf4f51
#~ msgid "This configuration allows your compute cluster to scale with your data."
#~ msgstr ""

#~ msgid ""
#~ "[Deploy Spark on "
#~ "Mesos](http://spark.apache.org/docs/latest/running-on-"
#~ "mesos.html)."
#~ msgstr ""

#~ msgid ""
#~ "Configure each slave with [the `--no-"
#~ "switch_user` flag](https://open.mesosphere.com/reference"
#~ "/mesos-slave/) or create the `$NB_USER` "
#~ "account on every slave node."
#~ msgstr ""

# 16c4327879294075a64b4329f972321c
#~ msgid "Follow the language specific instructions below."
#~ msgstr ""

#~ msgid ""
#~ "# point to mesos master or "
#~ "zookeeper entry (e.g., zk://10.10.10.10:2181/mesos)"
#~ " conf.setMaster(\"mesos://10.10.10.10:5050\") # point"
#~ " to spark binary package in HDFS "
#~ "or on local filesystem on all "
#~ "slave # nodes (e.g., "
#~ "file:///opt/spark/spark-2.2.0-bin-hadoop2.7.tgz) "
#~ "conf.set(\"spark.executor.uri\", "
#~ "\"hdfs://10.10.10.10/spark/spark-2.2.0-bin-hadoop2.7.tgz\") "
#~ "# set other options as desired "
#~ "conf.set(\"spark.executor.memory\", \"8g\") "
#~ "conf.set(\"spark.core.connection.ack.wait.timeout\", \"1200\")"
#~ msgstr ""

#~ msgid ""
#~ "# Point to mesos master or "
#~ "zookeeper entry (e.g., zk://10.10.10.10:2181/mesos)"
#~ " # Point to spark binary package "
#~ "in HDFS or on local filesystem on"
#~ " all slave # nodes (e.g., "
#~ "file:///opt/spark/spark-2.2.0-bin-hadoop2.7.tgz) in "
#~ "sparkEnvir # Set other options in "
#~ "sparkEnvir sc <- "
#~ "sparkR.session(\"mesos://10.10.10.10:5050\", sparkEnvir=list("
#~ msgstr ""

#~ msgid ""
#~ "spark.executor.uri=\"hdfs://10.10.10.10/spark/spark-2.2.0-bin-"
#~ "hadoop2.7.tgz\", spark.executor.memory=\"8g\" )"
#~ msgstr ""

#~ msgid ""
#~ "```python %%init_spark # Configure the "
#~ "location of the mesos master and "
#~ "spark distribution on HDFS launcher.master "
#~ "= \"mesos://10.10.10.10:5050\" "
#~ "launcher.conf.spark.executor.uri=hdfs://10.10.10.10/spark/spark-2.2.0"
#~ "-bin-hadoop2.7.tgz ```"
#~ msgstr ""

#~ msgid ""
#~ "The Apache Toree kernel automatically "
#~ "creates a `SparkContext` when it starts"
#~ " based on configuration information from"
#~ " its command line arguments and "
#~ "environment variables. You can pass "
#~ "information about your Mesos cluster via"
#~ " the `SPARK_OPTS` environment variable when"
#~ " you spawn a container."
#~ msgstr ""

# 3e3d5ec9fa554e75989856139938f4f8
#~ msgid ""
#~ "For instance, to pass information about"
#~ " a Mesos master, Spark binary "
#~ "location in HDFS, and an executor "
#~ "options, you could start the container"
#~ " like so:"
#~ msgstr ""

#~ msgid ""
#~ "``` docker run -d -p 8888:8888 -e"
#~ " SPARK_OPTS='--master=mesos://10.10.10.10:5050 \\"
#~ msgstr ""

#~ msgid ""
#~ "--spark.executor.uri=hdfs://10.10.10.10/spark/spark-2.2.0-bin-"
#~ "hadoop2.7.tgz \\ --spark.executor.memory=8g' jupyter"
#~ "/all-spark-notebook"
#~ msgstr ""

# 3c781f06114240e28dcdb0c40a5d5cf5
#~ msgid ""
#~ "The language specific instructions are "
#~ "almost same as mentioned above for "
#~ "Mesos, only the master url would "
#~ "now be something like spark://10.10.10.10:7077"
#~ msgstr ""

#~ msgid ""
#~ "**Specific Docker Image Options** * `-p"
#~ " 4040:4040` - The `jupyter/pyspark-"
#~ "notebook` and `jupyter/all-spark-notebook` "
#~ "images open [SparkUI (Spark Monitoring "
#~ "and Instrumentation "
#~ "UI)](http://spark.apache.org/docs/latest/monitoring.html) at "
#~ "default port `4040`, this option map "
#~ "`4040` port inside docker container to"
#~ " `4040` port on host machine . "
#~ "Note every new spark context that "
#~ "is created is put onto an "
#~ "incrementing port (ie. 4040, 4041, 4042,"
#~ " etc.), and it might be necessary "
#~ "to open multiple ports. For example: "
#~ "`docker run -d -p 8888:8888 -p "
#~ "4040:4040 -p 4041:4041 jupyter/pyspark-"
#~ "notebook`"
#~ msgstr ""

# 15a0171869f3437481b9dfb2aec3db00
#~ msgid ""
#~ "Spark local mode is useful for "
#~ "experimentation on small data when you"
#~ " do not have a Spark cluster "
#~ "available."
#~ msgstr ""

#~ msgid "#### In a Python Notebook"
#~ msgstr ""

#~ msgid ""
#~ "```python from pyspark.sql import SparkSession"
#~ " spark = "
#~ "SparkSession.builder.appName(\"SimpleApp\").getOrCreate() # "
#~ "do something to prove it works "
#~ "spark.sql('SELECT \"Test\" as c1').show() ```"
#~ msgstr ""

#~ msgid "#### In a R Notebook"
#~ msgstr ""

#~ msgid "```r library(SparkR)"
#~ msgstr ""

#~ msgid "as <- sparkR.session(\"local[*]\")"
#~ msgstr ""

#~ msgid ""
#~ "# do something to prove it works"
#~ " df <- as.DataFrame(iris) head(filter(df, "
#~ "df$Petal_Width > 0.2)) ```"
#~ msgstr ""

#~ msgid "#### In a Spylon Kernel Scala Notebook"
#~ msgstr ""

#~ msgid ""
#~ "```python %%init_spark # Configure Spark "
#~ "to use a local master launcher.master"
#~ " = \"local[*]\" ```"
#~ msgstr ""

#~ msgid ""
#~ "```scala // Now run Scala code "
#~ "that uses the initialized SparkContext "
#~ "in sc val rdd = sc.parallelize(0 "
#~ "to 999) rdd.takeSample(false, 5) ```"
#~ msgstr ""

#~ msgid "#### In an Apache Toree Scala Notebook"
#~ msgstr ""

#~ msgid ""
#~ "```scala val rdd = sc.parallelize(0 to"
#~ " 999) rdd.takeSample(false, 5) ```"
#~ msgstr ""

# 79db0ba4244a4701aa8dfe0053d5579c
#~ msgid ""
#~ "Connection to Spark Cluster on "
#~ "Standalone Mode requires the following "
#~ "set of steps:"
#~ msgstr ""

#~ msgid ""
#~ "```python import os # make sure "
#~ "pyspark tells workers to use python3 "
#~ "not 2 if both are installed "
#~ "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'"
#~ msgstr ""

#~ msgid "import pyspark conf = pyspark.SparkConf()"
#~ msgstr ""

#~ msgid ""
#~ "# Point to spark master "
#~ "conf.setMaster(\"spark://10.10.10.10:7070\") # point "
#~ "to spark binary package in HDFS or"
#~ " on local filesystem on all slave "
#~ "# nodes (e.g., file:///opt/spark/spark-2.2.0-bin-"
#~ "hadoop2.7.tgz) conf.set(\"spark.executor.uri\", "
#~ "\"hdfs://10.10.10.10/spark/spark-2.2.0-bin-hadoop2.7.tgz\") "
#~ "# set other options as desired "
#~ "conf.set(\"spark.executor.memory\", \"8g\") "
#~ "conf.set(\"spark.core.connection.ack.wait.timeout\", \"1200\")"
#~ msgstr ""

#~ msgid "# create the context sc = pyspark.SparkContext(conf=conf)"
#~ msgstr ""

#~ msgid ""
#~ "# do something to prove it works"
#~ " rdd = sc.parallelize(range(100000000)) "
#~ "rdd.sumApprox(3) ```"
#~ msgstr ""

#~ msgid ""
#~ "# Point to spark master # Point"
#~ " to spark binary package in HDFS "
#~ "or on local filesystem on all "
#~ "worker # nodes (e.g., "
#~ "file:///opt/spark/spark-2.2.0-bin-hadoop2.7.tgz) in "
#~ "sparkEnvir # Set other options in "
#~ "sparkEnvir sc <- "
#~ "sparkR.session(\"spark://10.10.10.10:7070\", sparkEnvir=list("
#~ msgstr ""

#~ msgid ""
#~ "spark.executor.uri=\"hdfs://10.10.10.10/spark/spark-2.4.3-bin-"
#~ "hadoop2.7.tgz\", spark.executor.memory=\"8g\" )"
#~ msgstr ""

#~ msgid ""
#~ "# do something to prove it works"
#~ " data(iris) df <- as.DataFrame(iris) "
#~ "head(filter(df, df$Petal_Width > 0.2)) ```"
#~ msgstr ""

#~ msgid ""
#~ "```python %%init_spark # Point to spark"
#~ " master launcher.master = "
#~ "\"spark://10.10.10.10:7070\" "
#~ "launcher.conf.spark.executor.uri=hdfs://10.10.10.10/spark/spark-2.4.3"
#~ "-bin-hadoop2.7.tgz ```"
#~ msgstr ""

#~ msgid ""
#~ "For instance, to pass information about"
#~ " a standalone Spark master, Spark "
#~ "binary location in HDFS, and an "
#~ "executor options, you could start the"
#~ " container like so:"
#~ msgstr ""

#~ msgid ""
#~ "``` docker run -d -p 8888:8888 -e"
#~ " SPARK_OPTS='--master=spark://10.10.10.10:7070 \\"
#~ msgstr ""

#~ msgid ""
#~ "--spark.executor.uri=hdfs://10.10.10.10/spark/spark-2.4.3-bin-"
#~ "hadoop2.7.tgz \\ --spark.executor.memory=8g' jupyter"
#~ "/all-spark-notebook"
#~ msgstr ""

#~ msgid ""
#~ "// do something to prove it works"
#~ " val rdd = sc.parallelize(0 to "
#~ "99999999) rdd.sum() ```"
#~ msgstr ""

#~ msgid ""
#~ "``` docker run -d -p 8888:8888 "
#~ "jupyter/base-notebook start-notebook.sh "
#~ "--NotebookApp.password='sha1:74ba40f8a388:c913541b7ee99d15d5ed31d4226bf7838f83a50e'"
#~ " ```"
#~ msgstr ""

#~ msgid ""
#~ "``` docker run -d -p 8888:8888 "
#~ "jupyter/base-notebook start-notebook.sh "
#~ "--NotebookApp.base_url=/some/path ```"
#~ msgstr ""

#~ msgid "``` docker run -d -p 8888:8888 \\"
#~ msgstr ""

#~ msgid "``` docker run -it --rm jupyter/base-notebook start.sh ipython ```"
#~ msgstr ""

#~ msgid ""
#~ "``` docker run -it --rm -p "
#~ "8888:8888 jupyter/base-notebook start.sh "
#~ "jupyter lab ```"
#~ msgstr ""

#~ msgid ""
#~ "``` # install a package into the"
#~ " default (python 3.x) environment pip "
#~ "install some-package conda install "
#~ "some-package ```"
#~ msgstr ""

#~ msgid ""
#~ "``` docker run -it -e GRANT_SUDO=yes "
#~ "--user root jupyter/minimal-notebook ```"
#~ msgstr ""

#~ msgid "``` # Choose your desired base image FROM jupyter/scipy-notebook:latest"
#~ msgstr ""

#~ msgid ""
#~ "``` # Choose your desired base "
#~ "image FROM jupyter/minimal-notebook:latest"
#~ msgstr ""

#~ msgid ""
#~ "And build the image as: ``` docker"
#~ " build -t jupyter/scipy-dasklabextension:latest"
#~ " . ```"
#~ msgstr ""

#~ msgid ""
#~ "Once built, run using the command: "
#~ "``` docker run -it --rm -p "
#~ "8888:8888 -p 8787:8787 jupyter/scipy-"
#~ "dasklabextension:latest ```"
#~ msgstr ""

#~ msgid ""
#~ "``` # Add Live slideshows with "
#~ "RISE RUN conda install -c damianavila82"
#~ " rise ```"
#~ msgstr ""

#~ msgid "``` %%bash conda install -y gcc pip install xgboost"
#~ msgstr ""

#~ msgid ""
#~ "``` FROM  jupyter/base-notebook:5ded1de07260 "
#~ "RUN pip install jupyterhub==0.8.0b1 ```"
#~ msgstr ""

#~ msgid ""
#~ "``` import os os.environ['PYSPARK_SUBMIT_ARGS'] "
#~ "= '--jars /home/jovyan/spark-streaming-"
#~ "kafka-assembly_2.10-1.6.1.jar pyspark-shell' "
#~ "import pyspark from pyspark.streaming.kafka "
#~ "import KafkaUtils from pyspark.streaming "
#~ "import StreamingContext sc = "
#~ "pyspark.SparkContext() ssc = StreamingContext(sc,1)"
#~ " broker = \"<my_broker_ip>\" directKafkaStream"
#~ " = KafkaUtils.createDirectStream(ssc, [\"test1\"], "
#~ "{\"metadata.broker.list\": broker}) "
#~ "directKafkaStream.pprint() ssc.start() ```"
#~ msgstr ""

#~ msgid "``` FROM jupyter/all-spark-notebook"
#~ msgstr ""

#~ msgid ""
#~ "``` docker run jupyter/base-"
#~ "notebook:6d2a05346196 start.sh jupyter lab "
#~ "--LabApp.token='' ```"
#~ msgstr ""

#~ msgid ""
#~ "``` docker run jupyter/base-"
#~ "notebook:6d2a05346196 start.sh jupyter notebook "
#~ "--NotebookApp.token='' ```"
#~ msgstr ""

#~ msgid ""
#~ "``` # Update with your base image"
#~ " of choice FROM jupyter/minimal-"
#~ "notebook:latest"
#~ msgstr ""

#~ msgid ""
#~ "``` ARG BASE_CONTAINER=jupyter/scipy-notebook "
#~ "FROM jupyter/scipy-notebook:latest"
#~ msgstr ""

#~ msgid ""
#~ "Run the Docker container with "
#~ "`--net=host` in a location that is "
#~ "network addressable by all of your "
#~ "Spark workers. (This is a [Spark "
#~ "networking requirement](http://spark.apache.org/docs/latest"
#~ "/cluster-overview.html#components).)"
#~ msgstr ""

#~ msgid ""
#~ "NOTE: When using `--net=host`, you must"
#~ " also use the flags `--pid=host -e"
#~ " TINI_SUBREAPER=true`. See https://github.com/jupyter"
#~ "/docker-stacks/issues/64 for details."
#~ msgstr ""

#~ msgid ""
#~ "# Workaround for a mandb bug, "
#~ "should be fixed in mandb > 2.8.5"
#~ " # https://git.savannah.gnu.org/cgit/man-"
#~ "db.git/commit/?id=8197d7824f814c5d4b992b4c8730b5b0f7ec589a RUN"
#~ " echo \"MANPATH_MAP ${CONDA_DIR}/bin "
#~ "${CONDA_DIR}/man\" >> /etc/manpath.config \\"
#~ msgstr ""

#~ msgid ""
#~ "Adding the documentation on top of "
#~ "an existing singleuser image wastes a"
#~ " lot of space and requires "
#~ "reinstalling every system package, which "
#~ "can take additional time and bandwidth;"
#~ " the `datascience-notebook` image has "
#~ "been shown to grow by almost 3GB"
#~ " when adding manapages in this way."
#~ " Enabling manpages in the base Ubuntu"
#~ " layer prevents this container bloat:"
#~ msgstr ""

#~ msgid ""
#~ "```Dockerfile # Ubuntu 18.04 (bionic) "
#~ "from 2018-05-26 # https://github.com/docker-"
#~ "library/official-"
#~ "images/commit/aac6a45b9eb2bffb8102353c350d341a410fb169 ARG "
#~ "BASE_CONTAINER=ubuntu:bionic-20180526@sha256:c8c275751219dadad8fa56b3ac41ca6cb22219ff117ca98fe82b42f24e1ba64e"
#~ " FROM $BASE_CONTAINER"
#~ msgstr ""

#~ msgid ""
#~ "ENV DEBIAN_FRONTEND noninteractive # Remove"
#~ " the manpage blacklist, install man, "
#~ "install docs RUN rm "
#~ "/etc/dpkg/dpkg.cfg.d/excludes \\"
#~ msgstr ""

#~ msgid ""
#~ "# Workaround for a mandb bug, "
#~ "should be fixed in mandb > 2.8.5"
#~ " # https://git.savannah.gnu.org/cgit/man-"
#~ "db.git/commit/?id=8197d7824f814c5d4b992b4c8730b5b0f7ec589a RUN"
#~ " echo \"MANPATH_MAP /opt/conda/bin "
#~ "/opt/conda/man\" >> /etc/manpath.config \\"
#~ msgstr ""

#~ msgid ""
#~ "&& echo \"MANPATH_MAP /opt/conda/bin "
#~ "/opt/conda/share/man\" >> /etc/manpath.config"
#~ msgstr ""

#~ msgid ""
#~ "[tidyr](http://tidyr.tidyverse.org/), "
#~ "[readr](http://readr.tidyverse.org/), "
#~ "[purrr](http://purrr.tidyverse.org/), "
#~ "[tibble](http://tibble.tidyverse.org/), "
#~ "[stringr](http://stringr.tidyverse.org/), "
#~ "[lubridate](http://lubridate.tidyverse.org/), and "
#~ "[broom](https://cran.r-project.org/web/packages/broom/vignettes/broom.html)"
#~ " from [conda-forge](https://conda-"
#~ "forge.github.io/feedstocks) * "
#~ "[plyr](https://cran.r-project.org/web/packages/plyr/index.html), "
#~ "[devtools](https://cran.r-project.org/web/packages/devtools/index.html),"
#~ " [shiny](https://shiny.rstudio.com/), "
#~ "[rmarkdown](http://rmarkdown.rstudio.com/), "
#~ "[forecast](https://cran.r-project.org/web/packages/forecast/forecast.pdf),"
#~ " "
#~ "[rsqlite](https://cran.r-project.org/web/packages/RSQLite/index.html),"
#~ " "
#~ "[reshape2](https://cran.r-project.org/web/packages/reshape2/reshape2.pdf),"
#~ " "
#~ "[nycflights13](https://cran.r-project.org/web/packages/nycflights13/index.html),"
#~ " [caret](http://topepo.github.io/caret/index.html), "
#~ "[rcurl](https://cran.r-project.org/web/packages/RCurl/index.html), "
#~ "and "
#~ "[randomforest](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf)"
#~ " packages from [conda-forge](https://conda-"
#~ "forge.github.io/feedstocks)"
#~ msgstr ""

#~ msgid ""
#~ "[tidyverse](https://www.tidyverse.org/) packages, "
#~ "including [ggplot2](http://ggplot2.org/), "
#~ "[dplyr](http://dplyr.tidyverse.org/),"
#~ msgstr ""

#~ msgid ""
#~ "[tidyr](http://tidyr.tidyverse.org/), "
#~ "[readr](http://readr.tidyverse.org/), "
#~ "[purrr](http://purrr.tidyverse.org/), "
#~ "[tibble](http://tibble.tidyverse.org/), "
#~ "[stringr](http://stringr.tidyverse.org/), "
#~ "[lubridate](http://lubridate.tidyverse.org/), and "
#~ "[broom](https://cran.r-project.org/web/packages/broom/vignettes/broom.html)"
#~ " from [conda-forge](https://conda-"
#~ "forge.github.io/feedstocks) * "
#~ "[devtools](https://cran.r-project.org/web/packages/devtools/index.html),"
#~ " [shiny](https://shiny.rstudio.com/), "
#~ "[rmarkdown](http://rmarkdown.rstudio.com/), "
#~ "[forecast](https://cran.r-project.org/web/packages/forecast/forecast.pdf),"
#~ " "
#~ "[rsqlite](https://cran.r-project.org/web/packages/RSQLite/index.html),"
#~ " "
#~ "[nycflights13](https://cran.r-project.org/web/packages/nycflights13/index.html),"
#~ " [caret](http://topepo.github.io/caret/index.html), "
#~ "[tidymodels](https://www.tidymodels.org/), "
#~ "[rcurl](https://cran.r-project.org/web/packages/RCurl/index.html), "
#~ "and "
#~ "[randomforest](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf)"
#~ " packages from [conda-forge](https://conda-"
#~ "forge.github.io/feedstocks)"
#~ msgstr ""

#~ msgid ""
#~ "[dask](https://dask.org/), [pandas](https://pandas.pydata.org/),"
#~ " [numexpr](https://github.com/pydata/numexpr), "
#~ "[matplotlib](https://matplotlib.org/), "
#~ "[scipy](https://www.scipy.org/),"
#~ msgstr ""

#~ msgid ""
#~ "[seaborn](https://seaborn.pydata.org/), [scikit-"
#~ "learn](http://scikit-learn.org/stable/), [scikit-"
#~ "image](http://scikit-image.org/), "
#~ "[sympy](http://www.sympy.org/en/index.html), "
#~ "[cython](http://cython.org/), "
#~ "[patsy](https://patsy.readthedocs.io/en/latest/), "
#~ "[statsmodel](http://www.statsmodels.org/stable/index.html), "
#~ "[cloudpickle](https://github.com/cloudpipe/cloudpickle), "
#~ "[dill](https://pypi.python.org/pypi/dill), "
#~ "[numba](https://numba.pydata.org/), "
#~ "[bokeh](https://bokeh.pydata.org/en/latest/), "
#~ "[sqlalchemy](https://www.sqlalchemy.org/), "
#~ "[hdf5](http://www.h5py.org/), "
#~ "[vincent](http://vincent.readthedocs.io/en/latest/), "
#~ "[beautifulsoup](https://www.crummy.com/software/BeautifulSoup/), "
#~ "[protobuf](https://developers.google.com/protocol-"
#~ "buffers/docs/pythontutorial), [xlrd](http://www.python-"
#~ "excel.org/), "
#~ "[bottleneck](https://bottleneck.readthedocs.io/en/latest/), and"
#~ " [pytables](https://www.pytables.org/) packages * "
#~ "[ipywidgets](https://ipywidgets.readthedocs.io/en/stable/) and"
#~ " [ipympl](https://github.com/matplotlib/jupyter-matplotlib)"
#~ " for interactive visualizations and plots"
#~ " in Python notebooks * "
#~ "[Facets](https://github.com/PAIR-code/facets) for "
#~ "visualizing machine learning datasets"
#~ msgstr ""

#~ msgid ""
#~ "Pull requests to the `jupyter/docker-"
#~ "stacks` repository trigger builds of all"
#~ " images on Travis CI. These images"
#~ " are for testing purposes only and"
#~ " are not saved for use. When "
#~ "pull requests merge to master, all "
#~ "images rebuild on Docker Cloud and "
#~ "become available to `docker pull` from"
#~ " Docker Hub."
#~ msgstr ""

#~ msgid ""
#~ "[csharp-notebook is a community Jupyter"
#~ " Docker Stack image. Try C# in "
#~ "Jupyter Notebooks](https://github.com/tlinnet/csharp-"
#~ "notebook). The image includes more"
#~ msgstr ""

#~ msgid ""
#~ "than 200 Jupyter Notebooks with example"
#~ " C# code and can readily be "
#~ "tried online via mybinder.org. Click "
#~ "here to launch "
#~ "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/tlinnet"
#~ "/csharp-notebook/master)."
#~ msgstr ""

#~ msgid ""
#~ "[education-notebook is a community "
#~ "Jupyter Docker Stack image](https://github.com"
#~ "/umsi-mads/education-notebook). The image "
#~ "includes nbgrader and RISE on top "
#~ "of"
#~ msgstr ""

#~ msgid ""
#~ "the datascience-notebook image. Click "
#~ "here to launch it on "
#~ "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh"
#~ "/umsi-mads/education-notebook/master)."
#~ msgstr ""

#~ msgid "__crosscompass/ihaskell-notebook__"
#~ msgstr ""

#~ msgid ""
#~ "[java-notebook is a community Jupyter"
#~ " Docker Stack image](https://github.com/jbindinga"
#~ "/java-notebook). The image includes"
#~ msgstr ""

#~ msgid ""
#~ "[IJava](https://github.com/SpencerPark/IJava) kernel on"
#~ " top of the minimal-notebook image."
#~ " Click here to launch it on "
#~ "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jbindinga"
#~ "/java-notebook/master)."
#~ msgstr ""

#~ msgid ""
#~ "[sage-notebook](https://github.com/sharpTrick/sage-"
#~ "notebook) is a community Jupyter Docker"
#~ " Stack image with the "
#~ "[sagemath](https://sagemath.org) kernel on top "
#~ "of"
#~ msgstr ""

#~ msgid ""
#~ "the minimal-notebook image. Click here"
#~ " to launch it on "
#~ "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sharpTrick"
#~ "/sage-notebook/master)."
#~ msgstr ""

#~ msgid ""
#~ "[GPU-Jupyter](https://github.com/iot-salzburg/gpu-"
#~ "jupyter/): Leverage Jupyter Notebooks with "
#~ "the power of your NVIDIA GPU and"
#~ " perform GPU calculations using"
#~ msgstr ""

#~ msgid ""
#~ "Tensorflow and Pytorch in collaborative "
#~ "notebooks. This is done by generating"
#~ " a Dockerfile, that consists of the"
#~ " **nvidia/cuda** base image, the well-"
#~ "maintained **docker-stacks** that is "
#~ "integrated as submodule and GPU-able "
#~ "libraries like **Tensorflow**, **Keras** and"
#~ " **PyTorch** on top of it."
#~ msgstr ""

#~ msgid ""
#~ "[cgspatial-notebook](https://github.com/SCiO-systems"
#~ "/cgspatial-notebook) is a community Jupyter"
#~ " Docker Stack image. The image "
#~ "includes major geospatial Python &"
#~ msgstr ""

#~ msgid ""
#~ "R libraries on top of the "
#~ "datascience-notebook image. Try it on "
#~ "binder:[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh"
#~ "/SCiO-systems/cgspatial-notebook/master)"
#~ msgstr ""

#~ msgid "## Apache Spark"
#~ msgstr ""

#~ msgid "**Specific Docker Image Options**"
#~ msgstr ""

#~ msgid "**Usage Examples**"
#~ msgstr ""

#~ msgid "### Using Spark Local Mode"
#~ msgstr ""

#~ msgid "#### In Python"
#~ msgstr ""

#~ msgid "#### In R"
#~ msgstr ""

#~ msgid "#### In Scala"
#~ msgstr ""

#~ msgid "##### In a Spylon Kernel"
#~ msgstr ""

#~ msgid "##### In an Apache Toree Kernel"
#~ msgstr ""

#~ msgid ""
#~ "Apache Toree instantiates a local "
#~ "`SparkContext` for you in variable `sc`"
#~ " when the kernel starts."
#~ msgstr ""

#~ msgid "### Connecting to a Spark Cluster in Standalone Mode"
#~ msgstr ""

#~ msgid "##### In an Apache Toree Scala Notebook"
#~ msgstr ""

#~ msgid ""
#~ "The Apache Toree kernel automatically "
#~ "creates a `SparkContext` when it starts"
#~ " based on configuration information from"
#~ " its command line arguments and "
#~ "environment variables. You can pass "
#~ "information about your cluster via the"
#~ " `SPARK_OPTS` environment variable when you"
#~ " spawn a container."
#~ msgstr ""

#~ msgid ""
#~ "For instance, to pass information about"
#~ " a standalone Spark master, you could"
#~ " start the container like so:"
#~ msgstr ""

#~ msgid ""
#~ "```bash docker run -d -p 8888:8888 "
#~ "-e SPARK_OPTS='--master=spark://master:7077' \\"
#~ msgstr ""

# fa8494a4dde544109b9f6f49ac28178f
#~ msgid ""
#~ "Note that this is the same "
#~ "information expressed in a notebook in"
#~ " the Python case above. Once the "
#~ "kernel spec has your cluster "
#~ "information, you can test your cluster"
#~ " in an Apache Toree notebook like "
#~ "so:"
#~ msgstr ""

#~ msgid ""
#~ "```scala // should print the value "
#~ "of --master in the kernel spec "
#~ "println(sc.master)"
#~ msgstr ""

#~ msgid ""
#~ "// Sum of the first 100 whole "
#~ "numbers val rdd = sc.parallelize(0 to"
#~ " 100) rdd.sum() // 5050 ```"
#~ msgstr ""

#~ msgid ""
#~ "Spark distribution is defined by the "
#~ "combination of the Spark and the "
#~ "Hadoop version and verified by the "
#~ "package checksum, see [Download Apache "
#~ "Spark](https://spark.apache.org/downloads.html) for more"
#~ " information. * `spark_version`: The Spark"
#~ " version to install (`3.0.0`). * "
#~ "`hadoop_version`: The Hadoop version (`3.2`)."
#~ " * `spark_checksum`: The package checksum"
#~ " (`BFE4540...`)."
#~ msgstr ""

#~ msgid ""
#~ "[git](https://git-scm.com/), "
#~ "[emacs](https://www.gnu.org/software/emacs/) (actually "
#~ "`emacs-nox`), [vi](https://vim.org/) (actually "
#~ "`vim-tiny`), [jed](https://www.jedsoft.org/jed/), "
#~ "[nano](https://www.nano-editor.org/), tzdata, and"
#~ " unzip"
#~ msgstr ""

#~ msgid ""
#~ "[tidyverse](https://www.tidyverse.org/) packages, "
#~ "including [ggplot2](http://ggplot2.org/), "
#~ "[dplyr](http://dplyr.tidyverse.org/), "
#~ "[tidyr](http://tidyr.tidyverse.org/), "
#~ "[readr](http://readr.tidyverse.org/), "
#~ "[purrr](http://purrr.tidyverse.org/), "
#~ "[tibble](http://tibble.tidyverse.org/), "
#~ "[stringr](http://stringr.tidyverse.org/), "
#~ "[lubridate](http://lubridate.tidyverse.org/), and "
#~ "[broom](https://cran.r-project.org/web/packages/broom/vignettes/broom.html)"
#~ " from [conda-forge](https://conda-"
#~ "forge.github.io/feedstocks)"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile # Start from a core "
#~ "stack version FROM jupyter/datascience-"
#~ "notebook:9f9e5ca8fe5a # Install from "
#~ "requirements.txt file COPY requirements.txt "
#~ "/tmp/ RUN pip install --requirement "
#~ "/tmp/requirements.txt && \\"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile # Start from a core "
#~ "stack version FROM jupyter/datascience-"
#~ "notebook:9f9e5ca8fe5a # Install from "
#~ "requirements.txt file COPY requirements.txt "
#~ "/tmp/ RUN conda install --yes --file "
#~ "/tmp/requirements.txt && \\"
#~ msgstr ""

#~ msgid ""
#~ "# COPY environment.yml /home/$NB_USER/tmp/ #"
#~ " RUN cd /home/$NB_USER/tmp/ && \\ #"
#~ "     conda env create -p "
#~ "$CONDA_DIR/envs/$conda_env -f environment.yml && "
#~ "\\ #     conda clean --all -f -y"
#~ msgstr ""

#~ msgid "[Miniconda](https://conda.io/miniconda.html) Python 3.x in `/opt/conda`"
#~ msgstr ""

#~ msgid ""
#~ "[git](https://git-scm.com/), "
#~ "[emacs](https://www.gnu.org/software/emacs/) (actually "
#~ "`emacs-nox`), [vi](https://vim.org/) (actually "
#~ "`vim-tiny`), [jed](https://www.jedsoft.org/jed/), "
#~ "[nano](https://www.nano-editor.org/) (actually "
#~ "`nano-tiny`), tzdata, and unzip"
#~ msgstr ""

#~ msgid ""
#~ "Spark is shipped with a version of"
#~ " Py4J that has to be referenced "
#~ "in the `PYTHONPATH`. * `py4j_version`: "
#~ "The Py4J version (`0.10.9`), see the "
#~ "tip below."
#~ msgstr ""

#~ msgid ""
#~ "-t jupyter/pyspark-notebook:spark-2.4.6 "
#~ "./pyspark-notebook \\ --build-arg "
#~ "spark_version=2.4.6 \\ --build-arg "
#~ "hadoop_version=2.7 \\ --build-arg "
#~ "spark_checksum=3A9F401EDA9B5749CDAFD246B1D14219229C26387017791C345A23A65782FB8B25A302BF4AC1ED7C16A1FE83108E94E55DAD9639A51C751D81C8C0534A4A9641"
#~ " \\ --build-arg openjdk_version=8 \\ "
#~ "--build-arg py4j_version=0.10.7"
#~ msgstr ""

#~ msgid ""
#~ "# Check the newly built image "
#~ "docker images jupyter/pyspark-notebook:spark-2.4.6"
#~ msgstr ""

#~ msgid ""
#~ "# REPOSITORY                 TAG                 "
#~ "IMAGE ID            CREATED             SIZE #"
#~ " jupyter/pyspark-notebook   spark-2.4.6         "
#~ "7ad7b5a9dbcd        4 minutes ago       3.44GB"
#~ msgstr ""

#~ msgid ""
#~ "# Check the Spark version docker "
#~ "run -it --rm jupyter/pyspark-"
#~ "notebook:spark-2.4.6 pyspark --version"
#~ msgstr ""

#~ msgid ""
#~ "# Welcome to #       ____              "
#~ "__ #      / __/__  ___ _____/ /__"
#~ " #     _\\ \\/ _ \\/ _ `/ "
#~ "__/  '_/ #    /___/ .__/\\_,_/_/ "
#~ "/_/\\_\\   version 2.4.6 #       /_/ #"
#~ " # Using Scala version 2.11.12, "
#~ "OpenJDK 64-Bit Server VM, 1.8.0_265 ```"
#~ msgstr ""

#~ msgid "**Tip**: to get the version of Py4J shipped with Spark:"
#~ msgstr ""

#~ msgid ""
#~ "Build a first image without changing "
#~ "`py4j_version` (it will not prevent the"
#~ " image to build it will just "
#~ "prevent Python to find the `pyspark` "
#~ "module),"
#~ msgstr ""

#~ msgid "get the version (`ls /usr/local/spark/python/lib/`),"
#~ msgstr ""

#~ msgid "set the version `--build-arg py4j_version=0.10.7`."
#~ msgstr ""

#~ msgid ""
#~ "```bash docker run -it --rm jupyter"
#~ "/pyspark-notebook:spark-2.4.6 ls "
#~ "/usr/local/spark/python/lib/ # py4j-0.10.7-src.zip  "
#~ "PY4J_LICENSE.txt  pyspark.zip # You can "
#~ "now set the build-arg # "
#~ "--build-arg py4j_version= ```"
#~ msgstr ""

#~ msgid ""
#~ "*Note: At the time of writing "
#~ "there is an issue preventing to "
#~ "use Spark `2.4.6` with Python `3.8`, "
#~ "see [this answer on "
#~ "SO](https://stackoverflow.com/a/62173969/4413446) for more"
#~ " information.*"
#~ msgstr ""

#~ msgid "# Install the Dask dashboard RUN pip install dask_labextension ; \\"
#~ msgstr ""

#~ msgid "jupyter labextension install -y --clean \\ dask-labextension"
#~ msgstr ""

#~ msgid ""
#~ "The `jovyan` user has full read/write"
#~ " access to the `/opt/conda` directory. "
#~ "You can use either `conda` or "
#~ "`pip` to install new packages without"
#~ " any additional permissions."
#~ msgstr ""

#~ msgid ""
#~ "```bash # install a package into "
#~ "the default (python 3.x) environment pip"
#~ " install some-package conda install "
#~ "some-package ```"
#~ msgstr ""

#~ msgid ""
#~ "[Miniforge](https://github.com/conda-forge/miniforge) "
#~ "Python 3.x in `/opt/conda`"
#~ msgstr ""

#~ msgid ""
#~ "Spark distribution is defined by the "
#~ "combination of the Spark and the "
#~ "Hadoop version and verified by the "
#~ "package checksum, see [Download Apache "
#~ "Spark](https://spark.apache.org/downloads.html) for more"
#~ " information. At this time the build"
#~ " will only work with the set of"
#~ " versions available on the Apache "
#~ "Spark download page, so it will "
#~ "not work with the archived versions. "
#~ "* `spark_version`: The Spark version to"
#~ " install (`3.0.0`). * `hadoop_version`: The"
#~ " Hadoop version (`3.2`). * "
#~ "`spark_checksum`: The package checksum "
#~ "(`BFE4540...`)."
#~ msgstr ""

#~ msgid ""
#~ "And build the image as: ```bash "
#~ "docker build -t jupyter/scipy-"
#~ "dasklabextension:latest . ```"
#~ msgstr ""

#~ msgid ""
#~ "Once built, run using the command: "
#~ "```bash docker run -it --rm -p "
#~ "8888:8888 -p 8787:8787 jupyter/scipy-"
#~ "dasklabextension:latest ```"
#~ msgstr ""

#~ msgid ""
#~ "For Ubuntu 18.04 (bionic) and earlier,"
#~ " you may also require to workaround"
#~ " for a mandb bug, which was "
#~ "fixed in mandb >= 2.8.6.1: ```dockerfile"
#~ " # https://git.savannah.gnu.org/cgit/man-"
#~ "db.git/commit/?id=8197d7824f814c5d4b992b4c8730b5b0f7ec589a # "
#~ "http://launchpadlibrarian.net/435841763/man-"
#~ "db_2.8.5-2_2.8.6-1.diff.gz"
#~ msgstr ""

#~ msgid "``` docker run -p 8888:8888 jupyter/scipy-notebook:2c80cf3537ca"
#~ msgstr ""

#~ msgid ""
#~ "``` # list containers docker ps -a"
#~ " CONTAINER ID        IMAGE                   "
#~ "COMMAND                  CREATED    STATUS"
#~ "                      PORTS               NAMES "
#~ "d67fe77f1a84        jupyter/base-notebook   \"tini"
#~ " -- start-noteb\"   44 seconds ago"
#~ "    Exited (0) 39 seconds ago"
#~ "                       cocky_mirzakhani"
#~ msgstr ""

#~ msgid ""
#~ "# start the stopped container docker "
#~ "start -a d67fe77f1a84 Executing the "
#~ "command: jupyter notebook [W 16:45:02.020 "
#~ "NotebookApp] WARNING: The notebook server "
#~ "is listening on all IP addresses "
#~ "and not using encryption. This is "
#~ "not recommended. ..."
#~ msgstr ""

#~ msgid "# remove the stopped container docker rm d67fe77f1a84 d67fe77f1a84 ```"
#~ msgstr ""

#~ msgid ""
#~ "``` docker run --rm -p 10000:8888 "
#~ "-v \"$PWD\":/home/jovyan/work "
#~ "jupyter/r-notebook:e5c5a7d3e52d"
#~ msgstr ""

#~ msgid "``` docker run -d -P --name notebook jupyter/all-spark-notebook ```"
#~ msgstr ""

#~ msgid ""
#~ "``` # get the random host port "
#~ "assigned to the container port 8888 "
#~ "docker port notebook 8888 0.0.0.0:32769"
#~ msgstr ""

#~ msgid "# get the notebook token from the logs docker logs --tail 3 notebook"
#~ msgstr ""

# c4bc333e19324e2a93118e21b1f8f360
#~ msgid ""
#~ "Together, the URL to visit on the"
#~ " host machine to access the server"
#~ " in this case is "
#~ "http://localhost:32769?token=15914ca95f495075c0aa7d0e060f1a78b6d94f70ea373b00."
#~ msgstr ""

#~ msgid "``` # stop the container docker stop notebook notebook"
#~ msgstr ""

#~ msgid "##### In Python"
#~ msgstr ""

#~ msgid "##### In R"
#~ msgstr ""

#~ msgid "##### In Scala"
#~ msgstr ""

#~ msgid ""
#~ "Run the Docker container with "
#~ "`--net=host` in a location that is "
#~ "network addressable by all of your "
#~ "Spark workers. (This is a [Spark "
#~ "networking requirement](http://spark.apache.org/docs/latest"
#~ "/cluster-overview.html#components).) * NOTE: When"
#~ " using `--net=host`, you must also "
#~ "use the flags `--pid=host -e "
#~ "TINI_SUBREAPER=true`. See https://github.com/jupyter"
#~ "/docker-stacks/issues/64 for details."
#~ msgstr ""

#~ msgid ""
#~ "You can pass [Jupyter command line "
#~ "options](https://jupyter.readthedocs.io/en/latest/projects/jupyter-"
#~ "command.html) to the `start-notebook.sh` "
#~ "script when launching the container. For"
#~ " example, to secure the Notebook "
#~ "server with a custom password hashed "
#~ "using `IPython.lib.passwd()` instead of the"
#~ " default token, you can run the "
#~ "following:"
#~ msgstr ""

#~ msgid ""
#~ "[git](https://git-scm.com/), [vi](https://vim.org/) "
#~ "(actually `vim-tiny`), [nano](https://www.nano-"
#~ "editor.org/) (actually `nano-tiny`), tzdata,"
#~ " and unzip"
#~ msgstr ""

#~ msgid ""
#~ "[ggplot2](http://ggplot2.org/), "
#~ "[sparklyr](http://spark.rstudio.com/), and "
#~ "[rcurl](https://cran.r-project.org/web/packages/RCurl/index.html) "
#~ "packages"
#~ msgstr ""

#~ msgid ""
#~ "Pull requests to the `jupyter/docker-"
#~ "stacks` repository trigger builds of all"
#~ " images on GitHub Actions. These "
#~ "images are for testing purposes only "
#~ "and are not saved for use. When"
#~ " pull requests merge to master, all"
#~ " images rebuild on Docker Cloud and"
#~ " become available to `docker pull` "
#~ "from Docker Hub."
#~ msgstr ""

#~ msgid "# Common Features"
#~ msgstr ""

#~ msgid "## Notebook Options"
#~ msgstr ""

#~ msgid ""
#~ "```bash docker run -d -p 8888:8888 "
#~ "jupyter/base-notebook start-notebook.sh "
#~ "--NotebookApp.password='sha1:74ba40f8a388:c913541b7ee99d15d5ed31d4226bf7838f83a50e'"
#~ " ```"
#~ msgstr ""

#~ msgid ""
#~ "```bash docker run -d -p 8888:8888 "
#~ "jupyter/base-notebook start-notebook.sh "
#~ "--NotebookApp.base_url=/some/path ```"
#~ msgstr ""

#~ msgid "## Docker Options"
#~ msgstr ""

#~ msgid "## Startup Hooks"
#~ msgstr ""

#~ msgid "## SSL Certificates"
#~ msgstr ""

#~ msgid "```bash docker run -d -p 8888:8888 \\"
#~ msgstr ""

#~ msgid ""
#~ "-v /some/host/folder:/etc/ssl/notebook \\ jupyter"
#~ "/base-notebook start-notebook.sh \\ "
#~ "--NotebookApp.keyfile=/etc/ssl/notebook/notebook.key "
#~ "--NotebookApp.certfile=/etc/ssl/notebook/notebook.crt"
#~ msgstr ""

#~ msgid "```"
#~ msgstr ""

#~ msgid ""
#~ "-v /some/host/folder/notebook.pem:/etc/ssl/notebook.pem \\"
#~ " jupyter/base-notebook start-notebook.sh \\"
#~ " --NotebookApp.certfile=/etc/ssl/notebook.pem"
#~ msgstr ""

#~ msgid "## Alternative Commands"
#~ msgstr ""

#~ msgid "### start.sh"
#~ msgstr ""

#~ msgid "```bash docker run -it --rm jupyter/base-notebook start.sh ipython ```"
#~ msgstr ""

#~ msgid ""
#~ "```bash docker run -it --rm -p "
#~ "8888:8888 jupyter/base-notebook start.sh "
#~ "jupyter lab ```"
#~ msgstr ""

#~ msgid "### Others"
#~ msgstr ""

#~ msgid "## Conda Environments"
#~ msgstr ""

#~ msgid ""
#~ "```bash # install a package into "
#~ "the default (python 3.x) environment pip"
#~ " install some-package conda install "
#~ "some-package mamba install some-package "
#~ "```"
#~ msgstr ""

#~ msgid "### Using alternative channels"
#~ msgstr ""

#~ msgid ""
#~ "```bash # using defaults channels to "
#~ "install a package conda install "
#~ "--channel defaults humanize # configure "
#~ "conda to add default channels at "
#~ "the top of the list conda config"
#~ " --system --prepend channels defaults # "
#~ "install a package conda install humanize"
#~ " ```"
#~ msgstr ""

#~ msgid "# Contributed Recipes"
#~ msgstr ""

#~ msgid "## Using `sudo` within a container"
#~ msgstr ""

#~ msgid ""
#~ "```bash docker run -it -e GRANT_SUDO=yes"
#~ " --user root jupyter/minimal-notebook ```"
#~ msgstr ""

#~ msgid "## Using `pip install` or `conda install` in a Child Docker image"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile # Start from a core "
#~ "stack version FROM jupyter/datascience-"
#~ "notebook:9f9e5ca8fe5a # Install in the "
#~ "default python3 environment RUN pip "
#~ "install 'ggplot==0.6.8' ```"
#~ msgstr ""

#~ msgid "```bash docker build --rm -t jupyter/my-datascience-notebook . ```"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile # Start from a core "
#~ "stack version FROM jupyter/datascience-"
#~ "notebook:9f9e5ca8fe5a # Install from "
#~ "requirements.txt file COPY "
#~ "--chown=${NB_UID}:${NB_GID} requirements.txt /tmp/ "
#~ "RUN pip install --requirement "
#~ "/tmp/requirements.txt && \\"
#~ msgstr ""

#~ msgid "fix-permissions $CONDA_DIR && \\ fix-permissions /home/$NB_USER"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile # Start from a core "
#~ "stack version FROM jupyter/datascience-"
#~ "notebook:9f9e5ca8fe5a # Install from "
#~ "requirements.txt file COPY "
#~ "--chown=${NB_UID}:${NB_GID} requirements.txt /tmp/ "
#~ "RUN conda install --yes --file "
#~ "/tmp/requirements.txt && \\"
#~ msgstr ""

#~ msgid "## Add a Python 2.x environment"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile # Choose your desired base"
#~ " image FROM jupyter/scipy-notebook:latest"
#~ msgstr ""

#~ msgid ""
#~ "# Create a Python 2.x environment "
#~ "using conda including at least the "
#~ "ipython kernel # and the kernda "
#~ "utility. Add any additional packages you"
#~ " want available for use # in a"
#~ " Python 2 notebook to the first "
#~ "line here (e.g., pandas, matplotlib, "
#~ "etc.) RUN conda create --quiet --yes "
#~ "-p $CONDA_DIR/envs/python2 python=2.7 ipython "
#~ "ipykernel kernda && \\"
#~ msgstr ""

#~ msgid "conda clean --all -f -y"
#~ msgstr ""

#~ msgid "USER root"
#~ msgstr ""

#~ msgid ""
#~ "# Create a global kernelspec in "
#~ "the image and modify it so that"
#~ " it properly activates # the python2"
#~ " conda environment. RUN "
#~ "$CONDA_DIR/envs/python2/bin/python -m ipykernel "
#~ "install && \\ $CONDA_DIR/envs/python2/bin/kernda "
#~ "-o -y /usr/local/share/jupyter/kernels/python2/kernel.json"
#~ msgstr ""

#~ msgid "USER $NB_USER ```"
#~ msgstr ""

#~ msgid "## Add a Python 3.x environment"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile # Choose your desired base"
#~ " image FROM jupyter/minimal-notebook:latest"
#~ msgstr ""

#~ msgid ""
#~ "# name your environment and choose "
#~ "python 3.x version ARG conda_env=python36 "
#~ "ARG py_ver=3.6"
#~ msgstr ""

#~ msgid ""
#~ "# you can add additional libraries "
#~ "you want conda to install by "
#~ "listing them below the first line "
#~ "and ending with \"&& \\\" RUN "
#~ "conda create --quiet --yes -p "
#~ "$CONDA_DIR/envs/$conda_env python=$py_ver ipython "
#~ "ipykernel && \\"
#~ msgstr ""

#~ msgid ""
#~ "# alternatively, you can comment out "
#~ "the lines above and uncomment those "
#~ "below # if you'd prefer to use "
#~ "a YAML file present in the docker"
#~ " build context"
#~ msgstr ""

#~ msgid ""
#~ "# COPY --chown=${NB_UID}:${NB_GID} environment.yml"
#~ " /home/$NB_USER/tmp/ # RUN cd "
#~ "/home/$NB_USER/tmp/ && \\ #     conda "
#~ "env create -p $CONDA_DIR/envs/$conda_env -f"
#~ " environment.yml && \\ #     conda "
#~ "clean --all -f -y"
#~ msgstr ""

#~ msgid ""
#~ "# create Python 3.x environment and "
#~ "link it to jupyter RUN "
#~ "$CONDA_DIR/envs/${conda_env}/bin/python -m ipykernel "
#~ "install --user --name=${conda_env} && \\"
#~ msgstr ""

#~ msgid ""
#~ "# any additional pip installs can "
#~ "be added by uncommenting the following"
#~ " line # RUN $CONDA_DIR/envs/${conda_env}/bin/pip"
#~ " install"
#~ msgstr ""

#~ msgid ""
#~ "# prepend conda environment to path "
#~ "ENV PATH $CONDA_DIR/envs/${conda_env}/bin:$PATH"
#~ msgstr ""

#~ msgid ""
#~ "# if you want this environment to"
#~ " be the default one, uncomment the"
#~ " following line: # ENV CONDA_DEFAULT_ENV"
#~ " ${conda_env} ```"
#~ msgstr ""

#~ msgid "## Run JupyterLab"
#~ msgstr ""

#~ msgid "## Dask JupyterLab Extension"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile # Start from a core "
#~ "stack version FROM jupyter/scipy-"
#~ "notebook:latest"
#~ msgstr ""

#~ msgid "# Install the Dask dashboard RUN pip install dask-labextension"
#~ msgstr ""

#~ msgid "# Dask Scheduler & Bokeh ports EXPOSE 8787 EXPOSE 8786"
#~ msgstr ""

#~ msgid ""
#~ "ENTRYPOINT [\"jupyter\", \"lab\", \"--"
#~ "ip=0.0.0.0\", \"--allow-root\"] ```"
#~ msgstr ""

#~ msgid "```bash docker build -t jupyter/scipy-dasklabextension:latest . ```"
#~ msgstr ""

#~ msgid ""
#~ "```bash docker run -it --rm -p "
#~ "8888:8888 -p 8787:8787 jupyter/scipy-"
#~ "dasklabextension:latest ```"
#~ msgstr ""

#~ msgid "## Let's Encrypt a Notebook server"
#~ msgstr ""

#~ msgid "## Slideshows with Jupyter and RISE"
#~ msgstr ""

#~ msgid ""
#~ "```bash # Add Live slideshows with "
#~ "RISE RUN conda install -c damianavila82"
#~ " rise ```"
#~ msgstr ""

#~ msgid "## xgboost"
#~ msgstr ""

#~ msgid "```bash %%bash conda install -y gcc pip install xgboost"
#~ msgstr ""

#~ msgid "import xgboost ```"
#~ msgstr ""

#~ msgid "## Running behind a nginx proxy"
#~ msgstr ""

#~ msgid "## Host volume mounts and notebook errors"
#~ msgstr ""

#~ msgid "## Manpage installation"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile # Choose your desired base"
#~ " image ARG BASE_CONTAINER=jupyter/datascience-"
#~ "notebook:latest FROM $BASE_CONTAINER"
#~ msgstr ""

#~ msgid ""
#~ "# Remove the manpage blacklist, install"
#~ " man, install docs RUN rm "
#~ "/etc/dpkg/dpkg.cfg.d/excludes \\"
#~ msgstr ""

#~ msgid ""
#~ "&& apt-get update \\ && dpkg "
#~ "-l | grep ^ii | cut -d' '"
#~ " -f3 | xargs apt-get install "
#~ "-yq --no-install-recommends --reinstall "
#~ "man \\ && apt-get clean \\ "
#~ "&& rm -rf /var/lib/apt/lists/*"
#~ msgstr ""

#~ msgid "USER $NB_UID ```"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile # Ubuntu 20.04 (focal) "
#~ "from 2020-04-23 # https://github.com/docker-"
#~ "library/official-"
#~ "images/commit/4475094895093bcc29055409494cce1e11b52f94 ARG "
#~ "BASE_CONTAINER=ubuntu:focal-20200423@sha256:238e696992ba9913d24cfc3727034985abd136e08ee3067982401acdc30cbf3f"
#~ " ```"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile # https://git.savannah.gnu.org/cgit/man-"
#~ "db.git/commit/?id=8197d7824f814c5d4b992b4c8730b5b0f7ec589a # "
#~ "http://launchpadlibrarian.net/435841763/man-"
#~ "db_2.8.5-2_2.8.6-1.diff.gz"
#~ msgstr ""

#~ msgid ""
#~ "RUN echo \"MANPATH_MAP ${CONDA_DIR}/bin "
#~ "${CONDA_DIR}/man\" >> /etc/manpath.config \\"
#~ msgstr ""

#~ msgid ""
#~ "&& echo \"MANPATH_MAP ${CONDA_DIR}/bin "
#~ "${CONDA_DIR}/share/man\" >> /etc/manpath.config \\"
#~ " && mandb"
#~ msgstr ""

#~ msgid "## JupyterHub"
#~ msgstr ""

#~ msgid "### Use JupyterHub's dockerspawner"
#~ msgstr ""

#~ msgid "### Containers with a specific version of JupyterHub"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile FROM jupyter/base-"
#~ "notebook:5ded1de07260 RUN pip install "
#~ "jupyterhub==0.8.0b1 ```"
#~ msgstr ""

#~ msgid "## Spark"
#~ msgstr ""

#~ msgid "### Using PySpark with AWS S3"
#~ msgstr ""

#~ msgid ""
#~ "```py import os # !ls "
#~ "/usr/local/spark/jars/hadoop* # to figure out"
#~ " what version of hadoop "
#~ "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages "
#~ "\"org.apache.hadoop:hadoop-aws:2.7.3\" pyspark-"
#~ "shell'"
#~ msgstr ""

#~ msgid "import pyspark myAccessKey = input() mySecretKey = input()"
#~ msgstr ""

#~ msgid "spark = pyspark.sql.SparkSession.builder \\"
#~ msgstr ""

#~ msgid ""
#~ ".master(\"local[*]\") \\ "
#~ ".config(\"spark.hadoop.fs.s3a.access.key\", myAccessKey) "
#~ "\\ .config(\"spark.hadoop.fs.s3a.secret.key\", "
#~ "mySecretKey) \\ .getOrCreate()"
#~ msgstr ""

#~ msgid "df = spark.read.parquet(\"s3://myBucket/myKey\") ```"
#~ msgstr ""

#~ msgid ""
#~ "```py import os os.environ['PYSPARK_SUBMIT_ARGS']"
#~ " = '--packages com.amazonaws:aws-java-"
#~ "sdk:1.10.34,org.apache.hadoop:hadoop-aws:2.6.0 pyspark-"
#~ "shell'"
#~ msgstr ""

#~ msgid "import pyspark sc = pyspark.SparkContext(\"local[*]\")"
#~ msgstr ""

#~ msgid "from pyspark.sql import SQLContext sqlContext = SQLContext(sc)"
#~ msgstr ""

#~ msgid ""
#~ "hadoopConf = sc._jsc.hadoopConfiguration() "
#~ "myAccessKey = input() mySecretKey = "
#~ "input() hadoopConf.set(\"fs.s3.impl\", "
#~ "\"org.apache.hadoop.fs.s3native.NativeS3FileSystem\") "
#~ "hadoopConf.set(\"fs.s3.awsAccessKeyId\", myAccessKey) "
#~ "hadoopConf.set(\"fs.s3.awsSecretAccessKey\", mySecretKey)"
#~ msgstr ""

#~ msgid "df = sqlContext.read.parquet(\"s3://myBucket/myKey\") ```"
#~ msgstr ""

#~ msgid "### Using Local Spark JARs"
#~ msgstr ""

#~ msgid ""
#~ "```python import os "
#~ "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars "
#~ "/home/jovyan/spark-streaming-kafka-"
#~ "assembly_2.10-1.6.1.jar pyspark-shell' import "
#~ "pyspark from pyspark.streaming.kafka import "
#~ "KafkaUtils from pyspark.streaming import "
#~ "StreamingContext sc = pyspark.SparkContext() "
#~ "ssc = StreamingContext(sc,1) broker = "
#~ "\"<my_broker_ip>\" directKafkaStream = "
#~ "KafkaUtils.createDirectStream(ssc, [\"test1\"], "
#~ "{\"metadata.broker.list\": broker}) "
#~ "directKafkaStream.pprint() ssc.start() ```"
#~ msgstr ""

#~ msgid "### Using spark-packages.org"
#~ msgstr ""

#~ msgid "### Use jupyter/all-spark-notebooks with an existing Spark/YARN cluster"
#~ msgstr ""

#~ msgid "```dockerfile FROM jupyter/all-spark-notebook"
#~ msgstr ""

#~ msgid ""
#~ "# Set env vars for pydoop ENV "
#~ "HADOOP_HOME /usr/local/hadoop-2.7.3 ENV JAVA_HOME"
#~ " /usr/lib/jvm/java-8-openjdk-amd64 ENV "
#~ "HADOOP_CONF_HOME /usr/local/hadoop-2.7.3/etc/hadoop ENV"
#~ " HADOOP_CONF_DIR  /usr/local/hadoop-2.7.3/etc/hadoop"
#~ msgstr ""

#~ msgid ""
#~ "USER root # Add proper open-jdk-8"
#~ " not just the jre, needed for "
#~ "pydoop RUN echo 'deb http://cdn-"
#~ "fastly.deb.debian.org/debian jessie-backports main'"
#~ " > /etc/apt/sources.list.d/jessie-backports.list "
#~ "&& \\"
#~ msgstr ""

#~ msgid ""
#~ "apt-get -y update && \\ apt-"
#~ "get install --no-install-recommends -t"
#~ " jessie-backports -y openjdk-8-jdk && "
#~ "\\ rm /etc/apt/sources.list.d/jessie-backports.list"
#~ " && \\ apt-get clean && \\ "
#~ "rm -rf /var/lib/apt/lists/ && \\"
#~ msgstr ""

#~ msgid "# Add hadoop binaries"
#~ msgstr ""

#~ msgid ""
#~ "wget "
#~ "http://mirrors.ukfast.co.uk/sites/ftp.apache.org/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz"
#~ " && \\ tar -xvf hadoop-2.7.3.tar.gz "
#~ "-C /usr/local && \\ chown -R "
#~ "$NB_USER:users /usr/local/hadoop-2.7.3 && \\ "
#~ "rm -f hadoop-2.7.3.tar.gz && \\"
#~ msgstr ""

#~ msgid "# Install os dependencies required for pydoop, pyhive"
#~ msgstr ""

#~ msgid ""
#~ "apt-get update && \\ apt-get "
#~ "install --no-install-recommends -y "
#~ "build-essential python-dev libsasl2-dev &&"
#~ " \\ apt-get clean && \\ rm "
#~ "-rf /var/lib/apt/lists/* && \\"
#~ msgstr ""

#~ msgid ""
#~ "# Remove the example hadoop configs "
#~ "and replace # with those for our"
#~ " cluster. # Alternatively this could "
#~ "be mounted as a volume"
#~ msgstr ""

#~ msgid "rm -f /usr/local/hadoop-2.7.3/etc/hadoop/*"
#~ msgstr ""

#~ msgid ""
#~ "# Download this from ambari / "
#~ "cloudera manager and copy here COPY "
#~ "example-hadoop-conf/ "
#~ "/usr/local/hadoop-2.7.3/etc/hadoop/"
#~ msgstr ""

#~ msgid ""
#~ "# Spark-Submit doesn't work unless "
#~ "I set the following RUN echo "
#~ "\"spark.driver.extraJavaOptions -Dhdp.version=2.5.3.0-37\" "
#~ ">> /usr/local/spark/conf/spark-defaults.conf  && "
#~ "\\"
#~ msgstr ""

#~ msgid ""
#~ "echo \"spark.yarn.am.extraJavaOptions "
#~ "-Dhdp.version=2.5.3.0-37\" >> /usr/local/spark/conf"
#~ "/spark-defaults.conf && \\ echo "
#~ "\"spark.master=yarn\" >>  /usr/local/spark/conf/spark-"
#~ "defaults.conf && \\ echo \"spark.hadoop.yarn"
#~ ".timeline-service.enabled=false\" >> "
#~ "/usr/local/spark/conf/spark-defaults.conf && \\ "
#~ "chown -R $NB_USER:users /usr/local/spark/conf"
#~ "/spark-defaults.conf && \\ # Create "
#~ "an alternative HADOOP_CONF_HOME so we "
#~ "can mount as a volume and repoint"
#~ " # using ENV var if needed "
#~ "mkdir -p /etc/hadoop/conf/ && \\ chown"
#~ " $NB_USER:users /etc/hadoop/conf/"
#~ msgstr ""

#~ msgid "USER $NB_USER"
#~ msgstr ""

#~ msgid ""
#~ "# Install useful jupyter extensions and"
#~ " python libraries like : # - "
#~ "Dashboards # - PyDoop # - PyHive"
#~ " RUN pip install jupyter_dashboards faker"
#~ " && \\"
#~ msgstr ""

#~ msgid ""
#~ "jupyter dashboards quick-setup --sys-"
#~ "prefix && \\ pip2 install pyhive "
#~ "pydoop thrift sasl thrift_sasl faker"
#~ msgstr ""

#~ msgid ""
#~ "USER root # Ensure we overwrite "
#~ "the kernel config so that toree "
#~ "connects to cluster RUN jupyter toree"
#~ " install --sys-prefix --spark_opts=\"--"
#~ "master yarn --deploy-mode client "
#~ "--driver-memory 512m  --executor-memory "
#~ "512m  --executor-cores 1 --driver-"
#~ "java-options -Dhdp.version=2.5.3.0-37 --conf "
#~ "spark.hadoop.yarn.timeline-service.enabled=false\" USER"
#~ " $NB_USER ```"
#~ msgstr ""

#~ msgid ""
#~ "## Run Jupyter Notebook/Lab inside an"
#~ " already secured environment (i.e., with"
#~ " no token)"
#~ msgstr ""

#~ msgid ""
#~ "```bash docker run jupyter/base-"
#~ "notebook:6d2a05346196 start.sh jupyter lab "
#~ "--LabApp.token='' ```"
#~ msgstr ""

#~ msgid ""
#~ "```bash docker run jupyter/base-"
#~ "notebook:6d2a05346196 start.sh jupyter notebook "
#~ "--NotebookApp.token='' ```"
#~ msgstr ""

#~ msgid ""
#~ "## Enable nbextension spellchecker for "
#~ "markdown (or any other nbextension)"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile # Update with your base"
#~ " image of choice FROM jupyter/minimal-"
#~ "notebook:latest"
#~ msgstr ""

#~ msgid "RUN pip install jupyter_contrib_nbextensions && \\"
#~ msgstr ""

#~ msgid ""
#~ "jupyter contrib nbextension install --user "
#~ "&& \\ # can modify or enable "
#~ "additional extensions here jupyter nbextension"
#~ " enable spellchecker/main --user"
#~ msgstr ""

#~ msgid "## Enable auto-sklearn notebooks"
#~ msgstr ""

#~ msgid ""
#~ "```dockerfile ARG BASE_CONTAINER=jupyter/scipy-"
#~ "notebook FROM jupyter/scipy-notebook:latest"
#~ msgstr ""

#~ msgid ""
#~ "# autosklearn requires swig, which no"
#~ " other image has RUN apt-get "
#~ "update && \\"
#~ msgstr ""

#~ msgid ""
#~ "apt-get install -y --no-install-"
#~ "recommends swig && \\ apt-get "
#~ "clean && \\ rm -rf /var/lib/apt/lists/*"
#~ msgstr ""

#~ msgid "USER $NB_UID"
#~ msgstr ""

#~ msgid "RUN pip install --quiet --no-cache-dir auto-sklearn ```"
#~ msgstr ""

#~ msgid "## Enable Delta Lake in Spark notebooks"
#~ msgstr ""

#~ msgid "```dockerfile FROM jupyter/pyspark-notebook:latest"
#~ msgstr ""

#~ msgid "ARG DELTA_CORE_VERSION=\"0.8.0\""
#~ msgstr ""

#~ msgid ""
#~ "RUN echo \"spark.jars.packages io.delta:delta-"
#~ "core_2.12:${DELTA_CORE_VERSION}\" >> $SPARK_HOME/conf"
#~ "/spark-defaults.conf && \\"
#~ msgstr ""

#~ msgid ""
#~ "echo 'spark.sql.extensions "
#~ "io.delta.sql.DeltaSparkSessionExtension' >> "
#~ "$SPARK_HOME/conf/spark-defaults.conf && \\ "
#~ "echo 'spark.sql.catalog.spark_catalog "
#~ "org.apache.spark.sql.delta.catalog.DeltaCatalog' >> "
#~ "$SPARK_HOME/conf/spark-defaults.conf"
#~ msgstr ""

#~ msgid ""
#~ "# Run pyspark and exit to trigger"
#~ " the download of the delta lake "
#~ "jars RUN echo \"quit()\" > /tmp/init-"
#~ "delta.py && \\"
#~ msgstr ""

#~ msgid "spark-submit /tmp/init-delta.py && \\ rm /tmp/init-delta.py"
#~ msgstr ""

#~ msgid "# Running a Container"
#~ msgstr ""

#~ msgid "## Using the Docker CLI"
#~ msgstr ""

#~ msgid "```bash $ docker run -p 8888:8888 jupyter/scipy-notebook:2c80cf3537ca"
#~ msgstr ""

#~ msgid ""
#~ "Executing the command: jupyter notebook "
#~ "[I 15:33:00.567 NotebookApp] Writing notebook"
#~ " server cookie secret to "
#~ "/home/jovyan/.local/share/jupyter/runtime/notebook_cookie_secret "
#~ "[W 15:33:01.084 NotebookApp] WARNING: The "
#~ "notebook server is listening on all "
#~ "IP addresses and not using encryption."
#~ " This is not recommended. [I "
#~ "15:33:01.150 NotebookApp] JupyterLab alpha "
#~ "preview extension loaded from "
#~ "/opt/conda/lib/python3.6/site-packages/jupyterlab [I "
#~ "15:33:01.150 NotebookApp] JupyterLab application "
#~ "directory is /opt/conda/share/jupyter/lab [I "
#~ "15:33:01.155 NotebookApp] Serving notebooks "
#~ "from local directory: /home/jovyan [I "
#~ "15:33:01.156 NotebookApp] 0 active kernels "
#~ "[I 15:33:01.156 NotebookApp] The Jupyter "
#~ "Notebook is running at: [I 15:33:01.157"
#~ " NotebookApp] http://[all ip addresses on"
#~ " your "
#~ "system]:8888/?token=112bb073331f1460b73768c76dffb2f87ac1d4ca7870d46a"
#~ " [I 15:33:01.157 NotebookApp] Use Control-C"
#~ " to stop this server and shut "
#~ "down all kernels (twice to skip "
#~ "confirmation). [C 15:33:01.160 NotebookApp]"
#~ msgstr ""

#~ msgid ""
#~ "Copy/paste this URL into your browser"
#~ " when you connect for the first "
#~ "time, to login with a token:"
#~ msgstr ""

#~ msgid "http://localhost:8888/?token=112bb073331f1460b73768c76dffb2f87ac1d4ca7870d46a"
#~ msgstr ""

#~ msgid ""
#~ "```bash # list containers $ docker "
#~ "ps -a CONTAINER ID        IMAGE"
#~ "                   COMMAND                  CREATED    "
#~ "STATUS                      PORTS               NAMES "
#~ "d67fe77f1a84        jupyter/base-notebook   \"tini"
#~ " -- start-noteb\"   44 seconds ago"
#~ "    Exited (0) 39 seconds ago"
#~ "                       cocky_mirzakhani"
#~ msgstr ""

#~ msgid ""
#~ "# start the stopped container $ "
#~ "docker start -a d67fe77f1a84 Executing "
#~ "the command: jupyter notebook [W "
#~ "16:45:02.020 NotebookApp] WARNING: The "
#~ "notebook server is listening on all "
#~ "IP addresses and not using encryption."
#~ " This is not recommended. ..."
#~ msgstr ""

#~ msgid ""
#~ "# remove the stopped container $ "
#~ "docker rm d67fe77f1a84 d67fe77f1a84 ```"
#~ msgstr ""

#~ msgid ""
#~ "```bash $ docker run --rm -p "
#~ "10000:8888 -v \"$PWD\":/home/jovyan/work "
#~ "jupyter/r-notebook:e5c5a7d3e52d"
#~ msgstr ""

#~ msgid ""
#~ "Executing the command: jupyter notebook "
#~ "[I 19:31:09.573 NotebookApp] Writing notebook"
#~ " server cookie secret to "
#~ "/home/jovyan/.local/share/jupyter/runtime/notebook_cookie_secret "
#~ "[W 19:31:11.930 NotebookApp] WARNING: The "
#~ "notebook server is listening on all "
#~ "IP addresses and not using encryption."
#~ " This is not recommended. [I "
#~ "19:31:12.085 NotebookApp] JupyterLab alpha "
#~ "preview extension loaded from "
#~ "/opt/conda/lib/python3.6/site-packages/jupyterlab [I "
#~ "19:31:12.086 NotebookApp] JupyterLab application "
#~ "directory is /opt/conda/share/jupyter/lab [I "
#~ "19:31:12.117 NotebookApp] Serving notebooks "
#~ "from local directory: /home/jovyan [I "
#~ "19:31:12.117 NotebookApp] 0 active kernels "
#~ "[I 19:31:12.118 NotebookApp] The Jupyter "
#~ "Notebook is running at: [I 19:31:12.119"
#~ " NotebookApp] http://[all ip addresses on"
#~ " your "
#~ "system]:8888/?token=3b8dce890cb65570fb0d9c4a41ae067f7604873bd604f5ac"
#~ " [I 19:31:12.120 NotebookApp] Use Control-C"
#~ " to stop this server and shut "
#~ "down all kernels (twice to skip "
#~ "confirmation). [C 19:31:12.122 NotebookApp]"
#~ msgstr ""

#~ msgid "http://localhost:8888/?token=3b8dce890cb65570fb0d9c4a41ae067f7604873bd604f5ac"
#~ msgstr ""

#~ msgid "```bash docker run -d -P --name notebook jupyter/all-spark-notebook ```"
#~ msgstr ""

#~ msgid ""
#~ "```bash # get the random host port"
#~ " assigned to the container port 8888"
#~ " $ docker port notebook 8888 "
#~ "0.0.0.0:32769"
#~ msgstr ""

#~ msgid "# get the notebook token from the logs $ docker logs --tail 3 notebook"
#~ msgstr ""

#~ msgid "http://localhost:8888/?token=15914ca95f495075c0aa7d0e060f1a78b6d94f70ea373b00"
#~ msgstr ""

#~ msgid "```bash # stop the container docker stop notebook notebook"
#~ msgstr ""

#~ msgid "# remove the container permanently docker rm notebook notebook ```"
#~ msgstr ""

#~ msgid "## Using Binder"
#~ msgstr ""

#~ msgid "## Using JupyterHub"
#~ msgstr ""

#~ msgid "## Using Other Tools and Services"
#~ msgstr ""

#~ msgid "# Selecting an Image"
#~ msgstr ""

#~ msgid "## Core Stacks"
#~ msgstr ""

#~ msgid "### jupyter/base-notebook"
#~ msgstr ""

#~ msgid ""
#~ "[Miniforge](https://github.com/conda-forge/miniforge) "
#~ "Python 3.x in `/opt/conda` with two "
#~ "package managers - "
#~ "[conda](https://github.com/conda/conda): \"cross-platform,"
#~ " language-agnostic binary package "
#~ "manager\". - [mamba](https://github.com/mamba-"
#~ "org/mamba): \"reimplementation of the conda"
#~ " package manager in C++\"."
#~ msgstr ""

#~ msgid "### jupyter/minimal-notebook"
#~ msgstr ""

#~ msgid "### jupyter/r-notebook"
#~ msgstr ""

#~ msgid "### jupyter/scipy-notebook"
#~ msgstr ""

#~ msgid "### jupyter/tensorflow-notebook"
#~ msgstr ""

#~ msgid "### jupyter/datascience-notebook"
#~ msgstr ""

#~ msgid "### jupyter/pyspark-notebook"
#~ msgstr ""

#~ msgid "### jupyter/all-spark-notebook"
#~ msgstr ""

#~ msgid "### Image Relationships"
#~ msgstr ""

#~ msgid "### Builds"
#~ msgstr ""

#~ msgid "### Versioning"
#~ msgstr ""

#~ msgid "## Community Stacks"
#~ msgstr ""

#~ msgid "# Image Specifics"
#~ msgstr ""

#~ msgid "## Apache Spark"
#~ msgstr ""

#~ msgid "### Specific Docker Image Options"
#~ msgstr ""

#~ msgid "### Build an Image with a Different Version of Spark"
#~ msgstr ""

#~ msgid ""
#~ "Spark distribution is defined by the "
#~ "combination of the Spark and the "
#~ "Hadoop version and verified by the "
#~ "package checksum, see [Download Apache "
#~ "Spark](https://spark.apache.org/downloads.html) and the"
#~ " [archive repo](https://archive.apache.org/dist/spark/) "
#~ "for more information. * `spark_version`: "
#~ "The Spark version to install (`3.0.0`)."
#~ " * `hadoop_version`: The Hadoop version "
#~ "(`3.2`). * `spark_checksum`: The package "
#~ "checksum (`BFE4540...`)."
#~ msgstr ""

#~ msgid ""
#~ "Spark can run with different OpenJDK "
#~ "versions. * `openjdk_version`: The version "
#~ "of (JRE headless) the OpenJDK "
#~ "distribution (`11`), see [Ubuntu "
#~ "packages](https://packages.ubuntu.com/search?keywords=openjdk)."
#~ msgstr ""

#~ msgid ""
#~ "```bash # From the root of the "
#~ "project # Build the image with "
#~ "different arguments docker build --rm "
#~ "--force-rm \\"
#~ msgstr ""

#~ msgid ""
#~ "-t jupyter/pyspark-notebook:spark-2.4.7 "
#~ "./pyspark-notebook \\ --build-arg "
#~ "spark_version=2.4.7 \\ --build-arg "
#~ "hadoop_version=2.7 \\ --build-arg "
#~ "spark_checksum=0F5455672045F6110B030CE343C049855B7BA86C0ECB5E39A075FF9D093C7F648DA55DED12E72FFE65D84C32DCD5418A6D764F2D6295A3F894A4286CC80EF478"
#~ " \\ --build-arg openjdk_version=8"
#~ msgstr ""

#~ msgid ""
#~ "# Check the newly built image "
#~ "docker run -it --rm jupyter/pyspark-"
#~ "notebook:spark-2.4.7 pyspark --version"
#~ msgstr ""

#~ msgid ""
#~ "# Welcome to #       ____              "
#~ "__ #      / __/__  ___ _____/ /__"
#~ " #     _\\ \\/ _ \\/ _ `/ "
#~ "__/  '_/ #    /___/ .__/\\_,_/_/ "
#~ "/_/\\_\\   version 2.4.7 #       /_/ #"
#~ " # Using Scala version 2.11.12, "
#~ "OpenJDK 64-Bit Server VM, 1.8.0_275 ```"
#~ msgstr ""

#~ msgid "### Usage Examples"
#~ msgstr ""

#~ msgid "#### Using Spark Local Mode"
#~ msgstr ""

#~ msgid "##### Local Mode in Python"
#~ msgstr ""

#~ msgid "```python from pyspark.sql import SparkSession"
#~ msgstr ""

#~ msgid ""
#~ "# Spark session & context spark ="
#~ " SparkSession.builder.master('local').getOrCreate() sc "
#~ "= spark.sparkContext"
#~ msgstr ""

#~ msgid ""
#~ "# Sum of the first 100 whole "
#~ "numbers rdd = sc.parallelize(range(100 + "
#~ "1)) rdd.sum() # 5050 ```"
#~ msgstr ""

#~ msgid "##### Local Mode in R"
#~ msgstr ""

#~ msgid "```R library(SparkR)"
#~ msgstr ""

#~ msgid "# Spark session & context sc <- sparkR.session(\"local\")"
#~ msgstr ""

#~ msgid ""
#~ "# Sum of the first 100 whole "
#~ "numbers sdf <- createDataFrame(list(1:100)) "
#~ "dapplyCollect(sdf,"
#~ msgstr ""

#~ msgid "function(x) { x <- sum(x)}"
#~ msgstr ""

#~ msgid ")"
#~ msgstr ""

#~ msgid "# 5050 ```"
#~ msgstr ""

#~ msgid "```R library(sparklyr)"
#~ msgstr ""

#~ msgid ""
#~ "# Spark configuration conf <- "
#~ "spark_config() # Set the catalog "
#~ "implementation in-memory "
#~ "conf$spark.sql.catalogImplementation <- \"in-"
#~ "memory\""
#~ msgstr ""

#~ msgid ""
#~ "# Spark session & context sc <-"
#~ " spark_connect(master = \"local\", config ="
#~ " conf)"
#~ msgstr ""

#~ msgid ""
#~ "# Sum of the first 100 whole "
#~ "numbers sdf_len(sc, 100, repartition = "
#~ "1) %>%"
#~ msgstr ""

#~ msgid "spark_apply(function(e) sum(e))"
#~ msgstr ""

#~ msgid "##### Local Mode in Scala"
#~ msgstr ""

#~ msgid ""
#~ "```python %%init_spark # Configure Spark "
#~ "to use a local master launcher.master"
#~ " = \"local\" ```"
#~ msgstr ""

#~ msgid ""
#~ "```scala // Sum of the first 100"
#~ " whole numbers val rdd = "
#~ "sc.parallelize(0 to 100) rdd.sum() // "
#~ "5050 ```"
#~ msgstr ""

#~ msgid "#### Connecting to a Spark Cluster in Standalone Mode"
#~ msgstr ""

#~ msgid ""
#~ "Run the Docker container with "
#~ "`--net=host` in a location that is "
#~ "network addressable by all of your "
#~ "Spark workers. (This is a [Spark "
#~ "networking requirement](http://spark.apache.org/docs/latest"
#~ "/cluster-overview.html#components).) * NOTE: When"
#~ " using `--net=host`, you must also "
#~ "use the flags `--pid=host -e "
#~ "TINI_SUBREAPER=true`. See <https://github.com/jupyter"
#~ "/docker-stacks/issues/64> for details."
#~ msgstr ""

#~ msgid "##### Standalone Mode in Python"
#~ msgstr ""

#~ msgid ""
#~ "# Spark session & context spark ="
#~ " SparkSession.builder.master('spark://master:7077').getOrCreate()"
#~ " sc = spark.sparkContext"
#~ msgstr ""

#~ msgid "##### Standalone Mode in R"
#~ msgstr ""

#~ msgid "# Spark session & context sc <- sparkR.session(\"spark://master:7077\")"
#~ msgstr ""

#~ msgid ""
#~ "# Spark session & context # Spark"
#~ " configuration conf <- spark_config() # "
#~ "Set the catalog implementation in-memory"
#~ " conf$spark.sql.catalogImplementation <- \"in-"
#~ "memory\" sc <- spark_connect(master = "
#~ "\"spark://master:7077\", config = conf)"
#~ msgstr ""

#~ msgid "##### Standalone Mode in Scala"
#~ msgstr ""

#~ msgid ""
#~ "```python %%init_spark # Configure Spark "
#~ "to use a local master launcher.master"
#~ " = \"spark://master:7077\" ```"
#~ msgstr ""

#~ msgid "## Tensorflow"
#~ msgstr ""

#~ msgid "### Single Machine Mode"
#~ msgstr ""

#~ msgid "```python import tensorflow as tf"
#~ msgstr ""

#~ msgid "hello = tf.Variable('Hello World!')"
#~ msgstr ""

#~ msgid "sess = tf.Session() init = tf.global_variables_initializer()"
#~ msgstr ""

#~ msgid "sess.run(init) sess.run(hello) ```"
#~ msgstr ""

#~ msgid "### Distributed Mode"
#~ msgstr ""

#~ msgid "hello = tf.Variable('Hello Distributed World!')"
#~ msgstr ""

#~ msgid ""
#~ "server = tf.train.Server.create_local_server() sess"
#~ " = tf.Session(server.target) init = "
#~ "tf.global_variables_initializer()"
#~ msgstr ""

#~ msgid ""
#~ "[sparkr]: https://spark.apache.org/docs/latest/sparkr.html "
#~ "[sparklyr]: https://spark.rstudio.com/ [spark-conf]:"
#~ " https://spark.apache.org/docs/latest/configuration.html"
#~ msgstr ""

#~ msgid ""
#~ "[PRP GPU Jupyter "
#~ "repo](https://gitlab.nautilus.optiputer.net/prp/jupyter-"
#~ "stack/-/tree/prp) and "
#~ "[Registry](https://gitlab.nautilus.optiputer.net/prp/jupyter-"
#~ "stack/container_registry): PRP (Pacific Research "
#~ "Platform) maintained registry for jupyter "
#~ "stack based on NVIDIA CUDA-enabled "
#~ "image. Added the PRP image with "
#~ "Pytorch and some other python packages,"
#~ " and GUI Desktop notebook based on"
#~ " https://github.com/jupyterhub/jupyter-remote-"
#~ "desktop-proxy."
#~ msgstr ""

#~ msgid ""
#~ "`-e NB_GID=100` - Instructs the startup"
#~ " script to change the primary group"
#~ " of`$NB_USER` to `$NB_GID` (the new "
#~ "group is added with a name of "
#~ "`$NB_GROUP` if it is defined, otherwise"
#~ " the group is named `$NB_USER`).  "
#~ "This feature is useful when mounting "
#~ "host volumes with specific group "
#~ "permissions. For this option to take "
#~ "effect, you must run the container "
#~ "with `--user root`. (The startup script"
#~ " will `su $NB_USER` after adjusting "
#~ "the group ID.) You might consider "
#~ "using modern Docker options `--user` and"
#~ " `--group-add` instead. See the last"
#~ " bullet below for details.  The user"
#~ " is added to supplemental group "
#~ "`users` (gid 100) in order to "
#~ "allow write access to the home "
#~ "directory and `/opt/conda`.  If you "
#~ "override the user/group logic, ensure "
#~ "the user stays in group `users` if"
#~ " you want them to be able to"
#~ " modify files in the image."
#~ msgstr ""

#~ msgid ""
#~ "`-e NB_GROUP=<name>` - The name used "
#~ "for `$NB_GID`, which defaults to "
#~ "`$NB_USER`.  This is only used if "
#~ "`$NB_GID` is specified and completely "
#~ "optional: there is only cosmetic effect."
#~ msgstr ""

#~ msgid ""
#~ "`-e RESTARTABLE=yes` - Runs Jupyter in"
#~ " a loop so that quitting Jupyter "
#~ "does not cause the container to "
#~ "exit.  This may be useful when you"
#~ " need to install extensions that "
#~ "require restarting Jupyter."
#~ msgstr ""

#~ msgid ""
#~ "The default Python 3.x [Conda "
#~ "environment](http://conda.pydata.org/docs/using/envs.html) "
#~ "resides in `/opt/conda`. The `/opt/conda/bin`"
#~ " directory is part of the default "
#~ "`jovyan` user's `$PATH`. That directory "
#~ "is also whitelisted for use in "
#~ "`sudo` commands by the `start.sh` "
#~ "script."
#~ msgstr ""

#~ msgid ""
#~ "You can configure JupyterHub to launcher"
#~ " Docker containers from the Jupyter "
#~ "Docker Stacks images. If you've been "
#~ "following the [Zero to JupyterHub with"
#~ " Kubernetes](http://zero-to-"
#~ "jupyterhub.readthedocs.io/en/latest/) guide, see the"
#~ " [Use an existing Docker image](http"
#~ "://zero-to-jupyterhub.readthedocs.io/en/latest/user-"
#~ "environment.html#use-an-existing-docker-image)"
#~ " section for details. If you have "
#~ "a custom JupyterHub deployment, see the"
#~ " [Picking or building a Docker "
#~ "image](https://github.com/jupyterhub/dockerspawner#picking-"
#~ "or-building-a-docker-image) instructions for "
#~ "the [dockerspawner](https://github.com/jupyterhub/dockerspawner)"
#~ " instead."
#~ msgstr ""

#~ msgid ""
#~ "The Jupyter team maintains a set "
#~ "of Docker image definitions in the "
#~ "[https://github.com/jupyter/docker-"
#~ "stacks](https://github.com/jupyter/docker-stacks) GitHub"
#~ " repository. The following sections "
#~ "describe these images including their "
#~ "contents, relationships, and versioning "
#~ "strategy."
#~ msgstr ""

#~ msgid ""
#~ "[tidyverse](https://www.tidyverse.org/) packages from "
#~ "[conda-forge](https://conda-forge.github.io/feedstocks)"
#~ msgstr ""

#~ msgid ""
#~ "[devtools](https://cran.r-project.org/web/packages/devtools/index.html),"
#~ " [shiny](https://shiny.rstudio.com/), "
#~ "[rmarkdown](http://rmarkdown.rstudio.com/), "
#~ "[forecast](https://cran.r-project.org/web/packages/forecast/forecast.pdf),"
#~ " "
#~ "[rsqlite](https://cran.r-project.org/web/packages/RSQLite/index.html),"
#~ " "
#~ "[nycflights13](https://cran.r-project.org/web/packages/nycflights13/index.html),"
#~ " [caret](http://topepo.github.io/caret/index.html), "
#~ "[tidymodels](https://www.tidymodels.org/), "
#~ "[rcurl](https://cran.r-project.org/web/packages/RCurl/index.html), "
#~ "and "
#~ "[randomforest](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf)"
#~ " packages from [conda-forge](https://conda-"
#~ "forge.github.io/feedstocks)"
#~ msgstr ""

#~ msgid ""
#~ "[dask](https://dask.org/), [pandas](https://pandas.pydata.org/),"
#~ " [numexpr](https://github.com/pydata/numexpr), "
#~ "[matplotlib](https://matplotlib.org/), "
#~ "[scipy](https://www.scipy.org/), "
#~ "[seaborn](https://seaborn.pydata.org/), [scikit-"
#~ "learn](http://scikit-learn.org/stable/), [scikit-"
#~ "image](http://scikit-image.org/), "
#~ "[sympy](http://www.sympy.org/en/index.html), "
#~ "[cython](http://cython.org/), "
#~ "[patsy](https://patsy.readthedocs.io/en/latest/), "
#~ "[statsmodel](http://www.statsmodels.org/stable/index.html), "
#~ "[cloudpickle](https://github.com/cloudpipe/cloudpickle), "
#~ "[dill](https://pypi.python.org/pypi/dill), "
#~ "[numba](https://numba.pydata.org/), "
#~ "[bokeh](https://bokeh.pydata.org/en/latest/), "
#~ "[sqlalchemy](https://www.sqlalchemy.org/), "
#~ "[hdf5](http://www.h5py.org/), "
#~ "[vincent](http://vincent.readthedocs.io/en/latest/), "
#~ "[beautifulsoup](https://www.crummy.com/software/BeautifulSoup/), "
#~ "[protobuf](https://developers.google.com/protocol-"
#~ "buffers/docs/pythontutorial), [xlrd](http://www.python-"
#~ "excel.org/), "
#~ "[bottleneck](https://bottleneck.readthedocs.io/en/latest/), and"
#~ " [pytables](https://www.pytables.org/) packages"
#~ msgstr ""

#~ msgid ""
#~ "[ipywidgets](https://ipywidgets.readthedocs.io/en/stable/) and"
#~ " [ipympl](https://github.com/matplotlib/jupyter-matplotlib)"
#~ " for interactive visualizations and plots"
#~ " in Python notebooks"
#~ msgstr ""

#~ msgid ""
#~ "[HDF5](https://github.com/JuliaIO/HDF5.jl), "
#~ "[Gadfly](http://gadflyjl.org/stable/), and "
#~ "[RDatasets](https://github.com/johnmyleswhite/RDatasets.jl) "
#~ "packages"
#~ msgstr ""

#~ msgid ""
#~ "[Apache Toree](https://toree.apache.org/) and "
#~ "[spylon-kernel](https://github.com/maxpoint/spylon-kernel)"
#~ " to support Scala code in Jupyter "
#~ "notebooks"
#~ msgstr ""

#~ msgid ""
#~ "[ggplot2](https://ggplot2.tidyverse.org), "
#~ "[sparklyr](http://spark.rstudio.com/), and "
#~ "[rcurl](https://cran.r-project.org/web/packages/RCurl/index.html) "
#~ "packages"
#~ msgstr ""

#~ msgid ""
#~ "[sage-notebook](https://github.com/sharpTrick/sage-"
#~ "notebook) is a community Jupyter Docker"
#~ " Stack image with the "
#~ "[sagemath](https://sagemath.org) kernel on top "
#~ "of the minimal-notebook image. Click "
#~ "here to launch it on "
#~ "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sharpTrick"
#~ "/sage-notebook/master)."
#~ msgstr ""

#~ msgid ""
#~ "`-p 4040:4040` - The `jupyter/pyspark-"
#~ "notebook` and `jupyter/all-spark-notebook` "
#~ "images open [SparkUI (Spark Monitoring "
#~ "and Instrumentation "
#~ "UI)](http://spark.apache.org/docs/latest/monitoring.html) at "
#~ "default port `4040`, this option map "
#~ "`4040` port inside docker container to"
#~ " `4040` port on host machine . "
#~ "Note every new spark context that "
#~ "is created is put onto an "
#~ "incrementing port (ie. 4040, 4041, 4042,"
#~ " etc.), and it might be necessary "
#~ "to open multiple ports. For example: "
#~ "`docker run -d -p 8888:8888 -p "
#~ "4040:4040 -p 4041:4041 jupyter/pyspark-"
#~ "notebook`."
#~ msgstr ""

#~ msgid ""
#~ "[Deploy Spark in Standalone "
#~ "Mode](http://spark.apache.org/docs/latest/spark-"
#~ "standalone.html)."
#~ msgstr ""

#~ msgid ""
#~ "**Example 1** This command pulls the "
#~ "`jupyter/scipy-notebook` image tagged "
#~ "`2c80cf3537ca` from Docker Hub if it "
#~ "is not already present on the "
#~ "local host. It then starts a "
#~ "container running a Jupyter Notebook "
#~ "server and exposes the server on "
#~ "host port 8888. The server logs "
#~ "appear in the terminal and include "
#~ "a URL to the notebook server."
#~ msgstr ""

#~ msgid ""
#~ "**Example 2** This command pulls the "
#~ "`jupyter/r-notebook` image tagged `e5c5a7d3e52d` "
#~ "from Docker Hub if it is not "
#~ "already present on the local host. "
#~ "It then starts a container running "
#~ "a Jupyter Notebook server and exposes"
#~ " the server on host port 10000. "
#~ "The server logs appear in the "
#~ "terminal and include a URL to the"
#~ " notebook server, but with the "
#~ "internal container port (8888) instead "
#~ "of the the correct host port "
#~ "(10000)."
#~ msgstr ""

#~ msgid ""
#~ "Every image on Docker Hub also "
#~ "receives a 12-character tag which "
#~ "corresponds with the git commit SHA "
#~ "that triggered the image build. You "
#~ "can inspect the state of the "
#~ "`jupyter/docker-stacks` repository for that"
#~ " commit to review the definition of"
#~ " the image (e.g., images with tag "
#~ "7c45ec67c8e7 were built from "
#~ "[https://github.com/jupyter/docker-"
#~ "stacks/tree/7c45ec67c8e7](https://github.com/jupyter/docker-"
#~ "stacks/tree/7c45ec67c8e7))."
#~ msgstr ""

#~ msgid ""
#~ "You must refer to git-SHA image"
#~ " tags when stability and reproducibility"
#~ " are important in your work. (e.g."
#~ " `FROM jupyter/scipy-notebook:7c45ec67c8e7`, "
#~ "`docker run -it --rm jupyter/scipy-"
#~ "notebook:7c45ec67c8e7`). You should only use"
#~ " `latest` when a one-off container"
#~ " instance is acceptable (e.g., you "
#~ "want to briefly try a new library"
#~ " in a notebook)."
#~ msgstr ""

#~ msgid ""
#~ "Ref: [https://github.com/jupyter/docker-"
#~ "stacks/issues/440](https://github.com/jupyter/docker-"
#~ "stacks/issues/440)"
#~ msgstr ""

#~ msgid ""
#~ "JupyterLab is preinstalled as a notebook"
#~ " extension starting in tag "
#~ "[c33a7dc0eece](https://github.com/jupyter/docker-stacks/wiki"
#~ "/Docker-build-history)."
#~ msgstr ""

#~ msgid ""
#~ "Run jupyterlab using a command such "
#~ "as `docker run -it --rm -p "
#~ "8888:8888 jupyter/datascience-notebook start.sh "
#~ "jupyter lab`"
#~ msgstr ""

#~ msgid ""
#~ "Ref: [https://github.com/jupyter/docker-"
#~ "stacks/issues/999](https://github.com/jupyter/docker-"
#~ "stacks/issues/999)"
#~ msgstr ""

#~ msgid ""
#~ "See the README for the simple "
#~ "automation here [https://github.com/jupyter/docker-"
#~ "stacks/tree/master/examples/make-"
#~ "deploy](https://github.com/jupyter/docker-"
#~ "stacks/tree/master/examples/make-deploy) which "
#~ "includes steps for requesting and "
#~ "renewing a Let's Encrypt certificate."
#~ msgstr ""

#~ msgid ""
#~ "Ref: [https://github.com/jupyter/docker-"
#~ "stacks/issues/78](https://github.com/jupyter/docker-"
#~ "stacks/issues/78)"
#~ msgstr ""

#~ msgid ""
#~ "Ref: [https://github.com/jupyter/docker-"
#~ "stacks/issues/199](https://github.com/jupyter/docker-"
#~ "stacks/issues/199)"
#~ msgstr ""

#~ msgid ""
#~ "Ref: [https://github.com/jupyter/docker-"
#~ "stacks/issues/177](https://github.com/jupyter/docker-"
#~ "stacks/issues/177)"
#~ msgstr ""

#~ msgid ""
#~ "Ref: [https://github.com/jupyter/docker-"
#~ "stacks/issues/127](https://github.com/jupyter/docker-"
#~ "stacks/issues/127)"
#~ msgstr ""

#~ msgid ""
#~ "Ref: [https://github.com/jupyter/docker-"
#~ "stacks/issues/154](https://github.com/jupyter/docker-"
#~ "stacks/issues/154)"
#~ msgstr ""

#~ msgid ""
#~ "Ref: [https://github.com/jupyter/docker-"
#~ "stacks/issues/43](https://github.com/jupyter/docker-"
#~ "stacks/issues/43)"
#~ msgstr ""

#~ msgid ""
#~ "Ref: [https://github.com/jupyter/docker-"
#~ "stacks/issues/675](https://github.com/jupyter/docker-"
#~ "stacks/issues/675)"
#~ msgstr ""

#~ msgid ""
#~ "For example here is how to build"
#~ " a `pyspark-notebook` image with "
#~ "Spark `2.4.6`, Hadoop `2.7` and OpenJDK"
#~ " `8`."
#~ msgstr ""

#~ msgid ""
#~ "The **same Python version** need to "
#~ "be used on the notebook (where the"
#~ " driver is located) and on the "
#~ "Spark workers. The python version used"
#~ " at driver and worker side can "
#~ "be adjusted by setting the environment"
#~ " variables `PYSPARK_PYTHON` and / or "
#~ "`PYSPARK_DRIVER_PYTHON`, see [Spark Configuration"
#~ "][spark-conf] for more information."
#~ msgstr ""

#~ msgid ""
#~ "[git](https://git-scm.com/), [vi](https://www.vim.org) "
#~ "(actually `vim-tiny`), [nano](https://www.nano-"
#~ "editor.org/) (actually `nano-tiny`), tzdata,"
#~ " and unzip"
#~ msgstr ""

#~ msgid ""
#~ "[devtools](https://cran.r-project.org/web/packages/devtools/index.html),"
#~ " [shiny](https://shiny.rstudio.com/), "
#~ "[rmarkdown](https://rmarkdown.rstudio.com), "
#~ "[forecast](https://cran.r-project.org/web/packages/forecast/forecast.pdf),"
#~ " "
#~ "[rsqlite](https://cran.r-project.org/web/packages/RSQLite/index.html),"
#~ " "
#~ "[nycflights13](https://cran.r-project.org/web/packages/nycflights13/index.html),"
#~ " [caret](https://topepo.github.io/caret/index.html), "
#~ "[tidymodels](https://www.tidymodels.org/), "
#~ "[rcurl](https://cran.r-project.org/web/packages/RCurl/index.html), "
#~ "and "
#~ "[randomforest](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf)"
#~ " packages from [conda-forge](https://conda-"
#~ "forge.org/feedstock-outputs/index.html)"
#~ msgstr ""

#~ msgid ""
#~ "[dask](https://dask.org/), [pandas](https://pandas.pydata.org/),"
#~ " [numexpr](https://github.com/pydata/numexpr), "
#~ "[matplotlib](https://matplotlib.org/), "
#~ "[scipy](https://www.scipy.org/), "
#~ "[seaborn](https://seaborn.pydata.org/), [scikit-"
#~ "learn](https://scikit-learn.org/stable/), [scikit-"
#~ "image](https://scikit-image.org), "
#~ "[sympy](https://www.sympy.org/en/index.html), "
#~ "[cython](https://cython.org), "
#~ "[patsy](https://patsy.readthedocs.io/en/latest/), "
#~ "[statsmodel](https://www.statsmodels.org/stable/index.html), "
#~ "[cloudpickle](https://github.com/cloudpipe/cloudpickle), "
#~ "[dill](https://pypi.org/project/dill/), "
#~ "[numba](https://numba.pydata.org/), "
#~ "[bokeh](https://docs.bokeh.org/en/latest/), "
#~ "[sqlalchemy](https://www.sqlalchemy.org/), "
#~ "[hdf5](https://www.h5py.org), "
#~ "[vincent](https://vincent.readthedocs.io/en/latest/), "
#~ "[beautifulsoup](https://www.crummy.com/software/BeautifulSoup/), "
#~ "[protobuf](https://developers.google.com/protocol-"
#~ "buffers/docs/pythontutorial), [xlrd](https://www.python-"
#~ "excel.org), "
#~ "[bottleneck](https://bottleneck.readthedocs.io/en/latest/), and"
#~ " [pytables](https://www.pytables.org/) packages"
#~ msgstr ""

#~ msgid ""
#~ "[ipywidgets](https://ipywidgets.readthedocs.io/en/stable/) and"
#~ " [ipympl](https://github.com/matplotlib/ipympl) for "
#~ "interactive visualizations and plots in "
#~ "Python notebooks"
#~ msgstr ""

#~ msgid ""
#~ "[tensorflow](https://www.tensorflow.org/) and "
#~ "[keras](https://keras.io/) machine learning "
#~ "libraries"
#~ msgstr ""

#~ msgid ""
#~ "[HDF5](https://github.com/JuliaIO/HDF5.jl), "
#~ "[Gadfly](https://gadflyjl.org/stable/), and "
#~ "[RDatasets](https://github.com/JuliaStats/RDatasets.jl) packages"
#~ msgstr ""

#~ msgid ""
#~ "[Apache Toree](https://toree.apache.org/) and "
#~ "[spylon-kernel](https://github.com/vericast/spylon-kernel)"
#~ " to support Scala code in Jupyter "
#~ "notebooks"
#~ msgstr ""

#~ msgid ""
#~ "[ggplot2](https://ggplot2.tidyverse.org), "
#~ "[sparklyr](https://spark.rstudio.com), and "
#~ "[rcurl](https://cran.r-project.org/web/packages/RCurl/index.html) "
#~ "packages"
#~ msgstr ""

#~ msgid ""
#~ "Pull requests to the `jupyter/docker-"
#~ "stacks` repository trigger builds of all"
#~ " images on GitHub Actions. These "
#~ "images are for testing purposes only "
#~ "and are not saved for use. When"
#~ " pull requests merge to master, all"
#~ " images rebuild on Docker Hub and "
#~ "become available to `docker pull` from"
#~ " Docker Hub."
#~ msgstr ""

#~ msgid ""
#~ "The `jovyan` user has full read/write"
#~ " access to the `/opt/conda` directory. "
#~ "You can use either `conda`, `mamba` "
#~ "or `pip` to install new packages "
#~ "without any additional permissions."
#~ msgstr ""

#~ msgid ""
#~ "[beautifulsoup4](https://www.crummy.com/software/BeautifulSoup/), "
#~ "[bokeh](https://docs.bokeh.org/en/latest/), "
#~ "[bottleneck](https://bottleneck.readthedocs.io/en/latest/), "
#~ "[cloudpickle](https://github.com/cloudpipe/cloudpickle), "
#~ "[conda-forge::blas=\\*=openblas](https://www.openblas.net), "
#~ "[cython](https://cython.org), [dask](https://dask.org/), "
#~ "[dill](https://pypi.org/project/dill/), "
#~ "[h5py](https://www.h5py.org), [matplotlib-"
#~ "base](https://matplotlib.org/), "
#~ "[numba](https://numba.pydata.org/), "
#~ "[numexpr](https://github.com/pydata/numexpr), "
#~ "[pandas](https://pandas.pydata.org/), "
#~ "[patsy](https://patsy.readthedocs.io/en/latest/), "
#~ "[protobuf](https://developers.google.com/protocol-"
#~ "buffers/docs/pythontutorial), "
#~ "[pytables](https://www.pytables.org/), [scikit-"
#~ "image](https://scikit-image.org), [scikit-"
#~ "learn](https://scikit-learn.org/stable/), "
#~ "[scipy](https://www.scipy.org/), "
#~ "[seaborn](https://seaborn.pydata.org/), "
#~ "[sqlalchemy](https://www.sqlalchemy.org/), "
#~ "[statsmodel](https://www.statsmodels.org/stable/index.html), "
#~ "[sympy](https://www.sympy.org/en/index.html), "
#~ "[vincent](https://vincent.readthedocs.io/en/latest/), "
#~ "[widgetsnbextension](https://ipywidgets.readthedocs.io/en/latest/user_install.html"
#~ "#installing-in-classic-jupyter-notebook), "
#~ "[xlrd](https://www.python-excel.org) packages"
#~ msgstr ""

#~ msgid ""
#~ "`-e NB_USER=jovyan` - Instructs the "
#~ "startup script to change the default "
#~ "container username from `jovyan` to the"
#~ " provided value. Causes the script to"
#~ " rename the `jovyan` user home "
#~ "folder. For this option to take "
#~ "effect, you must run the container "
#~ "with `--user root`, set the working "
#~ "directory `-w /home/$NB_USER` and set "
#~ "the environment variable `-e CHOWN_HOME=yes`"
#~ " (see below for detail). This feature"
#~ " is useful when mounting host volumes"
#~ " with specific home folder."
#~ msgstr ""

#~ msgid ""
#~ "`-e NB_UID=1000` - Instructs the startup"
#~ " script to switch the numeric user"
#~ " ID of `$NB_USER` to the given "
#~ "value. This feature is useful when "
#~ "mounting host volumes with specific "
#~ "owner permissions. For this option to"
#~ " take effect, you must run the "
#~ "container with `--user root`. (The "
#~ "startup script will `su $NB_USER` after"
#~ " adjusting the user ID.) You might"
#~ " consider using modern Docker options "
#~ "`--user` and `--group-add` instead. See"
#~ " the last bullet below for details."
#~ msgstr ""

#~ msgid ""
#~ "`-e NB_GID=100` - Instructs the startup"
#~ " script to change the primary group"
#~ " of`$NB_USER` to `$NB_GID` (the new "
#~ "group is added with a name of "
#~ "`$NB_GROUP` if it is defined, otherwise"
#~ " the group is named `$NB_USER`). This"
#~ " feature is useful when mounting host"
#~ " volumes with specific group permissions."
#~ " For this option to take effect, "
#~ "you must run the container with "
#~ "`--user root`. (The startup script will"
#~ " `su $NB_USER` after adjusting the "
#~ "group ID.) You might consider using "
#~ "modern Docker options `--user` and "
#~ "`--group-add` instead. See the last "
#~ "bullet below for details. The user "
#~ "is added to supplemental group `users`"
#~ " (gid 100) in order to allow "
#~ "write access to the home directory "
#~ "and `/opt/conda`. If you override the"
#~ " user/group logic, ensure the user "
#~ "stays in group `users` if you want"
#~ " them to be able to modify "
#~ "files in the image."
#~ msgstr ""

#~ msgid ""
#~ "`-e NB_GROUP=<name>` - The name used "
#~ "for `$NB_GID`, which defaults to "
#~ "`$NB_USER`. This is only used if "
#~ "`$NB_GID` is specified and completely "
#~ "optional: there is only cosmetic effect."
#~ msgstr ""

#~ msgid ""
#~ "`-e CHOWN_HOME=yes` - Instructs the "
#~ "startup script to change the `$NB_USER`"
#~ " home directory owner and group to"
#~ " the current value of `$NB_UID` and"
#~ " `$NB_GID`. This change will take "
#~ "effect even if the user home "
#~ "directory is mounted from the host "
#~ "using `-v` as described below. The "
#~ "change is **not** applied recursively by"
#~ " default. You can change modify the"
#~ " `chown` behavior by setting "
#~ "`CHOWN_HOME_OPTS` (e.g., `-e CHOWN_HOME_OPTS='-R'`)."
#~ msgstr ""

#~ msgid ""
#~ "`-e CHOWN_EXTRA=\"<some dir>,<some other "
#~ "dir>\"` - Instructs the startup script"
#~ " to change the owner and group "
#~ "of each comma-separated container "
#~ "directory to the current value of "
#~ "`$NB_UID` and `$NB_GID`. The change is"
#~ " **not** applied recursively by default."
#~ " You can change modify the `chown`"
#~ " behavior by setting `CHOWN_EXTRA_OPTS` "
#~ "(e.g., `-e CHOWN_EXTRA_OPTS='-R'`)."
#~ msgstr ""

#~ msgid ""
#~ "`-e GRANT_SUDO=yes` - Instructs the "
#~ "startup script to grant the `NB_USER`"
#~ " user passwordless `sudo` capability. You"
#~ " do **not** need this option to "
#~ "allow the user to `conda` or `pip`"
#~ " install additional packages. This option"
#~ " is useful, however, when you wish"
#~ " to give `$NB_USER` the ability to"
#~ " install OS packages with `apt` or"
#~ " modify other root-owned files in "
#~ "the container. For this option to "
#~ "take effect, you must run the "
#~ "container with `--user root`. (The "
#~ "`start-notebook.sh` script will `su "
#~ "$NB_USER` after adding `$NB_USER` to "
#~ "sudoers.) **You should only enable "
#~ "`sudo` if you trust the user or"
#~ " if the container is running on "
#~ "an isolated host.**"
#~ msgstr ""

#~ msgid ""
#~ "`--user 5000 --group-add users` - "
#~ "Launches the container with a specific"
#~ " user ID and adds that user to"
#~ " the `users` group so that it "
#~ "can modify files in the default "
#~ "home directory and `/opt/conda`. You can"
#~ " use these arguments as alternatives "
#~ "to setting `$NB_UID` and `$NB_GID`."
#~ msgstr ""

#~ msgid ""
#~ "The default Python 3.x [Conda "
#~ "environment](https://conda.io/projects/conda/en/latest/user-"
#~ "guide/concepts/environments.html) resides in "
#~ "`/opt/conda`. The `/opt/conda/bin` directory "
#~ "is part of the default `jovyan` "
#~ "user's `$PATH`. That directory is also"
#~ " whitelisted for use in `sudo` "
#~ "commands by the `start.sh` script."
#~ msgstr ""

#~ msgid ""
#~ "[csharp-notebook is a community Jupyter"
#~ " Docker Stack image. Try C# in "
#~ "Jupyter Notebooks](https://github.com/tlinnet/csharp-"
#~ "notebook). The image includes more than"
#~ " 200 Jupyter Notebooks with example "
#~ "C# code and can readily be tried"
#~ " online via mybinder.org. Click here "
#~ "to launch "
#~ "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/tlinnet"
#~ "/csharp-notebook/master)."
#~ msgstr ""

#~ msgid ""
#~ "[education-notebook is a community "
#~ "Jupyter Docker Stack image](https://github.com"
#~ "/umsi-mads/education-notebook). The image "
#~ "includes nbgrader and RISE on top "
#~ "of the datascience-notebook image. Click"
#~ " here to launch it on "
#~ "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh"
#~ "/umsi-mads/education-notebook/master)."
#~ msgstr ""

#~ msgid ""
#~ "[java-notebook is a community Jupyter"
#~ " Docker Stack image](https://github.com/jbindinga"
#~ "/java-notebook). The image includes "
#~ "[IJava](https://github.com/SpencerPark/IJava) kernel on"
#~ " top of the minimal-notebook image."
#~ " Click here to launch it on "
#~ "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jbindinga"
#~ "/java-notebook/master)."
#~ msgstr ""

#~ msgid ""
#~ "[sage-notebook](https://github.com/sharpTrick/sage-"
#~ "notebook) is a community Jupyter Docker"
#~ " Stack image with the "
#~ "[sagemath](https://www.sagemath.org) kernel on top"
#~ " of the minimal-notebook image. Click"
#~ " here to launch it on "
#~ "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sharpTrick"
#~ "/sage-notebook/master)."
#~ msgstr ""

#~ msgid ""
#~ "[PRP GPU Jupyter "
#~ "repo](https://gitlab.nautilus.optiputer.net/prp/jupyter-"
#~ "stack/-/tree/prp) and "
#~ "[Registry](https://gitlab.nautilus.optiputer.net/prp/jupyter-"
#~ "stack/container_registry): PRP (Pacific Research "
#~ "Platform) maintained registry for jupyter "
#~ "stack based on NVIDIA CUDA-enabled "
#~ "image. Added the PRP image with "
#~ "Pytorch and some other python packages,"
#~ " and GUI Desktop notebook based on"
#~ " <https://github.com/jupyterhub/jupyter-remote-"
#~ "desktop-proxy>."
#~ msgstr ""

#~ msgid ""
#~ "[cgspatial-notebook](https://github.com/SCiO-systems"
#~ "/cgspatial-notebook) is a community Jupyter"
#~ " Docker Stack image. The image "
#~ "includes major geospatial Python & R "
#~ "libraries on top of the datascience-"
#~ "notebook image. Try it on "
#~ "binder:[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh"
#~ "/SCiO-systems/cgspatial-notebook/master)"
#~ msgstr ""

#~ msgid ""
#~ "[kotlin-notebook](https://github.com/knonm/kotlin-"
#~ "notebook) is a community Jupyter Docker"
#~ " Stack image. The image includes "
#~ "[Kotlin kernel for "
#~ "Jupyter/IPython](https://github.com/Kotlin/kotlin-jupyter) "
#~ "on top of the `base-notebook` "
#~ "image. Try it on Binder: "
#~ "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/knonm"
#~ "/kotlin-notebook/main)"
#~ msgstr ""

#~ msgid ""
#~ "`-p 4040:4040` - The `jupyter/pyspark-"
#~ "notebook` and `jupyter/all-spark-notebook` "
#~ "images open [SparkUI (Spark Monitoring "
#~ "and Instrumentation "
#~ "UI)](https://spark.apache.org/docs/latest/monitoring.html) at"
#~ " default port `4040`, this option map"
#~ " `4040` port inside docker container "
#~ "to `4040` port on host machine ."
#~ " Note every new spark context that"
#~ " is created is put onto an "
#~ "incrementing port (ie. 4040, 4041, 4042,"
#~ " etc.), and it might be necessary "
#~ "to open multiple ports. For example: "
#~ "`docker run -d -p 8888:8888 -p "
#~ "4040:4040 -p 4041:4041 jupyter/pyspark-"
#~ "notebook`."
#~ msgstr ""

#~ msgid "**crosscompass/ihaskell-notebook**"
#~ msgstr ""

#~ msgid ""
#~ "[Source on GitHub](https://github.com/jamesdbrock"
#~ "/ihaskell-notebook) | [Dockerfile commit "
#~ "history](https://github.com/jamesdbrock/ihaskell-"
#~ "notebook/commits/master/Dockerfile) | [Docker Hub"
#~ " image tags](https://hub.docker.com/r/crosscompass"
#~ "/ihaskell-notebook/tags)"
#~ msgstr ""

#~ msgid ""
#~ "`crosscompass/ihaskell-notebook` is based on"
#~ " [IHaskell](https://github.com/gibiansky/IHaskell). Includes"
#~ " popular packages and example notebooks."
#~ msgstr ""

#~ msgid ""
#~ "Pull requests to the `jupyter/docker-"
#~ "stacks` repository trigger builds of all"
#~ " images on GitHub Actions. These "
#~ "images are for testing purposes only "
#~ "and are not saved for further use."
#~ " When pull requests merge to master,"
#~ " all images rebuild on Docker Hub "
#~ "and become available to `docker pull`"
#~ " from Docker Hub."
#~ msgstr ""

#~ msgid ""
#~ "The `latest` tag in each Docker "
#~ "Hub repository tracks the master branch"
#~ " `HEAD` reference on GitHub. `latest` "
#~ "is a moving target, by definition, "
#~ "and will have backward-incompatible "
#~ "changes regularly."
#~ msgstr ""

#~ msgid ""
#~ "Every image on Docker Hub also "
#~ "receives a 12-character tag which "
#~ "corresponds with the git commit SHA "
#~ "that triggered the image build. You "
#~ "can inspect the state of the "
#~ "`jupyter/docker-stacks` repository for that"
#~ " commit to review the definition of"
#~ " the image (e.g., images with tag "
#~ "`33add21fab64` were built from "
#~ "<https://github.com/jupyter/docker-stacks/tree/33add21fab64>."
#~ msgstr ""

#~ msgid ""
#~ "You must refer to git-SHA image"
#~ " tags when stability and reproducibility"
#~ " are important in your work. (e.g."
#~ " `FROM jupyter/scipy-notebook:33add21fab64`, "
#~ "`docker run -it --rm jupyter/scipy-"
#~ "notebook:33add21fab64`). You should only use"
#~ " `latest` when a one-off container"
#~ " instance is acceptable (e.g., you "
#~ "want to briefly try a new library"
#~ " in a notebook)."
#~ msgstr ""

#~ msgid ""
#~ "Conda is configured by default to "
#~ "use only the [`conda-"
#~ "forge`](https://anaconda.org/conda-forge) channel. "
#~ "However, alternative channels can be "
#~ "used either one shot by overwriting "
#~ "the default channel in the installation"
#~ " command or by configuring `conda` to"
#~ " use different channels. The examples "
#~ "below show how to use the "
#~ "[anaconda default "
#~ "channels](https://repo.anaconda.com/pkgs/main) instead of"
#~ " `conda-forge` to install packages."
#~ msgstr ""

#~ msgid "Using `pip install` or `conda install` in a Child Docker image"
#~ msgstr ""

# ce204678c3af4aa9a0fb55bb6de7554b
#~ msgid ""
#~ "You need to install conda's gcc "
#~ "for Python xgboost to work properly. "
#~ "Otherwise, you'll get an exception about"
#~ " libgomp.so.1 missing GOMP_4.0."
#~ msgstr ""

#~ msgid "Enable auto-sklearn notebooks"
#~ msgstr ""

#~ msgid ""
#~ "Using `auto-sklearn` requires `swig`, "
#~ "which the other notebook images lack,"
#~ " so it cant be experimented with. "
#~ "Also, there is no Conda package "
#~ "for `auto-sklearn`."
#~ msgstr ""

#~ msgid ""
#~ "[mamba](https://github.com/mamba-org/mamba): "
#~ "\"reimplementation of the conda package "
#~ "manager in C++\"."
#~ msgstr ""

